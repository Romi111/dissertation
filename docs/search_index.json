[
["intro-placemarker.html", "Examining youth engagement during learning activities that involve work with data: An Experience Sampling Approach Chapter 1 Introduction", " Examining youth engagement during learning activities that involve work with data: An Experience Sampling Approach Joshua M. Rosenberg 2018-05-01 Chapter 1 Introduction Changes in how we plan our day-to-day lives, communicate, and learn are increasingly impacted by data. These sources of data–quantitative and qualitative–are created by us, for us, and about us, although at present opportunities for learners to analyze data in educational settings remain limited. Work with data more broadly includes processes of collecting, creating, modeling data, and asking questions that may be answered with data and making sense of findings. Work with data, then, is more than just crunching numbers or interpreting a figure created by someone else, but rather is about making sense of phenomena and problem solving, a point particularly relevant to educational contexts (Lee &amp; Wilkerson, 2018; Wild &amp; Pfannkuch, 1999). Aspects of work with data cut across STEM domains and are recognized as core competencies in both the Next Generation Science Standards and the Common Core State Standards in mathematics (National Governors Association Center for Best Practices, Council of Chief State School Officers, 2010; NGSS Lead States, 2013). Scholars have pointed out the benefits of analyzing data for learners as young as two years old (Gopnik, &amp; Sobel, 2000). In supporting teachers and learners’ data analysis efforts, some scholars have focused on key data analytic processes, particularly those related to generating measures of phenomena and creating data models, using these as anchoring practices for other aspects of work with data, like posing questions (English, 2012; Lehrer &amp; Romberg, 1996; Lesh, Middleton, Caylor, &amp; Gupta, 2008). Findings from this area of research suggest that engaging in these practices “has an exceptionally high payoff in terms of students’ scientific reasoning” (Lehrer &amp; Schauble, 2015, p. 696) and can highlight the utility of mathematics for students’ lives (Lesh, Middleton, Caylor, &amp; Gupta, 2008). Learners’ experiences, considered from the perspective of engagement theory, consist not only of cognitive processes, but also behavioral and even affective dimensions, too (Fredricks, Blumenfeld, &amp; Paris, 2004; Skinner &amp; Pitzer, 2012). When learners’ experiences are considered in terms of their engagement, we can hypothesize that learners who are engaged in high-quality activities related to work with data will be more or less cognitively, behaviorally, and affectively engaged. This engagement is a key outcome in its own right and may be an antecedent of changes in other outcomes, such as students’ intention to pursue an area of study or career in a STEM domain. While scholars have looked at cognitive outcomes and learners’ capability to participate in specific, learners’ experiences of working with data has not been the focus of past research. Thus, the present study sets out to understand to how learners’ experiences are impacted by work with data. In this study, I use contemporary engagement theory as a framework to understand learners’ experience. Past research has shown that how engaged learners and youth are is a predictor of key outcomes, such as their well-being, achievement and pursuit of an area of study or career (Sinatra, Heddy, &amp; Lombardi, 2015; Wang, Chow, Hofkens, &amp; Salmela-Aro, 2015; Wang &amp; Eccles, 2012). In this framework, engagement is considered to multi-dimensional and dynamic, or changing over time (Fredricks &amp; McColskey, 2012). Scholars commonly consider engagement in terms of three dimensions: cognitive (i.e., use of meta-cognitive learning strategies), behavioral (hard work on a task), and affective dimensions (enjoyment; Fredricks, Blumenfeld, &amp; Paris, 2004; Sinatra, et al., 2015; Skinner &amp; Pitzer, 2012). In recognition of its dynamic nature, some engagement scholars have drawn upon flow theory (Csikszentmihalyi, 1990, 1997) to identify not only dimensions of engagement, but also other, subjective, characteristics that effect engagement. This past research, drawn upon in the present study, has considered two of learners’ subjective considerations, their perceived competence and challenge, act as key conditions of engagement (Shernoff, Kelly, Tonks, Anderson, Cavanagh, Sinha, &amp; Abdi, 2016). The purpose of this study, then, is to understand learners’ experience of working with data through the lens of engagement. Engagement is understood in terms of cognitive, behavioral, and affective dimensions, and the conditions that support engagement are understood in terms of two subjective components that past research and theory suggest influence engagement: perceived challenge and perceived competence. Work with data is considered in terms of specific aspects, such as asking questions and generating and modeling data, identified from past research. Engagement in work with data is explored in the context of outside-of-school STEM enrichment programs carried out during the summer. "],
["literature-review.html", "Chapter 2 Literature Review 2.1 Defining Work with Data 2.2 The role of work with data in the curriculum 2.3 What We Know (And Do Not Know) About How Youth Work with Data 2.4 Engagement in General and in STEM Domains 2.5 What conditions and youth characteristics impact engagement 2.6 Using ESM to Study the Dynamics of Engagement 2.7 A place for profiles 2.8 Need for the Present Study 2.9 Conceptual Framework and Research Questions", " Chapter 2 Literature Review The framework for this study is informed by work on STEM practices, student engagement, and analytic approaches to modeling multidimensional constructs. In this review of literature, I define work with data as a key practice across STEM domains. I also describe and justify a multi-dimensional framework for understanding engagement, and then review an approach to analyzing data that is ideal for capturing this multidimensionality. 2.1 Defining Work with Data Some scholars have focused on a few key pieces of data analysis connected through the use of “data to solve real problems and to answer authentic questions” (Hancock et al., 1992, p. 337). This approach has primarily been taken up by mathematics educators and is reflected in statistics curriculum documents (Franklin et al., 2007). In science settings, where answering questions about phenomena serve as the focus of activities, it shares features of the process of engaging in scientific and engineering practices, but has been less often studied. While work with data has been conceived in different ways, some core components have emerged (see Lee and Wikerson [in press] for a review and Wild and Pfannkuch [1999], Franklin et al. [2007], Lehrer and Schauble [2004] for specific examples from past research). Different approaches to working with data that have been articulated in prior studies are distilled into five key aspects (see Figure 1) that guide their conceptualization in this study: Asking questions: Generating questions that can be answered with empirical evidence Making observations: Watching phenomena and noticing what is happening with respect to the phenomena or problem being investigated Generating data: The process of figuring out how or why to inscribe an observation as data about a phenomena, as well as generating coding frames or tools for measuring Data modeling: Activities involving use of simple statistics, such as the mean and variance, as well as more complicated models, such as linear models and extensions of the linear model Interpreting and communicating findings: Activities related to identifying a driving question regarding the phenomena that the question is about Figure 2.1: Work with data in STEM education settings The five practices are a cycle because not only does each part follow that before it, but also because the overall process is iterative: interpreting findings commonly leads to new questions and subsequent engagement in work with data. Also, scholars have pointed out some key features of how work with data is carried out that impact their effectiveness as a pedagogical approach. These key features include an emphasis on making sense of real-world phenomena and iterative cycles of engaging in work with data and collaboration and dialogue, through which ideas and intermediate findings are critiqued and subject to critique, and revised over time (McNeill &amp; Berland, 2017). 2.2 The role of work with data in the curriculum Work with data can serve as an organizing set of practices for engaging in inquiry in STEM learning settings (Lehrer &amp; Schauble, 2015). Data are both encountered and generated by learners, and so opportunities for learners to work with data provide many opportunities to leverage their curiosity because processes of inquiry can be grounded in phenomena that learners themselves can see and manipulate or phenomena that learners are interested in. Also important, becoming proficient in work with data can provide learners with an in-demand capability in society, owing to the number of occupations, from education to entrepreneurship, that demand or involve taking action based on data (Wilkerson &amp; Fenwick, 2017). Furthermore, becoming proficient in work with data can be personally empowering because of the parts of our lives—from paying energy bills to interpreting news articles—that use data. Recent educational reform efforts emphasize work with data (i.e., the scientific and engineering practices in the NGSS and the standards for mathematical practice in the Common Core State Standards). However, work with data is uncommon in many classroom settings (McNeill &amp; Berland, 2017), and so learning environments suited to engaging in work with data, but not explicitly designed to support it, may be valuable to study because they may serve as incubators of these rare and challenging learning activities. Outside-of-school programs are a potentially valuable setting to explore engagement in work with data because of the combined pedagogical and technical expertise of their staff and the activities learners do during their participation in them. Staff for these programs includes educators and scientists, engineers, and others with the technical experience. Additionally, the programs were designed to involve learners in the types of real-world practices experienced by experts in STEM disciplines. Attendance in such programs is associated with many benefits to learners (Green, Lee, Constance, &amp; Hynes, 2013; see Lauer, Akiba, Wilkerson, Apthorp, Snow, &amp; Martin-Glenn, 2006, for a comprehensive review). These programs are also selected because little research has examined how data are part of the experiences of youth in out-of-school-time programs, despite its place as one of a few core practices in STEM. While these reasons to study work with data focus on outside-of-school programs, they are also germane to more formal learning environments, such as classrooms, in which teachers want to design opportunities for their learners to work with data. This is important even for those teachers who themselves have technical expertise, but who have experienced limited training and support for engaging learners in work with data. Therefore, these programs can provide insight into whether engaging in work with data is associated with more optimal forms of engagement in the conditions like those for classrooms in which engaging in work with data is a novel and potentially promising approach to doing and learning about STEM. 2.3 What We Know (And Do Not Know) About How Youth Work with Data Scholars have researched cognitive capabilities related to work with data. Much of this laboratory-based research has focused on how children develop the capability to inductively reason from observations (Gelman &amp; Markman, 1987). Other research has focused on the development of causal, or mechanistic, reasoning, among young children (Gopnik et al., 2001; Gopnik &amp; Sobel, 2000), often from a Piagetian, individual-development focused tradition (i.e., Piaget &amp; Inhelder, 1969). A key outcome of engaging in work with data has to do with how learners account for variability (Lehrer, Kim, &amp; Schauble, 2007; Petrosino, Lehrer, &amp; Schauble, 2003; Lesh, Middleton, Caylor, &amp; Gupta, 2008; Lee, Angotti, &amp; Tarr, 2010), arguably the main goal of engaging in work with data (Konold &amp; Pollatsek, 2002). From this research, we know that learners can develop the capacity to reason about variability (and covariability). Past research has also shown that there are strategies that can support work with data. These include the design of technological tools and the development of curricula. From this research, we know about specific strategies and learning progressions for learners to develop this capability, such as the role of measurement in exposing learners in a direct way to sources of variability (Petrosino et al., 2003), role of simulation to learn about sampling distributions (Stohl &amp; Tarr, 2002), and use of relevant phenomena, such as manufacturing processes, such as the size of metallic bolts, which can help learners to focus on “tracking a process by looking at its output” (Konold &amp; Pollatsek, 2002, p. 282). Finally, past research has shown that different aspects of work with data pose unique opportunities and challenges. Asking empirical questions requires experience and ample time to ask a question that is both able to be answered with data and which is sustaining and worth investigating (Bielik, 2016; Hasson &amp; Yarden, 2012). Making observations and generating data, such as of the height of the school’s flagpole, requires negotiation not only of what to measure, but how and how many times to measure it (Lehrer, Kim, &amp; Schauble, 2007). Regarding modeling, not only teaching students about models, such as that of the mean, but also asking them to create them, are valuable and practical (Lehrer &amp; Schauble, 2004; Lehrer, Kim, &amp; Jones, 2011), but also time-intensive. Interpreting findings, especially in light of variability through models, and communicating answers to questions, means not only identifying error but understanding its sources, and can be supported through exploring models that deliberately represent the data poorly, but can be instructive for probing the benefits and weaknesses of models (Lee &amp; Hollebrands, 2008; Lehrer, Kim, &amp; Schauble, 2007). Despite this past research, how learners participate in different aspects of work with data in terms of engagement theory has not been examined. Consider the process of structuring data, commonly described as a—or the—key part of many applied data analyses, that is also under-emphasized in students’ use of data in science settings in which students are provided already-processed, or plotted, data (McNeill &amp; Berland, 2017). How challenging do students perceive these activities to be? How do they perceive their competence regarding this activity? More importantly, how do they engage—cognitively, behaviorally, and affectively—during these experiences? Knowing more about these processes could help us to develop informed recommendations for teachers and designers intending to bring about opportunities for learners to engage in work with data in a better-supported way that is sustained over time. 2.4 Engagement in General and in STEM Domains The nature of engagement is discussed in terms of general features that have been identified across content area domains, conditions that support engagement, and differences between engagement in general and in STEM settings. This is followed by a discussion of two key features of engagement: its dynamic characteristics and what a person-oriented approach to its study can add to research about engagement and its impact on learning and other outcomes. Engagement is defined in this study as active involvement, or investment, in activities (Blumenfeld et al., 2004). Explaining how learners are involved in activities and tasks is especially important if we want to know about what aspects of work with data are most engaging (and in what ways), and therefore can serve as exemplary for others advancing work with data as well as those calling for greater support for engagement. Apart from being focused on involvement, engagement is often thought of as a meta-construct, that is, one that is made up of other constructs (Skinner &amp; Pitzer, 2012; Skinner, Kindermann, &amp; Furrer, 2009). By defining engagement as a meta-construct, scholars characterize it in terms of cognitive, behavioral, and affective dimensions that are distinct yet interrelated (Fredricks, 2016). We know from past research that the cognitive, behavioral, and affective dimensions of engagement can be distinguished (Wang &amp; Eccles, 2012; Wang &amp; Holcombe, 2012) and that while there are long-standing concerns about the conceptual breadth of engagement (Fredricks et al., 2016), careful justification and thoughtful use of multidimensional engagement constructs and measures is warranted based on past research. Engagement is also considered to be dynamic and changing in response to individual, situation or moment, and broader contextual factors, such as the family, classroom, or outside-of-school programs. Engagement in STEM settings shares characteristics with engagement across disciplines, yet there are some distinct aspects of it (Greene, 2015). While one type of engagement—behavioral—is associated with positive outcomes, many STEM practices call for engagement in additional ways (Sinatra et al., 2015), especially around epistemic and agency-related dimensions. For example, many scholars have defined scientific and engineering practices as epistemic practices, which involve applying epistemic considerations around sources of evidence and the nature of explanatory processes (Berland et al., 2016; Stroupe, 2014). The emphasis on developing new knowledge and capabilities through engaging in STEM practices is a potentially important aspect. This is important because measures of engagement might need to be modified for use in STEM domains. Because of the importance of constructing knowledge to engagement in STEM practices, then, cognitive engagement is defined for this study in terms of learning something new or getting better at something. While sometimes defined in terms of extra-curricular involvement or following directions, behavioral engagement is defined in this study as working hard at and concentrating on learning-related activities (Fredricks et al., 2004; Singh, Granville, &amp; Dika, 2002). Finally, affective engagement is defined as affective responses to activities, such as being excited, angry, or relaxed (Pekrun &amp; Linnenbrink-Garcia, 2012). 2.5 What conditions and youth characteristics impact engagement Past research has shown that ESM can help us to find out what conditions support it. Past research suggests that not only learner-level characteristics, such as learners’ interest in the domain of study, but also dynamic, changing moment-to-moment conditions are also important (Shernoff et al., 2003; Shernoff et al., 2016; Shumow, Schmidt, &amp; Zaleski, 2013). Focusing on dynamic conditions, Emergent Motivation Theory (EMT; Csikszentmihalyi, 1990), provides a useful lens. From EMT, a key momentary influencer of engagement is how difficult individuals perceive an activity to be, or its perceived challenge. Another key influencer is how good at an activity individuals perceive themselves to be, or their perceived competence. Most important, from the perspective of EMT, being challenged by and good at an activity are especially engaging experienced when together. Past research has supported this contention. Shernoff et al. (2016), for example, demonstrated that while challenge and skill with high levels of one but low levels on the other (i.e., high challenge and low skill) were not broadly associated with positive forms of engagement, their interaction was, suggesting that learners’ perceptions of the challenge of the activity, and their perceptions of how skillful they are, are important for explaining why learners engage. Other key conditions that support engagement concern teacher support (Strati, Schmidt, &amp; Maier, 2017). Particularly concerning work with data, which is demanding not only for learners but also teachers, sustained support from teachers is an essential component of learners being able to work with data (Lehrer &amp; Schauble, 2015; Wilkerson, Andrews, Shaban, Laina, &amp; Gravel, 2016). Consequently, this study considers not only engagement, but also the conditions of engagement as part in terms of both learners’ subjective experiences. The conditions included in the PECs relate to learners’ subjective perceptions of two key factors suggested by past research and theory, in particular, how challenging they perceive the activity to be and how good at it they perceive themselves to be (Csikszentmihalyi, 1990). I review a few other youth characteristics that impact engagement. In recognition of differences among learners in their tendency to engage in different (higher or lower) ways in specific activities based in part on individual differences (Hidi &amp; Renninger, 2006), learners’ interest in STEM before the start of the programs is also considered as a factor that can impact engagement. Finally, gender and the racial and ethnic group of students is added, as past research has indicated these as factors that influence engagement in STEM (Bystydzienski, Eisenhart, &amp; Bruning; Shernoff &amp; Schmidt, 2008). These conditions are different from those discussed in the section on the five aspects of work with data in that they are teacher-related factors (with respect to instructional support), subjective factors (with respect to perceptions of challenge and competence), and demographic characteristics, whereas a focus on real-world phenomena, iterative cycles, and collaboration and dialogue may potentially impact engagement through learners’ perceiving the activity to be supported by the subjective contextual conditions of challenge and competence. 2.6 Using ESM to Study the Dynamics of Engagement A number of scholars, in recognition of the dynamic nature of engagement, have explored the use of Experience Sampling Method (ESM) to understand engagement (e.g., Strati et al., 2017)—or have recommended it is as a valuable approach for doing so (Turner &amp; Meyer, 2000; Sinatra et al., 2015). ESM involves asking—usually using a digital tool and occasionally a diary—to ask participants short questions about their experiences. ESM is particularly well-suited to understanding the dynamic nature of engagement because students answered brief surveys about their experience when they were signaled, minimally interrupting them from the activity they are engaged in and also seeking to collect measures about learners’ experience when signaled (Hektner, et al., 2007). Research has shown us how the use of ESM can lead to distinct research contributions. Shernoff, Csikszentmihalyi, Schneider, and Shernoff (2003) examined engagement through the use of measures aligned with flow theory, namely, using measures of concentration, interest, and enjoyment (Csikszentmihalyi, 1997). In a study using the same measures of engagement (Shernoff et al. (2016) used an observational measure of challenge and control (or environmental complexity) and found that it significantly predicted engagement, as well as self-esteem, intrinsic motivation, and academic intensity. Schneider et al. (2016) and Linnansaari et al. (2015) examined features of optimal learning moments or moments in which students report high levels of interest, skill, and challenge, as well as their antecedents and consequences. Similar to ESM in that through its use engagement can be studied in a more context-sensitive, still other scholars have used daily diary studies to examine engagement as a function of autonomy-supportive classroom practices (Patall, Vasquez, Steingut, Trimble, &amp; Pituch, 2015; Patall, Steingut, Vasquez, Trimble, &amp; Freeman, 2017). This past research that used ESM (or daily diary studies) to study engagement has shown us that the methodological approach can be used to answer questions that were hard to answer using the more-traditional pre- or post-survey measures. Other research shows us that there are newer approaches to analyzing ESM data that can contribute insights into the dynamics of engagement in a more fine-grained way. For example, Strati et al. (2017) explored the relations between engagement to measures of teacher support, finding associations between instrumental support and engagement and powerfully demonstrating the capacity of ESM to understand some of the dynamics of engagement. Similarly, Poysa et al. (2017) used a similar data analytic approach as Strati et al. (2017), that is, use of crossed effects models for variation within both students and time points, both within and between days. These studies establish the value of the use of ESM to understand the dynamics of engagement and that such an approach may be able to be used to understand engaging in work with data. Additionally, these studies show that how effects at different levels are treated, namely, how variability at these levels is accounted for through random effects as part of mixed effects models, is a key practical consideration for analysts of ESM data. 2.7 A place for profiles One powerful and increasingly widely used way to examine dynamic constructs holistically is a person-oriented approach, which can be used to consider the way in which psychological constructs are experienced together and at once in the experiences of learners. In the context of the present study, this approach can help us to identify naturally occurring profiles of momentary engagement, or engagement as reported by youth via ESM during particular moments. Note that ESM involves asking youth about to report on their experience at the time they were signaled. Profiles seek to capture both the cognitive, behavioral, and affective dimensions of engagement and the subjective conditions of challenge and competence to understand how students experience engagement and its conditions in a more holistic way. There are some recent studies taking a person-oriented approach to the study of engagement (i.e., Salmela-Aro, Moeller, Schneider, Spicer, &amp; Lavonen, 2016a; Salmela-Aro, Muotka, Alho, Hakkarainen, &amp; Lonka, 2016b; Van Rooij, Jansen, &amp; van de Grift, 2017; Schmidt, Rosenberg, &amp; Beymer, 2018), though none have done so to study youths’ engagement in work with data. The person-oriented approach has an important implication for how we analyze data collected from ESM about youths’ engagement, in particular when we consider how to understand engagement as a meta-construct (Skinner, Kindermann, &amp; Furrer, 2009) and how to account for its dynamic nature (Csikszentmihalyi, 1990). We know from past research that engagement can be explained in terms of different patterns among its individual components (Bergman &amp; Magnusson, 1997), in the present case its cognitive, behavioral, and affective components. Because learners’ engagement includes cognitive, behavioral, and affective aspects experienced together at the same time, it can be experienced as a combined effect that is categorically distinct from the effects of the individual dimensions of engagement. This combined effect can be considered as profiles of engagement. Past studies have considered profiles of cognitive, behavioral, and affective aspects of engagement. To account for the dynamic nature of engagement, some past studies have used other measures to predict engagement, such as use of in-the-moment resources and demands (Salmela-Aro et al., 2016b) or, in the case of the study reviewed in the previous section, use of instructional activities and choice (Schmidt et al., 2018). Different from this past research, another potential way to account for the dynamics of engagement is to consider both engagement and its conditions at once. Since a person-oriented approach emphasizes the dynamic nature of development and the impact of not only external but also intra-individual factors. As in the present study, youths’ perceptions of challenge and competence, also collected via ESM, are used along with the measures of engagement to construct momentary profiles. Thus, the profiles of engagement can be considered to be profiles of engagement and its conditions, as they include youths’ responses to five ESM items for their cognitive, behavioral, and affective engagement and their perceptions of how challenging the activity they were doing is and of how competent at the activity they are. 2.8 Need for the Present Study While many scholars have argued that work with data can be understood in terms of the capabilities learners develop and the outcome learners achieve, there is a need to better understand learners’ experiences working with data. The present study does this through the use of contemporary engagement theory and innovative methodological and analytic approaches. Doing this can help us to understand work with data in terms of learner’s experience, which we know from past research impacts what and how students learn (Sinatra et al., 2015). Knowing more about students’ engagement can help us to design activities and interventions focused around work with data that are more engaging and which provide more support to learners in terms of their perceptions of challenge and their own competence. In addition to this general need to study engagement in work with data through the lens of engagement, no research that I am aware of has examined work with data or data analysis more generally in the context of outside-of-school programs. These settings are potentially rich with opportunities for highly engaged learners to analyze authentic data sources. Finally, little research has examined how data is part of the experiences of youth in out-of-school-time programs, despite its place as one of a few core practices in STEM. 2.9 Conceptual Framework and Research Questions The present study is about how engagement can be used to understand how learners are involved in work with data and how characteristics of activities and learners impact the relationships between work with data and engagement. Its context is out-of-school-time STEM enrichment programs designed to meet guidelines for best practices. The conceptual framework in the present study is presented in Figure 2 and is unpacked in the remainder of this section. Figure 2.2: A conceptual framework for this study with research questions labeled There are five aspects of work with data synthesized from past research (i.e., Hancock et al., 1992; Lehrer &amp; Romberg, 1996; Wild &amp; Pfannkuch, 1999): Asking questions or identifying problems Making observations Generating data Data modeling Interpreting and communicating findings In Figure 2, engagement in work with data is associated with different profiles of engagement and its conditions, referred to as either profiles of engagement and its conditions or profiles in the remainder of this manuscript. The theoretical framework for the person-oriented approach suggests that while the dynamics among the individual aspects of engagement emerge in complex and situation-specific ways, it is possible to consider engagement in terms of patterns among its components. In addition, a pre-program measure of learners’ individual interest in STEM is hypothesized to be associated with the profiles and the relations of work with data and the profiles. The ESM responses that make up the profiles are associated with students, moments, and program effects that must be accounted for (Strati et al., 2017). As depicted in the Figure 2, the four research questions are formalized as follows: What is the frequency and nature of opportunities for youth to engage in each of the five aspects of work with data in summer STEM programs? What profiles of youth engagement and its conditions emerge from experiential data collected in the programs? How do data practices relate to youth engagement in the programs? How do youth characteristics relate to their engagement? "],
["method.html", "Chapter 3 Method 3.1 Participants 3.2 Context 3.3 Procedure 3.4 Data Sources and Measures 3.5 Data Analysis 3.6 Sensitivity Analysis", " Chapter 3 Method In recognition of the challenge of studying engagement in learning environments where factors related to activities, learners, and each of the nine programs all interact at the same time, this study uses a methodological approach suited to studying engagement as a dynamic, multi-faceted experience. Specifically, this study employs the Experience Sampling Method (ESM; Hektner, Schmidt, &amp; Csikszentmihalyi, 2007) where learners answer short questions about their experience when signaled. This approach is both sensitive to changes in engagement over time, as well as between learners and allows us to understand engagement and how factors impact it in more nuanced and complex ways (Turner &amp; Meyer, 2000). 3.1 Participants Participants consist of 203 youth. Youth in these programs are from diverse racial and ethnic backgrounds (see Table 1). Most participants are around 13 years old (from youth whose age was available: M = 12.71, SD = 1.70, min. = 10.75, max. = 16.36). Detailed demographic characteristics of learners are presented in the table. Table 3.1: Demographic characteristics of youth Youth Percentage Sex Male 50 Female 50 Race/Ethnicity Hispanic 48 White 6 Black 36 Multi-racial 3 Asian/Pacific Islander 7 Parent Education High School or Below 79 Graduated from College (B.A. or B.S.) 21 3.2 Context The setting for this study is nine out-of-school STEM programs designed around best practices in urban areas in the Northeast United States during the summer of 2015. These are described in the appendix with pseudonyms for the program names. Two intermediary organizations contracted by the urban area school districts to administer the summer programs. The two intermediaries were responsible for soliciting and enrolling youth; establishing guidelines for the design of the programs, and the goals of the programs; and provide training and professional development for the program’s staff. A key difference between the intermediary organizations was that one separated academic and enrichment-related activities, whereas, in another, which was more closely involved in the day-to-day activities of the program, the academic and enrichment components were more integrated, which may have program-specific effects on learners’ engagement. Many of the programs aim to involve learners in work with data. These learning environments bring together youth activity leaders, educators, and those with technical expertise in STEM domains. Youth spent around three hours per day for four days per week for the approximately four-week programs, which were taught by youth activity leaders and scientists, engineers, and other community members with technical expertise. 3.3 Procedure Youth completed a pre-survey before the program. Youth also completed pre-course surveys of their experience in STEM, intention to pursue a STEM major or career, and questions for other motivation and engagement-related measures. At the beginning of the programs, youth were introduced to the study and the phones used for data collection related to the ESM. ESM data were collected two days each week, for three weeks (weeks 2-4 of the program). In all of the programs, about equal video-recording time was dedicated to classroom and field experiences. This detail is important because programs associated with one of the intermediaries rotated between classroom and field experience days, while the other used the first half of each day for one (i.e., classroom activities) or the other (i.e., field experience days). Each day, youth were signaled four times. These signals were at the same time for all of the youth within their program, but at different times between programs and between days within programs (with the constraint that no two signals could occur less than ten minutes apart). All of the programs were video-recorded by research team members. So that measures corresponding to the video and ESM data can be matched, videos include a signal from the video-recorder identifying the ESM signal to which youth responded at that point in the video. In a reflection of the dynamic conceptualization of engagement, this study uses data collected from ESM. As such, learners are prompted at regular intervals to respond to short questions about their perceptions of their engagement and its influencers. Though time-consuming to carry out, ESM can be a powerful measure that leverages the benefits of both observational and self-report measures, allowing for some ecological validity and the use of closed-form questionnaires amenable to quantitative analysis (Csikszentmihalyi &amp; Larson, 1987). Despite the logistic challenge of carrying out ESM in large studies, some scholars have referred to it as the “gold standard” for understanding individual’s subjective experience (Schwarz, Kahneman, &amp; Xu, 2009). This approach has the benefit of measuring learners’ engagement at a fine grain-size: Changes in the activity on learners’ engagement, even within the same session of the program, and changes in how influencers of engagement impact engagement and how the activity may relate to engagement, can be measured. 3.4 Data Sources and Measures Data sources consist of self-reported ESM measures of engagement and learners’ perceptions of themselves and the activity, pre-survey measures of youths’ interest, youths’ demographic information, and video-recordings of programs. 3.4.1 ESM measures of learners’ engagement and its conditions for the profiles Measures for engagement and its conditions were constructed from three ESM responses for engagement and two ESM responses for the conditions of engagement. The three variables for engagement are for learning (for the cognitive engagement construct), working hard (for behavioral engagement), and enjoying (for affective engagement). The variables for the conditions are for perceived challenge and perceived competence. All five items are used to construct profiles. Each of the ESM items consisted of the item text and the following four item response options, of which youth were directed to select one: Not at all (associated with the number 1 on the survey), A little (2), Somewhat (3), and Very Much (4), as presented in Table 3. Table 3.2: ESM measures for profiles Construct Item Cognitive engagement As you were signaled, were you learning anything or getting better at something? Behavioral engagement As you were signaled, how hard were you working? Affective engagement As you were signaled, did you enjoy what you are doing? Perceived challenge As you were signaled, how challenging was the main activity? Perceived competence As you were signaled, were you good at the main activity? 3.4.2 Survey measures of pre-interest Measures of youths’ pre-interest are used as youth-level influencers of the profiles. In particular, three items adapted from Vandell, Hall, O’Cadiz, and Karsh (2012) were used, with directions for youth to rate their agreement with the items’ text using the same scale as the ESM items: Not at all (associated with the number 1 on the survey), A little (2), Somewhat (3), and Very Much (4). The measure was constructed by taking the maximum value for the scales for the different content areas (science, mathematics, and engineering), so that the value for a youth whose response for the science scale was 2.5 and for the mathematics scale was 2.75 would be 2.5. The items are presented in Table 2. Table 3.3: Measure for pre-program interest in STEM Construct Items.text Individual interest in STEM I am interested in science / mathematics / engineering. At school, science / mathematics / engineering is fun I have always been fascinated by science / mathematics / engineering) 3.4.3 Codes from video-recordings for work with data Different aspects of work with data are identified from video-recordings with the use of a coding frame with five codesp for each of the aspects of work with data. These codes are developed from the STEM-Program Quality Assessment (STEM-PQA; Forum for Youth Investment, 2012), an assessment of quality programming in after school programs. For the PQA, raters contracted by American Institute of Research (AIR) were trained in the use of the PQA measure during February, 2017. Raters completed a four-hour online training module on the overall PQA tool and then attended an in-person two-day training led by a trainer from the David P. Weikart Center for Youth Program Quality, the tool’s publisher, where they learned about the instrument, trained on its use, and then established inter-rater reliability with a master coder. For the STEM-PQA, three of the same raters contracted by AIR to overall PQA measure used the STEM-PQA scored one video segment, for which there were no disagreements on scoring across the four raters on any items. If any of the raters encountered into a situation that was difficult to score, they would all discuss the issue by telephone or more often by email after viewing the video in question and reach a consensus on how to score the specific item. Programs were divided up among all of the raters, so raters coded some of the videos for all of the programs. Specific details on how the measure aligns with the original STEM-PQA on which this measure is based are presented in the appendix. Table 3.4: Coding Frame for Work With Data Code Description Asking questions or defining problems Discussing and exploring topics to investigate and pose questions. Making observations Watching and noticing what is happening with respect to the phenomena or problem being investigated. Generating data Figuring out how or why to inscribe an observation as data and generating coding frames or measurement tools. Data modeling Understanding and explaining phenomena using models of the data that account for variability or uncertainty. Interpreting and communicating findings Discussing and sharing and presenting findings. 3.4.4 Demographic variables used In addition to the measures described in this section, demographic information for youths’ gender and their racial and ethnic group are used to construct demographic variables for gender and membership in an under-represented (in STEM) group; membership in an under-represented group are identified on the basis of youths’ racial and ethnic group being Hispanic, African American, Asian or Pacific Islanders, or native American. 3.5 Data Analysis The steps for both preliminary and the primary analyses are described in this section. 3.5.1 Preliminary analyses First-order Pearson correlations and the frequency, range, mean, and standard deviations are first examined for all variables. In addition, the frequency of the codes for aspects of work with data, and the numbers of responses by youth, program, and moment are examined. 3.5.2 Analysis for Research Question #1 (on the frequency and nature of work with data) There are two primary steps taken to answer this question, one more quantitative in nature and one more qualitative. Specifically, first, the frequency of the codes for the individual aspects of work with data from the STEM PQA measure of work with data (described above in the measures) are calculated. Note that this coding frame was adapted from the existing STEM PQA measure. Also note that this coding frame was for instructional support for work with data. For these two reasons, while the codes for work with data align with the conceptual framework for work with data (see Figure 1 and its description), they focus on general aspects of STEM learning; part of this general focus is work with data. Then, to present a more in-depth description of work with data in the context of summer STEM programs, all of the segments were coded using an open-ended, qualtitative approach. To qualitatively code the data, three research assistants were trained for approximately eight hours over four meetings. Then, each research assistant coded all of the segments associated with one of the videos. The guiding questions for the qualitative coding were as follows: What are youth doing? When asking questions or defining problems is coded, what, if any are the questions or problems? Who is asking the question (i.e teacher or student) When making observations is coded, what are youth doing? When generating data is coded, how, if they are, are youth collecting or recording data? When analyzing or modeling data is coded, what analysis are they doing, or what models are they using? Are they talking about variability or uncertainty? If so, how? When interpreting and communicating findings is coded, what are youth interpreting or how are they communicating? Is there a phenomenon being studied or a problem being investigated? If so, what is the phenomenon being studied or problem being investigated? Is the activity related to something youth have previously done or learned about? If so, how? Is the activity related to something youth will do or will learn about? If so, how? Is the activity collaborative? If so, what is happening? Is anything else of interest or that is noteworthy going on? Two coders coded every segment. This coding took around 75 hours of coding by the research assistants. After coding all of the segments for each program, the coders and I met to discuss potential issues that emerged throughout the coding, and to clarify how they applied the coding frame (so the coders and I met nine times during the process to discuss the coding). I then read through all of the codes for all of the segments, and made notes associated with each of the five aspects of work with data (i.e., asking questions, making observations, and the other aspects). These notes focused on whether and in what ways there appeared to be alignment between the codes for work with data (from the PQA) and the conceptual framework for work with data. I used these notes to write detailed descriptions of each of the aspects of work with data. 3.5.3 Analysis for Research Question #2 (what profiles of engagement emerge) 3.5.3.1 Background information on Latent Profile Analysis (LPA) LPA can be used to identify common patterns in learners’ ESM responses as part of a person-oriented analysis to construct the profiles. These profiles make it possible to analyze the multivariate data collected on engagement in a way that balances the parsimony of a single model for all learners with a recognition of individual differences in how learners’ experience each of the dimensions of engagement together at the same time. A key benefit of the use of LPA, in addition to likelihood estimation-based fit indices, is probabilities of an observation being a member of a cluster (unlike in cluster analysis). To answer this question, profiles are constructed with the five self-reported ESM measures for cognitive, behavioral, and affective engagement and perceptions of challenge and competence. Answers to this question will help to understand how the aspects of engagement relate to both one another and to key conditions that influence engagement. To create the profiles, a mixture modeling approach is carried out. Mixture modeling is an approach for identifying distinct distributions, or mixtures of distributions, of measured variables. A type of mixture modeling within a latent variable modeling framework, Latent Profile Analysis (LPA; Harring &amp; Hodis, 2016; Muthen, 2004) is used in this study. LPA allows for capturing the multidimensional nature of engagement and its conditions, as is the goal of the analysis for the present study. 3.5.3.2 Selecting a model on the basis of fit indices and other techniques As part of LPA, different models that determine whether and how different parameters (i.e., means, variances, and covariances) are estimated. In addition, the number of profiles to estimate must be provided by the analyst. Determining the number of profiles depends on fit statistics (such as information criteria and the entropy statistic) as well as concerns of parsimony and interpretability. In general, the approach to choosing the model is similar to choosing the number of profiles, requiring deciding on the basis of evidence from multiple sources. The models are described in-depth in the appendix. The number of profiles is determined on the basis of the log-likelihood and bootstrapped likelihood ratio test, entropy, Akaike Information Criteria, and Bayesian Information Criteria statistics, as well as concerns of parsimony and interpretability. First, I examined a wide range of model types (i.e., the parameterization of the model, with the six options described in the appendix as candidates) and the numbers of profiles. These roughly became more complex, with additional parameters estimated, as the number for the model type increases from one to six. This step is taken to select candidate solutions to investigate in more detail. In order to carry out this analysis, I followed guidelines recommended by the developers of the MPlus software (Asparouhov &amp; Muthen, 2012; Muthen &amp; Muthen, 2017) as well as those making recommendations about its use (Geiser, 2012). To select a model for use in subsequent analyses, the log-likelihood (LL), a range of information criteria (AIC, BIC, sample adjusted BIC [SABIC], consistent AIC [CAIC]), statistics about the quality of the profile assignments (entropy, which represents the mean posterior probability), statistical tests (Vu-Lo-Mendell-Rubin LRT [VLMR], Lo-Mendell-Rubin LRT [LMR], and the bootstrapped LRT [BLRT]), and concerns of interpretability and parsimony are used. Past research suggests that BIC, CAIC, SABIC, and BLRT are most helpful for selecting the correct number of profiles (Nylund, Asparouhov, &amp; Muthen, 2007). For the entropy statistic, higher values are considered better, though scholars have suggested that the entropy statistic not be used for model selection (Lubke &amp; Muthen, 2007). Of the three statistical tests, the bootstrapped is considered to be the best indicator of which of two models, one nested (with certain parameters fixed to 0) within the other, fits better, but it is also the most computationally-intensive to carry out (Asparouhov &amp; Muthen, 2012). 3.5.4 Statistical software developed The MPlus software is used to carry out LPA as part of this study. In order to more flexibly carry out LPA, an open-source tool, tidyLPA (Rosenberg, Schmidt, &amp; Beymer, ), was developed. This tool provides interfaces to both the MPlus software and to the open-source mclust software. In addition to being used as part of this study, this package is provided free of use to other analysts as the first tool dedicated to carrying out LPA as part of the R software. More details on the statistical software developed and included in the Appendix. 3.5.5 Analysis for Research Question #3 (how work with data relates to engagement) Broadly, this question is focused on how work with data, as coded from video-recordings of the programs, relates to the profiles. For the primary results for this question, linear models that account for the cross-classification of the moment and youth are used and for the “nesting” of both within each of the nine programs are used. For the outcome (y variable), the probability of a response belonging to the profile is used; thus, there are six models, for each of the six profiles, for each specification of the predictor (x) variables. To answer this question, on how well the aspects of work with data predict the profiles, first, indicators for activities coded for any of the five aspects of work with data are used to predict each profile. The lme4 R package (Bates, Martin, Bolker, &amp; Walker, 2015) is used. All of the models for this and research question #4 use random effects for learner, momentary, and program effects. Learner and moment can be considered to be crossed with both nested within the program. Because the outcome from LPA is not a hard classification (i.e., an observation is in a profile—or not) but a probability, the outcome is treated as a continuous variable. First, null models with only the random parts (i.e., random learner, momentary, and program effects) are specified. Then, the predictors are added to the model with the main effects of the variables added. 3.5.6 Analysis for Research Question #4 (how youth characteristics relate to engagement) Research question #4 is focused on how the relationships of work with data differ on the basis of pre-program interest and other youth characteristics–their gender and URM status. Like for the previous research question, models that account for the cross-classification of the moment and the youth are used. 3.6 Sensitivity Analysis For observational studies, such as the present study, it can be important to determine how robust an inference is to alternative explanations. One approach to addressing this is sensitivity analysis, which involves quantifying the amount of bias that would be needed to invalidate an inference (hypothetically, this bias might be due to omitted or confounding variables, measurement, missing data, etc.). Using the approach described in Frank, Maroulis, Duong, and Kelcey (2013), I carried out sensitivity analysis for inferences made relative to key findings. I used the R package konfound (Rosenberg, Xu, &amp; Frank, 2018). The result, and what is used to interpret and contextualize findings, is a numeric value for each effect that indicates the proportion of the estimate that would have to be biased in order to invalidate the inference: higher values indicate more robust estimates in that the inferences would still hold even if there were substantial bias in the estimate. "],
["results.html", "Chapter 4 Results 4.1 Results from the preliminary analysis 4.2 Results for Research Question #1 4.3 Results for Research Question #2: What profiles of youth engagement and its conditions emerge from experiential data collected in the programs? 4.4 Results for Research Question #3: How do data practices relate to youth engagement in the programs? 4.5 Results for Research Question #4: How do youth characteristics relate to their engagement in summer STEM programs?", " Chapter 4 Results In this section, I present the results associated with the preliminary analysis and the four research questions. 4.1 Results from the preliminary analysis 4.1.1 Descriptive statistics for study variables First, descriptive statistics for all of the study variables–overall pre-interest, the five variables that are used to estimate the profiles, are presented. Overall pre-interest and the variables used to estimate the profiles are presented first. 4.1.2 Correlations among study variables Next, correlations between individual aspects of work with data (and the composite) and the variables that are used to create the profiles are presented. These correlations suggest that the aspects of work with data are not related to the aspects of work with data to a large degree, which is not surprising given the small ICC values for the momentary level, as the aspects of work with data are associated with this level. Most noteworthy is the very small correlations between the aspects of work with data and the profiles; these correlations range (in absolute values) from .00 to .05. Only the relations between communicating and profile six are statistically significant. The composite variable was correlated with the profiles from (in absolute values) 0.002 to 0.035, none statistically significant. The aspects of work with data are modestly correlated with one another, with correlations ranging from .16 to .46; all were significant. 4.2 Results for Research Question #1 4.2.1 Frequency of work with data From the coding with the STEM-PQA, work with data appears common. Out of the 248 segments, 12 were codeable for work with data; for these, issues with the video-recordings were the primary source of the missing data; in these cases, youth may have still replied to signals, but it was not possible to code for work with data associated with these responses. We can also examine the breakdown by program, which shows that, descriptively, there exists substantial variability. Table 4.1: Proportion of signals for which each of the aspects of work with data was present Aspect of Work With Data Proportion N Asking Questions 0.389 92 Making Observations 0.258 61 Generating Data 0.453 107 Data Modeling 0.288 68 Communicating Findings 0.470 111 Table 4.1: Proportion of signals for which each of the aspects of work with data was present by program Variable Asking Observing Generating Modeling Communicating Total Segments Island Explorers 0.312 0.375 0.438 0.250 0.375 16 The Ecosphere 0.625 0.417 0.500 0.292 0.500 24 Zoology Partners 0.250 0.167 0.125 0.167 0.208 24 Marine Investigators 0.458 0.333 0.250 0.375 0.542 24 Comunidad de Aprendizaje 0.327 0.182 0.400 0.273 0.327 55 Jefferson House 0.167 0.083 0.542 0.458 0.750 24 Uptown Architecture 0.375 0.208 0.708 0.167 0.292 24 Building Mania 0.333 0.208 0.375 0.333 0.500 24 Adventures in Mathematics 0.583 0.292 0.542 0.458 0.750 24 4.2.2 Nature of work with data Each of the segments of video was coded. This coding resulted in approximately three to four sentence notes from each of two raters for every segment. I then reviewed these notes with the aim to identify themes based on enriching and better understanding the aspects of work with data. 4.2.2.1 Asking questions or identifying problems Asking questions occurred in 92 of the segments (as coded by the PQA). In the 92 segments that were coded with asking questions, the open-ended, in-depth analysis identified 36 segments that were focused on asking questions in ways that clearly aligned with the conceptual framework for work with data. Qualitative coding showed that this aspect of work with data was highly variable. When the qualitative coding revealed this code to be present, it was often when youth were trying to better understand the phenomenon or problem they were investigating. For example, in a segment during the Ecosphere program in which youth constructed inclined tables to study how water moved throughout the ecosystem, the youth activity leader prompted youth to generate hypotheses of what would happen when water was poured onto the table, before pouring the water. Other segments showed that there were also many segments for which the PQA codes suggested asking questions would be present, but the in-depth analysis revealed were not always always focused on predicting, conjecturing, or hypothesizing. In these cases, the code was applied to instances in which the youth were asking generic questions (i.e., about how they do an assignment) or when the instructor was asking youth questions (i.e., math-related questions). For example, in the Marine Investigators program, youth visited a water treatment site, and were provided opportunities to ask questions about what they saw. 4.2.2.2 Making observations Making observations occurred in 57 of the segments (as coded by the PQA), 49 which the open-ended coding revealed were clearly aligned with the coding frame, indicating that this code was used in ways that were close to how this aspect of work with data was conceptualized. Many of the times, this code was applied in conjunction with observing phenomenon in the field, or, in the case of engineering-focused programs, noticing what was going on with a particular design. For example, in the Building Mania program, youth constructed Rube Goldberg machines; youth were prompted by the activity leaders to notice how changes in their design led to differences in how far objects were launched or rolled. When qualitative coders determined this was not present, it was usually due to the observations being not of phenomena, but of the instructor. For example, in the Adventures in Mathematics program, instances in which youth observed other youth or the youth activity leader solving a mathematics problem was often coded as involving making observations. 4.2.2.3 Generating data Generating data occurred in 102 segments (as coded by the PQA), 48 of which the in-depth analysis showed were aligned with the coding frame. When present based on qualitative codes, youth were writing down observations, recording information from experiments, or recording the results of a trial (in engineering contexts). For example, in the Marine Investigators program, youth collected pieces of recyclable plastic, bringing them back to the classroom and counting them for each location they were collected. When the PQA code indicated that work with data was present, but the subsequent analysis indicated that this practice was not evident, this was often youth were writing down what the youth activity leader was saying, or was focused on collecting specimens, but not writing them down, entering them into a spreadsheet, or otherwise recording them as data. For example, again in the Marine Investigators program, youth used nets to collect saltwater organisms, which they then transported in buckets back to the classroom setting for subsequent analysis. While these specimens could be considered as data, at least in the segment described, youth did not inscribe notes or any other observations on the specimens they were collecting, and so data was not generated (at this stage). 4.2.2.4 Data modeling Data modeling occurred in 68 segments (as coded by the PQA), 49 which were aligned with the coding frame. Like making observations, for data modeling, there was a high degree of alignment between the PQA codes and what the open-ended coding. When this aspect of work with data was found to be present on the basis of the qualitative coding, youth used mathematical models. For example, in the Comunidad de Aprendizaje program, youth accessed nationally-representative data and were tasked to solve problems, like finding out what percentage of people engage in particular activities, like donating to charity. When the PQA code was present but data modeling was not done in a way aligned with the conceptual framework for work with data, the youth activity leader, rather than students, was doing the modeling, or the model was not one that could generate data. For example, in the Marine Investigators program, a youth activity leader used a plush toy seal designed to teach youth about anatomy and the dangers of aquatic mammals consuming trash and recyclables. 4.2.2.5 Interpreting and communicating findings Codes for interpreting and communicating were present in 103 segments (as coded by the PQA), in-depth, open-ended coding revealed 49 were aligned with the coding frame. When the qualitative coding revealed this aspect of work with data to be present, youth were often sharing what they found from an investigation or the results of using the product they designed. For example, in the Comunidad de Aprendizaje program, youth participated in an activity designed to support their thinking about creating a product to bring to market; the youth activity leaders described this as being akin to the television show the Shark Tank. In one segment, the youth activity leader asks youth to think of an idea that would make an investor willing to invest in; students shared their ideas, describing what their ideas was, why it was a good idea, how much they could sell it for, and what their profit would be, while fielding questions from youth activity leaders and their peers. Interpreting and communicating findings was also commonly present in segments in which youth were debating the findings of an investigation, such as the results of calculations for the amount of recyclables entering waterways (in Marine Investigators). When not present, which was common, youth were communicating about topics other than the results of an investigation or design process, such as trying to find out the answer to a question posed by the youth activity leader, or the youth activity leader was who was doing the interpreting and communicating. For example, in the Adventures in Mathematics program, the youth activity leader helped youth to solve problems on a worksheet, asking guiding questions to help youth start to solve problems on their own. 4.2.3 Summary of Findings for Research Question #1 This suggests that differences in how work with data was conceptualized and operationalized may lead, in some cases, to codes that do not reflect work with data accurately, and can lead to some findings that seem unexpected given what we know about the potential for work with data to be engaging to youth. 4.3 Results for Research Question #2: What profiles of youth engagement and its conditions emerge from experiential data collected in the programs? on the basis of the selection criteria you used (you can name them again if you wish), the six profile solution with varying means, equal variances and covariances fixed to 0 emerged as the best fit of the data. This was on the basis of fit statistics, statistical tests, and concerns of interpretability and parsimony. The model demonstrated superior fit on the basis of the information criteria (AIC and BIC) and on the basis of the measure of classification accuracy (entropy). A seven profile solution with the same specifications regarding means, variances and covariances was also a similarly good fit (and is presented in the Appendix), but the 6 profile solution was ultimately chosen on the basis of parsimony and interpretability. For the selected model, presented below, the raw data and the data that are centered to have a mean equal to 0 and a standard deviation of 1 (thus, the y-axis on each of the plots is labeled “Z-score”). This solution is characterized by: A full profile, profile 6 A universally low profile, profile 2 A all moderate profile, profile 5–and, like, the model 1, six profile solution–with moderate levels of affective engagement An only behaviorally engaged profile, profile 1, with moderate levels of behavioral engagement, very low affective engagement, and moderately (low) levels of cognitive engagement and challenge and competence An only affectively engaged profile, profile 4, with moderate levels of affective engagement, low levels of behavioral engagement, and moderately (low) levels of cognitive engagement and challenge and competence An engaged and competent but not challenged profile, profile 3, characterized by high levels of each of the three dimensions of engagement and of competence, but with low levels of challenge The number of observations associated with each of the profiles is somewhat balanced, with the universally low profile with the largest number of observations (n = 667), followed by the all moderate profile (n = 638). Each of the other four profiles were associated with 300 to 400 observations. 4.3.1 Sources of variability in momentary profiles 4.3.1.1 Null models The null models presented in the table provide insight into the levels at which predictors may be able to explain the outcome. For all six profiles, the ICCs at the program level were very small, from 0.00 to 0.023. This suggests that very little variability can be explained simply by the program. For the momentary level, the ICCs were also very small, ranging from 0.004 to 0.011. Finally, the youth-level ICCs ranged from .099 to .427. Looking across these values, considering variability at the program, momentary, and youth levels, most of the explained variability in the responses is associated with youth; the program and momentary levels were associated with very small values, suggesting that variables at these levels have minimal variability to explain. In turn, this suggests that these variables, including those for work with data, may not have strong effects in terms of their relations with the profiles. In terms of specific ICCs at the youth level, the value for the youth-level ICC was highest for the full profile, suggesting that some youth have a strong tendency to be fully engaged (possibly due to their initial interest or other individual characteristics and differences). The other profile characterized by a consistent pattern across all of the variables–the universally low profile–had a modest ICC, .265. Finally, a large amount of variability is associated with the residual (variance that is not associated with the program, momentary, or youth levels). This suggests that there is wide variation in students’ responses that may not be readily explained or predicted. 4.3.1.2 Variability in momentary profiles across youth Variability in terms of the profiles youth report can also be considered. These show that a 4.3.2 Summary of research question #2 findings After reviewing a wide range of models, a relatively simple model (model 1) with six profiles was selected for use in subsequent analyses. This model has momentary profiles of engagement and its conditions characterized by both varying levels on the dimensions of engagement and perceptions of challenge and competence. In addition, the number of observations across the profiles is relatively balanced. 4.4 Results for Research Question #3: How do data practices relate to youth engagement in the programs? For this question, models with the aspects of work with data both separate from and together with the youth characteristics were fit. The models only with the aspects of work with data yielded very similar results; see the appendix. The models with both together were also used as part of research question #4, though they are presented here (and interpreted in the sections for both results). –&gt; 4.4.1 Summary of findings for research question #3 When looking across findings, we find few relations between work with data and the profiles, though there were notable effects of modeling and generating data, though they were small effects (i.e., when students are doing this, they are around 3% more likely to be responding in a way associated with the full profile). Broadly, further explanations and investigations of these effects –focusing on the characteristics of work with data in the context of summer STEM programs and how this support is measured in terms of codes from the video–are the focus on research question #4 and are discussed in the next chapter. Moreover, these findings are deepened in subsequent analyses for research questions #4. 4.5 Results for Research Question #4: How do youth characteristics relate to their engagement in summer STEM programs? For this question, models with the youth characteristics separate from and together with the aspects of work with data were fit. Like for the results for the previous question, the models only with the youth characteristics yielded very similar results; see the appendix. Thus, the model presented in the previous section with both youth characteristics and the aspects of work with data are interpreted here. 4.5.1 Pre-interest, gender, and URM status and the aspects work with data seperately These results show similar patterns to the earlier models.Like in the models with only pre-interest and the other individual characteristics alone (and like in the model with the individual aspects), pre-interest is related to the only behavioral profile (\\(\\beta\\) = 0.033 (0.018), p = .033). Being female is again related but not to a level that it meets the criteria for statistical significance (\\(\\beta\\) = 0.064 (0.041), p = .059). With the interactions added, the composite was no significantly related to the only behavioral profile (\\(\\beta\\) = 0.016 (0.016), p = .156) to a similar extent and with similar robustness as found in the separate model. One interaction, between pre-interest and being female, had a significant effect upon the profile for full engagement (\\(\\beta\\) = 0.012 (0.006), p = .026). However, only 1.953% of the effect would need to be due to bias to invalidate the inference. The R2 values, relative to the models with only random effects (the null models), increased from .003 to .028, again suggesting small effects of the predictors upon the profiles. Note that “Comp.” refers to the data modeling composite. 4.5.2 Pre-interest, gender, and URM status interactions work with the codes for work with data Here, interactions for the aspects of work with data that were statistically significant are considered. 4.5.3 Summary of findings for research question #4 When looking across findings, we find minimal relations between pre-interest and other individual characteristics. ## Error in mtcars %&gt;% select(hp) %&gt;% names(ds4) &lt;- names(oo) &lt;- c(&quot;Profile&quot;, : could not find function &quot;%&gt;%&lt;-&quot; In particular, we found that pre-interest was related to the engaged and competent but not challenged profile to a modest extent. Being female did not demonstrate statistically significant relations with the univerally low profile, though some moderately-sized effects that were nearly statistically significant were observed and interpreted in terms of how much bias would need to be reduced (or how much the larger the effect would need to be) in order for this relation to be statistically significant. Note that the positive pre-interest coefficient is the estimate from the model with the interaction (without the interaction, the coefficient was also statistically significant and was 0.039). These results, like those for research question #2, are similar to those obtained when the model 1 type, seven profile solution is used for the outcome variables. There were few interactive effects observed; the magnitude of the effect of the composite and gender interaction was small (as were the changes in the R2 value as a consequence of adding this interaction), and the effect appears to not be highly robust to potential sources of bias. Like for research question #2, reasons for why this may be are explored in the next chapter. "],
["discussion.html", "Chapter 5 Discussion 5.1 Key Findings 5.2 Limitations of the Study and Recommendations for Future Research 5.3 Implications for Practice 5.4 Conclusion", " Chapter 5 Discussion 5.1 Key Findings 5.1.1 Key findings for research question #1 (on the frequency and nature of work with data) In terms of the frequency and nature of work with data, work with data was found to be common in the summer STEM programs that made the context for this study, with frequencies ranging from .258 (making observations) to .470 (communicating findings) of the programs, with any aspect being present in [add] of the program. Data modeling was, like making observations, less common, whereas asking questions and generating data, like communicating findings, were relatively more common. This suggests that work with data is, in general, common across STEM programs, as expected based on past research (Lee &amp; Wilkerson, in press) and the design and goals of such programs (Dabney et al., 2012; Elam et al., 2012; add). Subsequent qualitative showed that asking questions, generating data, and interpreting and communicating findings, the three aspects that were more frequent in the programs, also were the most inconsistent with how work with data was conceptualized in this study. This suggests that while work with data is somewhat common, more veridical forms of it are somewhat less common, occurring in around 25% of the programs’ time. While descriptive in nature, these results present the first insight that I am aware of of the extent of work with data in STEM enrichment programs. They suggest that, as past scholarship (National Research Council, 2009, 2012) can provide a context for youth to be involved in the type of scientific and engineering practices-focused activities that can be particularly powerful for youth (and students) in terms of their learning. 5.1.2 Key findings for research question #2 (what profiles of engagement emerge) Six profiles of engagement and its conditions were identified. These profiles included those that were strongly negative (Universally low) and strongly positive (Full), as well as those characterized by different levels of engagement (Only behavioral and Only affective) and by different levels of the conditions of engagement (Engaged and Competent but not Challenged). An All moderate profile was also identified. The profiles suggest that the experiences of youth in summer STEM programs are variable and that the use of ESM can aid in the study of youths’ engagement. Little research has examined profiles of engagement, though Schmidt et al. (2018) examined profiles of momentary engagement, constructed from items for cognitive, behavioral, and affective engagement (but not perceptions of challenge and competence), and found six profiles, some of which partially overlap with those found in the present study. In particular, on the basis of the items shared between the studies, a Universally low, All moderate, and Full profile were found in both studies. However, as these profiles are characterized by the (uniform) level across all of the variables, this is only limited evidence for the presence of these profiles in the larger population of youth engaged in science and STEM-related learning activities. 5.1.3 Key findings for research question #3 (how work with data relates to engagement) Before relations between the groups of “predictor” variables, work with data and youth characteristics, and the profiles, were explored, the amount of variability that could be explained at the program, youth, and momentary levels were explored. The amount of variability that could be explained at the program and momentary level was small (no larger for any profile than .023, and as low as .00 at the program level and .004 at the momentary level for some profiles), while the amount of variability that could be explained at the youth level was moderate to large (between .099 and .427). This suggests that while there is variability in the composition of the profiles that were identified, youth characteristics–their pre-program thoughts, beliefs, and characteristics and their inclination to engage in particular ways throughout the program–largely explains the prevalence of the profiles. This also suggests that what youth do during the programs, and the design and implementation of the programs themselves, have little to do with how youth engage in them. This implies that even the strongest predictor variables at these (momentary and program) levels would likely not explain much variability in the profiles (though this is not always the case, as there are cases in which adding variables at one level can increase the amount of variability that can be explained at another; Gelman &amp; Hill, 2007). In line with what the preliminary analysis of the amount of variability that could be explained at the youth, momentary, and program levels, relations between work with data were largely not found, though some small, statistically significant relations were identified. Importantly, both generating and modeling data were found to be positively related to the Full profile, suggesting that when youth are involved in these practices, then they are more likely to report high levels of cognitive, behavioral, and affective engagement, and high perceptions of competence and challenge. The effect of data modeling was more robust than that for generating data, the latter which should be interpreted with caution. In short, this suggests that these activities are beneficial to youths’ engagement. Both communicating and interpreting findings and the composite measure for work with data were positively related to the Only behavioral profile and these findings were fairly robust. This profile may indicate that students are experiencing a routine engagement (and not particularly adaptive) when they are communicating findings and being involved in work with data in general. As there is no research on how work with data relates to youths’ engagement, the findings associated with this research question provide some, albeit limited, evidence (and directions for future research) for how some aspects of work with data relate to youths’ engagement. 5.1.4 Key findings for research question #4 (how youth characteristics relate to engagement) Not as much in line with expectations given the preliminary analysis, relations between youth characteristics and the profiles were found to be small. In this way, these small relations were similar (in magnitude) to those between work with data and the profiles. Youth with higher pre-program interest were more likely to be Engaged and competent but not challenged, suggesting that youth with higher interest in STEM are inclined to be highly engaged and good at what they are doing, but are not challenged by the activities they experience. This could be a function of the relationship between youths’ interest and their competence before the program, which are often strongly related ([add]); these youth, as a result of their higher interest and competence, need more challenging activities to be more fully engaged. This effect was fairly robust. The interaction with gender and the work with data composite revealed a positive relationship with Full engagement, suggesting that the more that female youth work with data, the more likely they are to be positively engaged. However, sensitivity analysis revealed that this effect was not very robust, which, along with its small magnitude, suggests that it should be interpreted with some caution. Finding that female youth who are engaged in work with data are more likely to be fully engaged is important, given that past research has suggested that female students are less likely to be engaged in STEM classes but we have limited information about what types of instruction may best support female students to be engaged and successful (e.g., Patall et al., 2017). 5.2 Limitations of the Study and Recommendations for Future Research This study examines youths’ engagement as an outcome. Accordingly, outcomes from engaging, such as the products of neither youths’ work or the specific cognitive capabilities they develop through their participation, are not the focus. Thus, while some findings about how work with data and youth characteristics were found to be associated with different profiles of engagement and its conditions, we do not have an understanding of how engaging in more or less adaptive ways relates to these outcomes. Examining how work with data and engagement relate to key learning, motivational, and future goals and plans-related outcomes is a topic for future research. Another limitation concerns the context of the study, summer STEM programs. While the programs that were involved in the study have many affordances for work with data and for being highly engaging for youth, they have some limitations, too, particularly with respect to support work with data. Importantly, these were not programs explicitly designed to support work with data; while such contexts are being developed, they are not yet widespread. Learning environments that deliberately support work with data over a long period may demonstrate different patterns of engagement than those examined in this study because of the focus on and sequencing of the aspects of work with data, which may make it more (or less) cognitively, behaviorally, or affectively engaging than is determined in this study. As Miller, Manz, Russ, Stroupe, and Berland (2018) highlight, truly engaging STEM activities are not easily come by; they require students to take ownership over and to make decisions about their explorations or designs. Thus, future research may study work with data in contexts designed to support it. A key part of this future research may be studying both work with data and how work with data is supported (most importantly by the instructor but also by the curriculum and technological tools). A related limitation is that the programs that were the focus of this study were model programs, or those based on characteristics of exemplary STEM enrichment programs. As a result, engagement may be different in other STEM enrichment programs depending on characteristics of the programs and their activities, and findings from this study should be interpreted in terms of programs that share similar characteristics. A potential issue concerns the analytic approach. As noted above, the profiles demonstrated very little variability at the program and momentary level, suggesting that factors at this level would likely not strongly predict the profiles. This could be a function of the use of profiles and the specific variables selected. It may also be the result of the outcome (engagement and its conditions) selected. Other analytic approaches can be carried out to determine the viability of the profiles approach and use of the items for engagement and its conditions for understanding work with data. A final limitation concerns the measures used. In particular, the qualitative coding revealed alignment but also discrepancies between work with data as determined from the PQA codes and the conceptual framework for work with data. While these issues were small, they suggest that the coding frame for work with data is a limitation of the present study. While these are important limitations, it is worth noting that the modeling strategy (with the mixed effects models) in inherently a conservative approach. Thus, while the findings detected are small, they can be considered to be trustworthy on the basis of the way the ESM data were analyzed. This trustworthiness is enhanced by the use of sensitivity analysis, which showed how much of the effects could be due to bias for them to be invalidated. 5.3 Implications for Practice 5.3.1 Engage youth in key aspects of work with data While limited evidence, this study suggests that generating and modeling data in particular may be beneficial in terms of engaging youth. Generating data in particular may be a key practice because it involves making work with data concrete; as Lehrer and Schauble (2015) describe, recording data in the form of “inscriptions” can serve as commitments that learners make (in terms of what data were chosen to be collected and recorded). This implication, in particular, should be interpreted with caution, however, given the very small magnitude of the effect. Similarly, data modeling has been described as the central scientific and engineering practice (Schwarz et al., 2009; Lehrer &amp; Schauble, 2015; Weisberg, 2012), and its relations with full engagement provides some actionable evidence for its importance in the context of summer STEM programs. Practically, youth activity leaders (in summer STEM and other STEM enrichment contexts) and teachers (in formal learning environments) can best include the beneficial practices of generating and modeling data not in isolation, but rather through involving learners in complete cycles of investigation. This aligns with both foundational and contemporary research on work with data in education (Berland et al., 2018; McNeill &amp; Berland, 2017; Hancock et al., 1992; Lee &amp; Wilkerson, 2018). Recent curricular reform efforts also suggest that the best way to engage learners in particular practices is through the process of identifying a question or problem, marshaling sources of data that can be used to figure out what is happening, and developing model-based explanations that are then communicated (or even used in an argument; National Governors Association, 2013; National Research Council, 2012; NGSS Lead States, 2013). With respect to work with data in particular, youth activity leaders and teachers can use the findings from this study as a starting point to consider how engaging in work with data may also prepare learners to think of, understand, and take action based on data in their day-to-day lives. Many questions or problems learners face may involve data that can be meaningfully incorporated into engaging learning activities. 5.3.2 Leverage the affordances of summer STEM and other STEM enrichment programs Another implication for practice concerns the affordances (and constraints) of summer STEM and other STEM enrichment programs. One affordance of these programs relevant to these informal and to K-12 learning environments concerns selecting activities that are engaging to learners. For example, in the Marine Investigators, youth participated in activities designed to help them understand water quality in their ecosystem. Youth collected trash from sites around their community (in different “districts”) and then brought the trash and recyclable plastic back to the classroom. Then, the youth activity leaders asked students to figure out how much plastic enters local waterways. As a part of this activity, youth activity leaders asked students not only to determine the quantity of trash that entered the waterways, but asked students about why they used math in particular ways (i.e., adding the quantity of trash collected and then extrapolating from this quantity to the amount from across the entire city over the course of the year). This appeared to be a powerful activity, one that was coded as involving all five aspects of work with data according to the measures for instructional support for work with data; this type of activity seemed to suggest that instructional support for work with data may impact youth’s engagement. Another affordance concerned the relevance of the program to youth’s lives. For example, in the Building Mania program, youth are involved in engineering design (i.e., identifying a problem and designing a solution), particularly around the use of simple machines. In a day in the classroom setting, youth are creating, testing, and revising catapults. In the next day, youth visit an area University, and are led in a discussion by a physicist who works with particle colliders. In this example, the expertise of the physicist, who explicitly mentions the benefits of engaging in the engineering design process and the importance of combining engineering to addressing problems (such as mitigating the damage of earthquakes), seems to be highly relevant to what youth are doing in their class. In these two days of class, youth are engaged in different aspects of work with data as indicated by the codes for instructional support for work with data (collecting data on the efficacy of their designs in the classroom day, and asking questions in the subsequent day, particularly); these seem to suggest, like the example of work work with data from the Marine Investigators program, affordances of work with data for summer STEM programs. 5.3.3 Consider the constraints of summer STEM and other STEM enrichment programs There are also constraints to summer STEM and other STEM enrichment programs. For example, youth activity leaders faced challenges linking activities as part of a complete cycle of investigation. For example, in the Ecosphere program, youth collected water samples in the field. They then brought these samples to the classroom and tested the water, involving students in both collecting and, to a degree, generating data (by noting the pH levels of the water). However, later in the day, youth created a small-scale model (with inclined trays of dirt, rocks, and plants) of an ecosystem, in which they added food coloring to determine the impacts of chemicals and acid rain. Youth then interpreted and discussed these findings, but did not connect the discussion to the water samples youth collected and tested earlier. This activity presented an opportunity for deeper engagement, in which youth could interpret and communicate findings related to the state of the water in their ecosystem, but, instead, it was potentially limiting in terms of youth’s engagement in work with data. Another constraint related to the challenge of linking activities concerned what the programs focused on. For example, the mathematics-focused programs, such as the Adventures in Mathematics program, the youth activity leaders recognizing that youth had difficulty solving equations, used duct tape and a “hippity hoppity”, building on an earlier activity in which youth considered what constituted a rate, on how many “hops” it would take someone to move from one end of the line of duct tape to the other; the youth activity leader than asked youth to consider how far they could move in one hop and to consider how they could find out many hops it would take, using a mathematical equation. In this activity, youth were supported to approach mathematics problem-solving in creative ways. However, apart from data modeling, other aspects of work with data were rarely present, and most of the data that youth worked with was provided by the teacher or considered in the abstract. Programs focused on science or engineering, similarly, emphasized other aspects of work with data: The science-focused programs (Island Explorers, The Ecosphere, and Marine Investigators) all emphasized collecting and generating data, but data, particularly the data collected or generated, was rarely modeled or interpreted. In the engineering-focused programs (Uptown Architecture, Crazy Machines, and Dorchester House, youth often collected data that resulted from their engineering designs, and communicated and interpreted their findings, but, did not generate data, and, accordingly, (and like the science-focused programs) did not model data as a regular part of their activities. This finding suggests that while work with data may have been common overall, different aspects of instructional support for work with data were emphasized to different degrees based on the focus of the program. 5.4 Conclusion Each of the disciplines that contribute to STEM learning involve work with data and how youth and students work with data in engaging ways is a concern of researchers and practitioners. While past research has focused on what practices learners do when working with data, or specific conceptual outcomes, little research has considered youths’ experience of working with data. In this study, engagement was used as a lens to understand the experience of youth working with data in the context of nine summer STEM programs. In particular, five aspects of work with data, a) asking questions, b) observing phenomena, c) constructing measures and generating data, d) data modeling, and e) interpreting and communicating findings, were identified from video-recordings of the programs. These codes were then used to predict profiles, or distinct groups on the basis of different levels, of youths’ cognitive, behavioral, and affective engagement, and two other variables, youths’ perceptions of challenge and competence. These measures were obtained using an innovative method, ESM, that provides some access to youths’ experience in-the-moment of the activities they were involved in during the program. Findings indicate that work with data occurs regularly in the programs and that there are some examples of ambitious activities centered on working with real-world data (and examples in which the work with data is not fully aligned with youth-driven work with data). Six profiles of engagement and its conditions were identified, representing different configurations of the three dimensions of engagement and its conditions. Relations of work with data and youth characteristics (pre-program interest in STEM and youths’ gender and status in terms of being a member of under-represented groups in STEM) were, overall, not strongly related with the profiles of engagement and its conditions, though some key findings were identified. Generating and modeling data were both related to the most potentially beneficial profile, one characterized by high levels of all five of the variables used to create the profiles. Female youth who were involved in work with data (at the momentary level) to a greater extent were also more likely to be fully engaged. This study suggests that work with data has purchase as an organizing set of activities for STEM can have some benefits in terms of understanding the nature of what youth do in summer STEM programs. In addition, this study shows that ESM and engagement can be used to understand youths’ experiences. Data–and who is able to work with data–have important roles in STEM learning and in society; efforts to understand and support learners engaging in these ambitious activities should be encouraged and expanded. "],
["references.html", "Chapter 6 References", " Chapter 6 References Akiva, T. (2005). Turning training into results: The new youth program quality assessment. High/Scope Resource, 24(2), 21-24. Bergman, L. R., &amp; Magnusson, D. (1997). A person-oriented approach in research on developmental psychopathology. Development and psychopathology, 9(2), 291-319. Bergman, L. R., Magnusson, D., &amp; El Khouri, B. M. (2003). Studying individual development in an interindividual context: A person-oriented approach. Psychology Press. Berland, L. K., Schwarz, C. V., Krist, C., Kenyon, L., Lo, A. S., &amp; Reiser, B. J. (2016). Epistemologies in practice: Making scientific practices meaningful for students. Journal of Research in Science Teaching, 53(7), 1082-1112. Bielik, T., &amp; Yarden, A. (2016). Promoting the asking of research questions in a high-school biotechnology inquiry-oriented program. International Journal of STEM Education, 3(1), 15. Breckenridge, J. N. (2000). Validating cluster analysis: Consistent replication and symmetry. Multivariate Behavioral Research, 35(2), 261-285. Bystydzienski, J. M., Eisenhart, M., &amp; Bruning, M. (2015). High school is not too late: Developing girls’ interest and engagement in engineering careers. Career Development Quarterly, 63(1), 88–95. http://doi.org/10.1002/j.2161-0045.2015.00097.x Cohen, J. (1992). A power primer. Psychological Bulletin, 112(1), 155. National Governors Association Center for Best Practices, Council of Chief State School Officers. (2010). Common Core State Standards for Mathematics. Washington, DC: National Governors Association Center for Best Practices and the Council of Chief State School Officers. Corpus, J. H., &amp; Wormington, S. V. (2014). Profiles of intrinsic and extrinsic motivations in elementary school: A longitudinal analysis. The Journal of Experimental Education, 82(4), 480-501. Csikszentmihalyi, M. (1990). Flow: The psychology of optimal performance. Cambridge, England: Cambridge University Press. Csikszentmihalyi, M. (1997). Finding flow: The psychology of engagement with everyday life. New York, NY: Basic Books. Creswell, J. W., Plano Clark, V. L., Gutmann, M. L., &amp; Hanson, W. E. (2003). Advanced mixed methods research designs. In A. Tashakkori &amp; C. Teddlie (Eds.), Handbook of mixed methods in social and behavioral research (pp. 209–240). Thousand Oaks, CA: Sage. English, L. D. (2012). Data modelling with first-grade students. Educational Studies in Mathematics, 81(1), 15-30. Finzer, W. (2013). The data science education dilemma. Technology Innovations in Statistics Education, 7(2), p. 1-9. Forum for Youth Investment. (2012). Youth Program Quality Assessment. Washington, DC: The Forum for Youth Investment Franklin, C., Kader, G., Mewborn, D., Moreno, J., Peck, R., Perry, M., &amp; Scheaffer, R. (2007). Guidelines for assessment and instruction in statistics education (GAISE) report. Alexandria, VA: American Statistical Association. Fredricks, J. A., &amp; McColskey, W. (2012). The measurement of student engagement: A comparative analysis of various methods and student self-report instruments. In S. L. Christenson, A. L. Reschly, &amp; C. Wylie (Eds.), The handbook of research on student engagement (pp. 763–782). New York: Springer Science. https://doi.org/10.1007/978-1-4614-2018-7_37 Fredricks, J. A., Blumenfeld, P. C., &amp; Paris, A. H. (2004). School engagement: Potential of the concept, state of the evidence. Review of Educational Research, 74(1), 59-109. Fredricks, J. A., Filsecker, M., &amp; Lawson, M. A. (2016). Student engagement, context, and adjustment: Addressing definitional, measurement, and methodological issues. Learning &amp; Instruction, 43, 1-4. Gelman, S. A., &amp; Markman, E. M. (1987). Young children’s inductions from natural kinds: The role of categories and appearances. Child Development, 58(6), 1532-1541. Gopnik, A., &amp; Sobel, D. M. (2000). Detecting blickets: How young children use information about novel causal powers in categorization and induction. Child Development, 71(5), 1205-1222. Gopnik, A., Sobel, D. M., Schulz, L. E., &amp; Glymour, C. (2001). Causal learning mechanisms in very young children: two-, three-, and four-year-olds infer causal relations from patterns of variation and covariation. Developmental Psychology, 37(5), 620. Greene, B. A. (2015). Measuring cognitive engagement with self-report scales: Reflections from over 20 years of research. Educational Psychologist, 50(1), 14-30. Greene, K. M., Lee, B., Constance, N., &amp; Hynes, K. (2013). Examining youth and program predictors of engagement in out-of-school time programs. Journal of Youth and Adolescence, 42(10), 1557-1572. Hancock, C., Kaput, J. J., &amp; Goldsmith, L. T. (1992). Authentic inquiry with data: Critical barriers to classroom implementation. Educational Psychologist, 27(3), 337-364. Harring, J. R., &amp; Hodis, F. A. (2016). Mixture modeling: Applications in educational psychology. Educational Psychologist, 51(3-4), 354-367. Hasson, E., &amp; Yarden, A. (2012). Separating the research question from the laboratory techniques: Advancing high‐school biology teachers’ ability to ask research questions. Journal of Research in Science Teaching, 49(10), 1296-1320. Hayenga, A. O., &amp; Corpus, J. H. (2010). Profiles of intrinsic and extrinsic motivations: A person-centered approach to motivation and achievement in middle school. Motivation and Emotion, 34(4), 371-383. Hektner, J. M., Schmidt, J. A., &amp; Csikszentmihalyi, M. (2007). Experience sampling method: Measuring the quality of everyday life. Sage. Jahnukainen, M. (2010). Extreme cases. Encyclopedia of Case Study Research. Thousand Oaks, CA: Sage. Konold, C., &amp; Pollatsek, A. (2002). Data analysis as the search for signals in noisy processes. Journal for Research in Mathematics Education, 33(4), 259-289. Lauer, P. A., Akiba, M., Wilkerson, S. B., Apthorp, H. S., Snow, D., &amp; Martin-Glenn, M. L. (2006). Out-of-school-time programs: A meta-analysis of effects for at-risk students. Review of educational research, 76(2), 275-313. Lee, H. S., Angotti, R. L., &amp; Tarr, J. E. (2010). Making comparisons between observed data and expected outcomes: students’ informal hypothesis testing with probability simulation tools. Statistics Education Research Journal, 9(1), 68-96. Lee, H., &amp; Hollebrands, K. (2008). Preparing to teach mathematics with technology: An integrated approach to developing technological pedagogical content knowledge. Contemporary Issues in Technology and Teacher Education, 8(4), 326-341. Lehrer, R., &amp; Romberg, T. (1996). Exploring children’s data modeling. Cognition and Instruction, 14(1), 69-108. Lehrer, R., &amp; Schauble, L. (2004). Modeling natural variation through distribution. American Educational Research Journal, 41(3), 635-679. Lehrer, R. &amp; Schauble, L. (2015). Developing scientific thinking. In L. S. Liben &amp; U. Müller (Eds.), Cognitive processes. Handbook of child psychology and developmental science (Vol. 2, 7th ed., pp. 671-174). Hoboken, NJ: Wiley. Lehrer, R., Kim, M. J., &amp; Jones, R. S. (2011). Developing conceptions of statistics by designing measures of distribution. ZDM, 43(5), 723-736. Lehrer, R., Kim, M. J., &amp; Schauble, L. (2007). Supporting the development of conceptions of statistics by engaging students in measuring and modeling variability. International Journal of Computers for Mathematical Learning, 12(3), 195-216. Lesh, R., Middleton, J. A., Caylor, E., &amp; Gupta, S. (2008). A science need: Designing tasks to engage students in modeling complex data. Educational Studies in Mathematics, 68(2), 113-130. Linnansaari, J., Viljaranta, J., Lavonen, J., Schneider, B., &amp; Salmela-Aro, K. (2015). Finnish Students Engagement in Science Lessons. NorDiNa: Nordic Studies in Science Education, 11(2), 192-206. Retrieved from https://www.journals.uio.no/index.php/nordina/article/view/2047 Lovett, M. C., &amp; Shah, P. (2007). Preface. In M. C. Lovett &amp; P. Shah (Eds.), Thinking with data (pp. x-xx [requested book through ILL to confirm page #s]). New York, NY: Lawrence Erlbaum. Magnusson, D., &amp; Cairns, R. B. (1996). Developmental science: Toward a unified framework. Cambridge, England: Cambridge University Press. McNeill, K. L., &amp; Berland, L. (2017). What is (or should be) scientific evidence use in k‐12 classrooms? Journal of Research in Science Teaching, 54(5), 672-689. Muthén, B. (2004). Latent variable analysis. The Sage handbook of quantitative methodology for the social sciences. Thousand Oaks, CA: Sage Publications, 345-68. Muthén, L. K., &amp; Muthén, B. O. (1998-2017). Mplus User’s Guide. Los Angeles, CA: Muthén &amp; Muthén. NGSS Lead States. (2013). Next generation science standards: For states, by states. Washington, DC: National Academies Press. Nolen, S. B., Horn, I. S., &amp; Ward, C. J. (2015). Situating motivation. Educational Psychologist, 50(3), 234-247. Patall, E. A., Vasquez, A. C., Steingut, R. R., Trimble, S. S., &amp; Pituch, K. A. (2016). Daily interest, engagement, and autonomy support in the high school science classroom. Contemporary Educational Psychology, 46, 180-194. Patall, E. A., Steingut, R. R., Vasquez, A. C., Trimble, S. S., Pituch, K. A., &amp; Freeman, J. L. (2017). Daily Autonomy Supporting or Thwarting and Students’ Motivation and Engagement in the High School Science Classroom. Journal of Educational Psychology. Advance online publication. http://dx.doi.org/10.1037/edu0000214 Pekrun, R., &amp; Linnenbrink-Garcia, L. (2012). Academic emotions and student engagement. In S. L. Christenson, A. L. Reschly, &amp; C. Wylie (Eds.), Handbook of research on student engagement (pp. 259-292). New York, NY: Springer. Petrosino, A., Lehrer, R., &amp; Schauble, L. (2003). Structuring error and experimental variation as distribution in the fourth grade. Mathematical Thinking and Learning, 5 (2&amp;3), 131-156. Piaget, J., &amp; Inhelder, B. (1969). The psychology of the child. New York, NY: Basic Books. Pöysä, S., Vasalampi, K., Muotka, J., Lerkkanen, M. K., Poikkeus, A. M., &amp; Nurmi, J. E. (2017). Variation in situation-specific engagement among lower secondary school students. Learning and Instruction. http://dx.doi.org/10.1016/j.learninstruc.2017.07.007 Rosenberg, J. M. (2018). Comparing mplus and mclust output. Retrieved from https://jrosen48.github.io/r-markdown/comparing-mplus-mclust.html Salmela-Aro, K., Moeller, J., Schneider, B., Spicer, J., &amp; Lavonen, J. (2016). Integrating the light and dark sides of student engagement using person-oriented and situation-specific approaches. Learning and Instruction, 43, 61-70. Salmela-Aro, K., Muotka, J., Alho, K., Hakkarainen, K., &amp; Lonka, K. (2016). School burnout and engagement profiles among digital natives in Finland: A person-oriented approach. European Journal of Developmental Psychology, 13(6), 704-718. Schneider, B., Krajcik, J., Lavonen, J., Salmela‐Aro, K., Broda, M., Spicer, J., … &amp; Viljaranta, J. (2016). Investigating optimal learning moments in US and Finnish science classes. Journal of Research in Science Teaching, 53(3), 400-421. Schmidt, J. A., Rosenberg, J. M., Beymer, P. (advance online publication). A person-in-context approach to student engagement in science: Examining learning activities and choice. Journal of Research in Science Teaching. https://dx.doi.org/10.1002/tea.21409 Schwarz, N., Kahneman, D., &amp; Xu, J. (2009). Global and episodic reports of hedonic experience. In R. Belli, D. Alwen, &amp; F. Stafford (Eds.), Using calendar and diary methods in life events research (pp. 157-174). Newbury Park, CA: Sage. Sfard, A. (1998). On two metaphors for learning and the dangers of choosing just one. Educational Researcher, 27(2), 4-13. Shernoff, D. J., Csikszentmihalyi, M., Schneider, B., &amp; Shernoff, E. S. (2003). Student engagement in high school classrooms from the perspective of flow theory. School Psychology Quarterly, 18(2), 158-176. Shernoff, D. J., Kelly, S., Tonks, S. M., Anderson, B., Cavanagh, R. F., Sinha, S., &amp; Abdi, B. (2016). Student engagement as a function of environmental complexity in high school classrooms. Learning and Instruction, 43, 52-60. Shumow, L., &amp; Schmidt, J. A. (2013). STEM interest and engagement (STEM I.E.). National Science Foundation proposal for award number 1421198. Sinatra, G. M., Heddy, B. C., &amp; Lombardi, D. (2015). The challenges of defining and measuring student engagement in science. Educational Psychologist, 50(1), 1-13. doi:10.1080/00461520.2014.1002924 Singh, K., Granville, M., &amp; Dika, S. (2002). Mathematics and science achievement: Effects of motivation, interest, and academic engagement. The Journal of Educational Research, 95(6), 323-332. Shernoff, D. J., &amp; Schmidt, J. A. (2008). Further Evidence of an Engagement–Achievement Paradox Among U.S. High School Students. Journal of Youth and Adolescence, 37(5), 564–580. http://doi.org/10.1007/s10964-007-9241-z Shumow, L., Schmidt, J. A., &amp; Zaleski, D. J. (2013). Multiple perspectives on student learning, engagement, and motivation in high school biology labs. The High School Journal, 96(3), 232-252. Skinner, E. A., &amp; Pitzer, J. (2012). Developmental dynamics of engagement, coping, and everyday resilience. In S. Christenson, A. Reschly, &amp; C. Wylie (Eds.), Handbook of Research on Student Engagement (pp. 21-45). New York: Springer Science. Skinner, E. A., Kindermann, T. A., &amp; Furrer, C. J. (2009). A motivational perspective on engagement and disaffection: Conceptualization and assessment of children’s behavioral and emotional participation in academic activities in the classroom. Educational and Psychological Measurement, 69(3), 493-525. Skinner, E., Furrer, C., Marchand, G., &amp; Kindermann, T. (2008). Engagement and disaffection in the classroom: Part of a larger motivational dynamic? Journal of Educational Psychology, 100(4), 765. Smith, C., Akiva, T., Sugar, S., Lo, Y. J., Frank, K. A., Peck, S. C., Cortina, K. S., &amp; Devaney, T. (2012).Continuous quality improvement in afterschool settings: Impact findings from the Youth Program Quality Intervention study. Washington, DC: The Forum for Youth Investment. Steinley, D., &amp; Brusco, M. J. (2011). Evaluating mixture modeling for clustering: recommendations and cautions. Psychological Methods, 16(1), 63. Stohl, H., &amp; Tarr, J. E. (2002). Developing notions of inference using probability simulation tools. The Journal of Mathematical Behavior, 21(3), 319-337. Stroupe, D. (2014). Examining classroom science practice communities: How teachers and students negotiate epistemic agency and learn science‐as‐practice. Science Education, 98(3), 487-516. Strati, A. D., Schmidt, J. A., &amp; Maier, K. S. (2017). Perceived challenge, teacher support, and teacher obstruction as predictors of student engagement. Journal of Educational Psychology, 109(1), 131-147. Trevors, G. J., Kendeou, P., Bråten, I., &amp; Braasch, J. L. (2017). Adolescents’ epistemic profiles in the service of knowledge revision. Contemporary Educational Psychology, 49, 107-120. Turner, J. C., &amp; Meyer, D. K. (2000). Studying and understanding the instructional contexts of classrooms: Using our past to forge our future. Educational Psychologist, 35(2), 69-85. van Rooij, E. C., Jansen, E. P., &amp; van de Grift, W. J. (2017). Secondary school students’ engagement profiles and their relationship with academic adjustment and achievement in university. Learning and Individual Differences, 54, 9-19. Vandell, D. L., Hall, V., O’Cadiz, P., &amp; Karsh, A. (2012). Piloting outcome measures for summer learning initiative programs. Final report to the David and Lucile Packard Foundation, Children, Families, and Communities Program. Retrieved from http://faculty.sites.uci.edu/childcare/files/2013/07/SL-Outcomes-2011-Pilot_Edited_8.19.pdf Wang, M. T., &amp; Eccles, J. S. (2012). Social support matters: Longitudinal effects of social support on three dimensions of school engagement from middle to high school. Child Development, 83(3), 877-895. Wang, M. T., &amp; Holcombe, R. (2010). Adolescents’ perceptions of school environment, engagement, and academic achievement in middle school. American Educational Research Journal, 47(3), 633-662. Westfall, J., Kenny, D. A., &amp; Judd, C. M. (2014). Statistical power and optimal design in experiments in which samples of participants respond to samples of stimuli. Journal of Experimental Psychology: General, 143(5), 2020-2045. Westfall, J. (2016). PANGEA: Power Analysis for General Anova designs. Retrieved from https://jakewestfall.shinyapps.io/pangea/ Wickham, H. (2018). CRAN downloads. Retrieved from https://hadley.shinyapps.io/cran-downloads/ Wild, C. J., &amp; Pfannkuch, M. (1999). Statistical thinking in empirical enquiry. International Statistical Review, 67(3), 223-248. Wilkerson, M. H., Andrews, C., Shaban, Y., Laina, V., &amp; Gravel, B. E. (2016). What’s the technology for? Teacher attention and pedagogical goals in a modeling-focused professional development workshop. Journal of Science Teacher Education, 27(1), 11-33. Wilkerson, M. H. &amp; Fenwick, M. (2017). The practice of using mathematics and computational thinking. In C. V. Schwarz, C. Passmore, &amp; B. J. Reiser (Eds.), Helping Students Make Sense of the World Using Next Generation Science and Engineering Practices. Arlington, VA: National Science Teachers’ Association Press. pp. 181-204. Witherington, D. C. (2015). Dynamic systems in developmental science. In W. F. Overton &amp; P. C. M. Molenaar (Vol. Eds.) &amp; R. M. Lerner (Ed.), Handbook of child psychology and developmental science. Vol. 1: Theory &amp; method (7th ed., pp. 63-112). Hoboken, NJ: Wiley. Wormington, S. V., &amp; Linnenbrink-Garcia, L. (advance online publication). A new look at multiple goal pursuit: The promise of a person-centered approach. Educational Psychology Review. doi:10.1007/s10648-016-9358-2 "],
["appendix.html", "Chapter 7 Appendix 7.1 Appendix A: STEM-PQA alignment", " Chapter 7 Appendix 7.1 Appendix A: STEM-PQA alignment Table 7.1: Alignment of codes for instructional support for work with data and the STEM-PQA Work.With.Data Description STEM.PQA Asking questions or defining problems Discussing and exploring topics to investigate and pose questions. Predict, conjecture, or hypothesize Making observations Watching and noticing what is happening with respect to the phenomena or problem being investigated. Classify or abstract Generating data Figuring out how or why to inscribe an observation as data and generating coding frames or measurement tools. Collect data or measure; Highlight precision and accuracy Data modeling Understanding and explaining phenomena using models of the data that account for variability or uncertainty. Simulate, experiment, or model Interpreting and communicating findings Discussing and sharing and presenting findings. Analyze; Use symbols or models 7.1.1 Appendix B: Program descriptions Table 7.2: Program (with pseudonyms) descriptions Program.Name Program.Description Island Explorers A science-focused program that aims to help youth develop expertise on one species found in the local ecosystem by reading and writing about related content for up to an hour per day; undertaking data collection and analysis tasks to learn about the local ecosystem and how to communicate scientific data; developing vocabulary about the local ecosystem; using art to learn and communicate information; and publishing a book illustrating important elements of the species being studied. Located in both the classroom and local ecosystem. 27 students who are rising 6th graders. Youth spend the morning in more academically-oriented sessions in a classroom setting, while afternoon sessions involved STEM-oriented enrichment sessions taking place outside (the program was associated with Outward Bound) with an emphasis on exploration of the local ecosystem. The Ecosphere A science-focused program that aims to help youth to explore the marine life of Narragansett Bay. Efforts were undertaken to build youth content knowledge in the areas of ecosystem preservation, marine biology, and water quality, and related skills, such as questioning, showing initiative, data collection, measuring, maintaining an ecosystem, and analyzing water samples. Located in a classroom setting, shoreline, and science education center. 27 youth who are rising 6th to 9th graders. Youth attended programming in a classroom at an area middle school and in a field-based setting on alternating days. Field-based settings included a science education center at a community-based organization and field trips to sites in the community related to the program’s focus. Zoology Partners A science-focused program that aims to support youth’s development of content knowledge related to the issue of endangered species, including how species become endangered, processes for monitoring ecosystem viability and population levels, solutions to prevent species from becoming endangered, and approaches to reviving populations that are currently endangered. Located in the classroom as well as zoos, parks, and other natural areas. 25 youth who are rising 6th to 9th graders. Youth attended programming in a classroom at an area middle school and in a field-based setting on alternating days. Field-based settings included a local zoo and field trips to sites in the community related to the program’s focus. Marine Investigators A science-focused program that aims to provide youth with opportunities to learn about and experience Narragansett Bay; examine human impacts on the local ecosystem, including how the geography of the Bay helped influence human history and how the history of humans along the shoreline has impacted the Bay, and begin the process of cultivating a sense of stewardship among participating youth for caring for and protecting the Bay in the future. Located in the classroom, shoreline along the bay, ship on the bay, and various field locations associated with bay health. 19 youth who are rising 7th to 9th graders. Youth attended programming in a classroom at an area middle school and in a field-based setting on alternating days. Field-based settings included the local bay shoreline, a voyage on a marine education ship researching in the Bay, and field trips to sites in the community related to the program’s focus. During the span of the program, youth had the opportunity to participate in both a water quality research study. Comunidad de Aprendizaje A STEM-focused program that aims to help youth improve basic skills in mathematics and develop an interest in STEM content and entrepreneurship. Primarily in the classroom setting. 33 students who are rising 5th to 8th graders. Morning sessions are characterized by direct instruction in mathematics for individual grade levels and mixed grade level afternoon enrichment sessions in either robotics or dance. The direct instruction component of the programs was organized around a theme of promoting entrepreneurship with the goal of helping participating youth better see the relevance of mathematics to future career goals and opportunities. Jefferson House A STEM-focused program that aims to support youth’s development of basic math skills, the program was primarily focused on helping youth develop problem solving, self-improvement, and critical thinking skills. Located in a classroom. 11 youth who are rising 7th graders. The youth spent the morning in more academically-oriented sessions in a classroom setting focusing on basic skill development, while afternoon sessions involved STEM-oriented enrichment sessions involving media, art, and nutrition. Enrichment offerings varied by day, with math sessions occurring twice per week, alternating with academically oriented sessions in the am that were oriented at supporting skill development in English/language arts. Uptown Architecture An engineering-focused program that aims to support youth’s participation in a process to design and build an outdoor learning space for use at the middle school where the program was housed. A key focus of the program was to provide youth with the opportunity to use design thinking as a problem-solving tool and have the experience of affecting their community positively through the design/build process. Located in a classroom, building shop, and various field locations. 18 youth who were rising 6th to 9th graders. Youth attended programming in a classroom at an area middle school and in a building shop located at a community-based organization on alternating days, while also taking field trips to locations associated with the program’s overall theme. Building Mania An engineering-focused program that aims to provide youth with the opportunity to experiment with designing and using simple machines. A goal of the program is to have youth engage in the engineering design process by determining a need, brainstorming possible designs, selecting a design, planning and drawing out the design, creating and testing and revising it, and producing a final machine. Located in the classroom, design labs, and other local locations. 24 youth who are rising 6th to 9th graders. Youth attended programming in a classroom at an area middle school and a field-based setting on alternating days. Field-based settings included a design lab at a community-based organization and field trips to sites in the community related to the program’s focus. Adventures in Mathematics A mathematics-focused program that aims to help youth to develop the basic math skills and prevent summer learning loss among participating youth through direct instruction and participation in math-related games. Located primarily in the classroom. 20 youth who are rising 8th to 10th graders. Youth participated in direct instructions in mathematics and math-related games in small groups. Program content was aligned with the state’s standards in mathematics. 7.1.2 Appendix C: Model specifications details Here, the six models that are possible to specify in LPA are described in terms of how the variables used to create the profiles are estimated. Note that p represents different profiles and each parameterization is represented by a 4 x 4 covariance matrix and therefore would represent the parameterization for a four-profile solution. In all of the models, the means are estimated freely in the different profiles. Imagine that each row and column represents a different variable, i.e., the first row (and column) represents broad interest, the second enjoyment, the third self-efficacy, and the fourth another variable, i.e., future goals and plans. Models 1 and 3 meet the assumption of independence, that is, that, after accounting for their relations with the profile, the variables used to estimate the profiles are independent (Collins &amp; Lanza, 2010). They estimate variable variances but do not estimate covariances (i.e., as can be seen, the covariance matrices are “diagonal,” without any off-diagonal parameters that are estimated). These models are estimated by default in MPlus, although these assumptions can be relaxed (Muthen &amp; Muthen, 2017). Importantly, this does not mean the variables used to create the profile are assumed to be not related; as Collins and Lanza (2010) explain: The local independence assumption refers only to conditioning on the latent variable. It does not imply that in a data set that is to be analyzed, the observed variables are independent. In fact, it is the relations among the observed variables that are explained by the latent classes. An observed data set is a mixture of all the latent classes. Independence is assumed to hold only within each latent class, which is why it is called “local”. Despite the assumption of independence, as Collins and Lanza (2010), Muthen and Muthen (2017), and others (i.e., Pastor et al., 2007; Vermunt &amp; Magidson, 2002) note, it can be lifted to improve model fit, though these models without the assumption of independence may be better described as general or Gaussian mixture models (Fraley et al., 2017). 7.1.2.1 Varying means, equal variances, and covariances fixed to 0 (model 1) In this model, which corresponds to the mclust model wit the name “EEI”, the variances are estimated to be equal across profiles, indicated by the absence of a p subscript for any of the diagonal elements of the matrix. The covariances are constrained to be zero, as indicated by the 0’s between every combination of the variables. Thus, this model is highly constrained but also parsimonious: the profiles are estimated in such a way that the variables’ variances are identical for each of the profiles, and the relationships between the variables are not estimated. In this way, less degrees of freedom are taken used to explain the observations that make up the data. However, estimating more parameters–as in the other models–may better explain the data, justifying the addition in complexity that their addition involves (and their reduction in degrees of freedom). \\[ \\left[ \\begin{matrix} { \\sigma }_{ 1 }^{ 2 } &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; { \\sigma }_{ 2 }^{ 2 } &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; { \\sigma }_{ 3 }^{ 2 } &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; { \\sigma }_{ 4 }^{ 2 } \\end{matrix} \\right] \\] 7.1.2.2 Varying means, equal variances, and equal covariances (model 2) This model corresponds to the mclust model “EEE”. In this model, the variances are still constrained to be the same across the profiles, although now the covariances are estimated (but like the variances, are constrained to be the same across profiles). Thus, this model is the first to estimate the covariance (or correlations) of the variables used to create the profiles, thus adding more information that can be used to better understand the characteristics of the profiles (and, potentially, better explain the data). \\[ \\left[ \\begin{matrix} { \\sigma }_{ 1 }^{ 2 } &amp; { \\sigma }_{ 21 } &amp; { \\sigma }_{ 31 } &amp; { \\sigma }_{ 41 } \\\\ { \\sigma }_{ 12 } &amp; { \\sigma }_{ 2 }^{ 2 } &amp; { \\sigma }_{ 23 } &amp; { \\sigma }_{ 24 } \\\\ { \\sigma }_{ 13 } &amp; { \\sigma }_{ 12 } &amp; { \\sigma }_{ 3 }^{ 2 } &amp; { \\sigma }_{ 33 } \\\\ { \\sigma }_{ 14 } &amp; { \\sigma }_{ 12 } &amp; { \\sigma }_{ 12 } &amp; { \\sigma }_{ 4 }^{ 2 } \\end{matrix} \\right] \\] 7.1.2.3 Varying means, varying variances, and covariances fixed to 0 (model 3) This model corresponds to the mclust model “VVI” and allows for the variances to be freely estimated across profiles. The covariances are constrained to zero. Thus, it is more flexible (and less parsimonious) than model 1, but in terms of the covariances, is more constrained than model 2. \\[ \\left[ \\begin{matrix} { \\sigma }_{ 1p }^{ 2 } &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; { \\sigma }_{ 2p }^{ 2 } &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; { \\sigma }_{ 3p }^{ 2 } &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; { \\sigma }_{ 4p }^{ 2 } \\end{matrix} \\right] \\] 7.1.2.4 Varying means, varying variances, and equal covariances (model 4) This model, which specifies for the variances to be freely estimated across the profiles and for the covariances to be estimated to be equal across profiles, extends model 3. Unfortunately, this model cannot be specified with mclust, though it can be with MPlus; this model can be used with the functions to interface to MPlus described below. \\[ \\left[ \\begin{matrix} { \\sigma }_{ 1p }^{ 2 } &amp; { \\sigma }_{ 21 } &amp; { \\sigma }_{ 31 } &amp; { \\sigma }_{ 41 } \\\\ { \\sigma }_{ 12 } &amp; { \\sigma }_{ 2p }^{ 2 } &amp; { \\sigma }_{ 23 } &amp; { \\sigma }_{ 24 } \\\\ { \\sigma }_{ 13 } &amp; { \\sigma }_{ 12 } &amp; { \\sigma }_{ 3p }^{ 2 } &amp; { \\sigma }_{ 33 } \\\\ { \\sigma }_{ 14 } &amp; { \\sigma }_{ 12 } &amp; { \\sigma }_{ 12 } &amp; { \\sigma }_{ 4p }^{ 2 } \\end{matrix} \\right] \\] 7.1.2.5 Varying means, equal variances, and varying covariances (model 5) This model specifies the variances to be equal across the profiles, but allows the covariances to be freely estimated across the profiles. Like model 4, this model cannot be specified with mclust, though it can be with MPlus. Again, this model can be used with the functions to interface to MPlus described below. \\[ \\left[ \\begin{matrix} { \\sigma }_{ 1 }^{ 2 } &amp; { \\sigma }_{ 21p } &amp; { \\sigma }_{ 31p } &amp; { \\sigma }_{ 41p } \\\\ { \\sigma }_{ 12p } &amp; { \\sigma }_{ 2 }^{ 2 } &amp; { \\sigma }_{ 23p } &amp; { \\sigma }_{ 24p } \\\\ { \\sigma }_{ 13p } &amp; { \\sigma }_{ 12p } &amp; { \\sigma }_{ 3 }^{ 2 } &amp; { \\sigma }_{ 33p } \\\\ { \\sigma }_{ 14p } &amp; { \\sigma }_{ 12p } &amp; { \\sigma }_{ 12p } &amp; { \\sigma }_{ 4 }^{ 2 } \\end{matrix} \\right] \\quad \\] 7.1.2.6 Varying means, varying variances, and varying covariances (model 6) This model corresponds to the mclust model “VVV”. It allows the variances and the covariances to be freely estimated across profiles. Thus, it is the most complex model, with the potential to allow for understanding many aspects of the variables that are used to estimate the profiles and how they are related. However, it is less parsimonious than all of the other models, and the added parameters should be considered in light of how preferred this model is relative to those with more simple specifications. \\[ \\left[ \\begin{matrix} { \\sigma }_{ 1p }^{ 2 } &amp; { \\sigma }_{ 21p } &amp; { \\sigma }_{ 31p } &amp; { \\sigma }_{ 41p } \\\\ { \\sigma }_{ 12p } &amp; { \\sigma }_{ 2p }^{ 2 } &amp; { \\sigma }_{ 23p } &amp; { \\sigma }_{ 24p } \\\\ { \\sigma }_{ 13p } &amp; { \\sigma }_{ 12p } &amp; { \\sigma }_{ 3p }^{ 2 } &amp; { \\sigma }_{ 33p } \\\\ { \\sigma }_{ 14p } &amp; { \\sigma }_{ 12p } &amp; { \\sigma }_{ 12p } &amp; { \\sigma }_{ 4p }^{ 2 } \\end{matrix} \\right] \\] 7.1.3 Appendix D: Additional details on the model selection process Looking across the statistics presented, some general ideas about which models are to be preferred emerge. Solutions are interpreted first for each model individually and then across models with the goal of choosing a smaller number of models to investigate in more detail. Figure 7.1: Fit statistics for model 1 solutions Figure 7.2: Fit statistics for model 2 solutions For solutions associated with model 1, the decrease (indicating a preferred model) in information criteria becomes smaller as the number of profiles increases from 5 to 6 and 6 to 7. A solution associated with 8 profiles did not replicate the log-likelihood and the VLMR and LMR suggest that the solution associated with 9 profiles did not fit better than that with 8 profiles, suggesting that models with 7 or fewer profiles be preferred. Considering these models, the entropy statistic increases by a large amount between the solution associated with 4 and 5 profiles (and then decreases slightly between 5 and 6 and 6 and 7 profile solutions), suggesting (but not providing conclusive evidence) that models 5, 6, or 7 may be preferred. The bootstrapped LRT suggests that, until the log-likelihood is not replicated, every more complex model be selected. Taking these pieces of evidence into conclusion, for model 1, solutions associated with 4 through 7 may be considered in more depth, with an emphasis on solutions associated with profiles with 5 and 6 profiles on the basis of the slowing of the decrease in the information criteria associated with the solutions with greater profiles than these, and the increase in the entropy from 4 to 5 (and 6) profile solutions. For solutions associated with model 2, only those associated with 2-5 profile solutions were associated with log-likelihoods that were replicated. For these four models, the log-likelihood decreased in a mostly consistent way, such that changes in the decrease are not as evident as those associated with model 1. The entropy statistic decreases from 2 to 3 profile solutions, increases from 3 to 4 profile solutions, and then decreases slightly from 4 to 5 profile solutions, providing some information that models associated with 4 profiles be preferred to the others. All of the LRTs suggest that the more complex model be selected, not providing clear information about which solutions are to be preferred. On the basis of these pieces of evidence, models with 3, 4, and 5 solutions may be considered in more depth. However, there is a lack of consistent evidence favoring more or less complex models. The model 1, six and seven profile solutions are compelling because both show profiles that are distinguished by dimensions of engagement and its conditions (challenge and competence). Note that for this model, only the means and variances are estimated (and so no covariances are estimated), and the variances are constrained to be the same across the profiles. While this is a very restrictive model, it, along with the model 3 type (which did not lead to solutions for any of the numbers of profiles specified) also is a standard model for LPA, in that it meets the assumption of local independence (of the variables that make up the profiles–unlike for models in which covariances are estimated) typical common to LPA (see Muthen &amp; Muthen, 2016). While some of the solutions associated with the model 2 type did reach solutions, these demonstrated less appealing properties in terms of their fit statistics as well as their interpretability and with respect to concerns of parsimony. Thus, while no covariances are estimated for the model 1 type solutions, there is no requirement that these be specified; their benefit, when models associated with them are preferred, is that they can provide better fit: they can be used to better explain or predict the data in a sample, but their inclusion also means that over-fitting the model to the data can become a greater concern. For each solution, alternate solutions associated with higher log-likelihoods were explored. One advantage of the six profile solution is that most of its profiles can also be identified in solutions with fewer profiles. For the six profile solutions, this alternate solution was very different, whereas for the seven profile solutions, this alternate solution was highly similar. The model solutions exhibit a less clear pattern in terms of which profiles appear when. All else being equal, on the basis of parsimony, the model 1, six profile solution is preferred and was selected for use in subsequent analyses. 7.1.4 Appendix E: Alternate model selected (model type 1, seven profile solution) This solution is characterized by: A full profile, profile 7 A universally low profile, profile 1 A competent but not engaged or challenged profile, profile 2, characterized by high competence and moderate (low) or low levels of engagement and challenge A moderately low profile, profile 3, characterized by moderately low levels of all of the variables A challenged profile, profile 4, characterized by high challenge, moderate (high) levels of engagement, and moderate (low) levels of competence A highly challenged profile, profile 5, characterized by patterns similar to those of the challenged profile, but with higher challenge and with low levels of both engagement and challenge A challenged but not engaged or competent profile, profile 6, characterized by low levels of challenge, and high levels of engagement and competence The number of observations associated with each of the profiles is not very balanced, with few (n = 181) observations associated with the universally low profile and few (n = 222) observations associated with the highly challenged profile. The number of observations associated with the other profiles ranged from 317 to 651. Distinct from other solutions, none of the other five profiles were found in the other model 1 solutions. Two pairs of the profiles–challenged and highly challenged and universally low and moderately low–exhibited similar patterns among the variables that were distinguished by different mean levels. The log-likelihood was replicated twice, with the next lowest log-likelihood being replicate four times, possibly warranting further investigation. Taken together, this solution raises questions about whether it may be too complex, possibly suggesting preference for model 1 five and six profile solutions. "]
]
