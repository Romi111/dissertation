## Appendix

## Appendix A: Method additional materials

### Statistical software developed

In order to provide results for this research question, the MPlus software (Muthen & Muthen, 2017) was used. While MPlus is powerful and widely-used, it can be very difficult to use as part of complex analyses. One reason for why it is difficult to use is that while it provides an environment for executing model *syntax*, it is not an environment, such as SPSS or R, for statistical computing (i.e., preparing data, processing and presenting results). Because of this, I created with colleagues an open-source tool, tidyLPA, in the statistical software R (Rosenberg, Schmidt, Beymer, & Steingut, 2018). This package is available on the R Comprehensive Archive Network. This software provides wrappers--functions that provide an interface--to MPlus functions via the MplusAutomation R package (Hallquist, 2018). 

These wrapper functions dynamically generate MPlus syntax, so that, for example, a user can simply provide a data frame with variables to be used in the analysis, the specification for one of six models, the number of profiles to be estimated as part of the analysis, and a number of fine-grained options concerning the estimation and the output generated. From these inputs, a data file for MPlus is prepared and saved, the model syntax is created and saved in a model input file, the model is run, and the output, including the "savedata", or the data with its associated posterior probabilities and profile assignments, is returned to R for use plots or in subsequent analyses. 

Because of the considerable time that it takes to generate MPlus model syntax (i.e., when choosing to specify a model with different parameters or when changing the number of profiles to be estimated as part of the solution), this package makes it easier to carry out LPA in a flexible way, while retaining the power of the MPlus software. While this functionality makes it considerably easier to carry out LPA, it requires that MPlus be purchased and installed. Because of this, the R package I developed also includes wrapper functions to an open-source tool, mclust (Scrucca, Fop, Murphy, & Raftery, 2016). This is a very widely-used package for mixture modeling. While some authors have suggested that it can be used to carry out LPA (Oberski, 2016), a key challenge for analysts using it concerns specifying the models. This is because the models are described in terms of the geometric properties of the multivariate distributions being estimated (i.e., "spherical, equal volume"), rather than in terms of whether and how the means, variances, and covariances are estimated. This R package corresponds LPA models to the mclust models and provides the same functionality that the functions that use MPlus provide, namely, preparing data, running the model, and returning the output or use in subsequent analyses. As part of incorporating the mclust functionality, the functions that use MPlus and those that use mclust have been benchmarked (Rosenberg, 2018). Despite leading to identical results (in most cases) for small datasets, because of differences in how the E-M algorithm is initialized as well as other estimation-related differences, output will likely not be identical for many analyses. 

### Appendix B: Descriptive statistics additional materials

The Spearman rank (because the data were dichotomous) correlations among the aspects of instructional support for work with data are presented. The variables were moderately correlated, with *rho* values between .18 and .50. These suggest that signals are assocaited

```{r}
dfs <- df %>% distinct(beep_ID_new, dm_ask, dm_obs, dm_gen, dm_mod, dm_composite)

names(dfs)[2:6] <- c("Asking Questions", "Making Observations", "Generating Data", "Data Modeling", "Communicating Findings", "Composite of All Codes")
```

```{r}
dfs %>%
  select(-beep_ID_new) %>%
  corrr::correlate(method = "spearman") %>%
  fashion() %>%
  slice() %>%
    knitr::kable(booktabs = TRUE, linesep = "", caption = "Correlations among codes for instructional support for work with data (and composite of all codes)")
```

### Appendix C: Research Question #1 additional materials

### Model 1 candidate solutions

#### Model: 1, Profiles: 3

This solution is characterized by: 

- a **full** profile, profile 2 (though with more modestly high levels of challenge) 
- a **universally low** profile, profile 1 (again with more modestly - in this case low - levels of challenge)
- an **all moderate** profile, profile 3, characterized by levels of all of the variables close to the mean, profile 3

The number of observations associated with each of the profiles is somewhat balanced, with the all moderate profile demonstrating a higher number of observations (*n* = 1,288) than the full (*n* = 897) and universally low (*n* = 773) profiles. The log-likelihood was replicated many (more than 10) times. Because the profiles associated with this solution all demonstrated the same overall pattern (i.e., all five variables are high, low, or moderate), on the basis of interpretability, this particular solution may not be useful in terms of understanding how youth experience engagement and its conditions. 

<!-- While replicated, the lowest log-likelihood associated with this solution demonstrated a very large decrease in the log-likelihood relative to those associated with the 2nd, 3rd, and 4th lowest log-likelihood solutions. This could suggest that the model is under-identified (Asparouhov & Muthen, 2012). -->

```{r, spec-solutions-m1_3, cache = FALSE, eval = FALSE}
m1_3 <- estimate_profiles_mplus(df,  
                                dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                                starts = c(600, 120),
                                model = 1,
                                n_profiles = 3,
                                include_BLRT=TRUE,
                                n_processors = 6, remove_tmp_files = FALSE)

write_rds(m1_3, "data/models/m1_3.rds")
```

```{r, m1_3p, cache = FALSE, eval = TRUE}
m1_3 <- read_rds("data/models/m1_3.rds")
plot_profiles_mplus(m1_3, to_scale = TRUE)
```

```{r, m1_3p-ll, cache = FALSE, eval = FALSE}
extract_LL_mplus() %>% slice(1:10) %>% knitr::kable(format = "latex")
```

#### Model: 1, Profiles: 4

This solution is characterized by: 

- a **full** profile, profile 2
- a **universally low** profile, profile 1
- an **all moderate** profile, profile 3. 
- a **competent but not engaged or challenged** profile, with high levels of competence and low levels of engagement and challenge

Most profiles are in the all moderate profile (*n* = 1,288), with a large number in the full (*n* = 920) profile, and fewer in the universally low and competent (*n* n = 427) but not engaged or challenged profiles (*n* = 415). With somewhat more purchase in terms of its interpretability than the solution for model 1 with three profiles, like that solution, this one may not be as useful as more complex models for understanding youth's experiences.

The log-likelihood was replicated many (more than 10) times. 

```{r, spec-solutions-m1_4, cache = FALSE, eval = FALSE}
m1_4 <- estimate_profiles_mplus(df,  
                                dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                                starts = c(600, 120),
                                model = 1,
                                n_profiles = 4,
                                include_BLRT=TRUE,
                                n_processors = 6, remove_tmp_files = FALSE)
write_rds(m1_4, "data/models/m1_4.rds")
```

```{r, m1_4p, cache = FALSE, eval = TRUE}
m1_4 <- read_rds("data/models/m1_4.rds")
plot_profiles_mplus(m1_4, to_scale = TRUE)
```

```{r, m1_4p-ll, cache = FALSE, eval = FALSE}
extract_LL_mplus() %>% slice(1:10) %>% knitr::kable()
```

#### Model: 1, Profiles: 5

This solution is characterized by: 

- a **full** profile, profile 5
- a **universally low** profile, profile 3
- an **all moderate** profile, profile 3, though with moderate levels of affective engagement than in similar profiles associated with the four and five profile solutions, perhaps suggesting that a different profile than in those solutions
- an **only behavioral** profile, profile 2, with moderate levels of behavioral engagement, very low affective engagement, and moderately (low) levels of cognitive engagement and challenge and competence
- an **only affective** profile, profile 4, with moderate levels of affective engagement, low levels of behavioral engagement, and moderately (low) levels of cognitive engagement and challenge and competence

The number of observations associated with each of the profiles is somewhat balanced, with a large number in the full profile (*n* = 928), a moderate number of observations in the universally low (*n* = 667) and all moderate (*n* = 643) profiles, and fewer observations in the only behaviorally engaged (*n* = 375) and only affective engaged (*n* = 345)  profiles. This solution primarily distinguishes between affective and behavioral engagement; unlike the solution for model 1 with four profiles, there is not a competent but not engaged or challenged profile. This may suggest that solutions with a greater number of profiles represents both the distinction between behavioral and affective engagement highlighted by profiles in this solution as well as profiles that are characterized by higher or lower levels of the conditions for engagement (i.e., competence). The log-likelihood was replicated four times. 

```{r, spec-solutions-m1_5, cache = FALSE, eval = FALSE}
m1_5 <- estimate_profiles_mplus(df,  
                                dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                                starts = c(600, 120),
                                model = 1,
                                n_profiles = 5,
                                include_BLRT=TRUE,
                                n_processors = 6, remove_tmp_files = FALSE)
write_rds(m1_5, "data/models/m1_5.rds")
```

```{r, m1_5p, cache = FALSE, eval = TRUE}
m1_5 <- read_rds("data/models/m1_5.rds")
plot_profiles_mplus(m1_5, to_scale = TRUE)
```

```{r, m1_5p-ll, cache = FALSE, eval = FALSE}
extract_LL_mplus() %>% slice(1:10) %>% knitr::kable(format = "latex")
```

#### Model: 1, Profiles: 6 (alternate)

This solution is characterized by: 

- a **full** profile, profile 6
- a **universally low** profile, profile 1
- an **engaged and competent but not challenged** profile, profile 3
- a **challenged** profile, profile 2
- a **highly challenged** profile, profile 3
- a **moderately low** profile, profile 5

The number of observations are not very balanced, with the moderately low profile with a large number of observations (*n* = 852) and the challenged, engaged and competent but not challenged, and full profiles with moderate numbers of observations (from 464 to 619 observations), and low numbers of observations exhibited by universally low (*n* = 280) and 
highly challenged (*n* = 158) profiles. This--and, critically, the lower log-likelihood of the other model 1, six profile solution--suggests that this solution is not preferred. However, the very different profiles that emerge for this solution suggest that there might not be a somewhat under-identified solution associated with model 1 and six profiles. 

```{r, spec-solutions-m1_6-alt, cache = FALSE, eval = FALSE}
m1_6_alt <- estimate_profiles_mplus(df,  
                                    dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                                    starts = c(600, 120),
                                    model = 1,
                                    n_profiles = 6,
                                    include_BLRT=TRUE,
                                    n_processors = 6, remove_tmp_files = FALSE,
                                    optseed = 49221)
write_rds(m1_6_alt, "data/models/m1_6_alt.rds")
```

```{r, m1_6p-alt, cache = FALSE, eval = TRUE}
m1_6_alt <- read_rds("data/models/m1_6_alt.rds")
plot_profiles_mplus(m1_6_alt, to_scale = TRUE)
```

```{r, m1_6p-ll-alt, eval = FALSE, cache = FALSE}
extract_LL_mplus() %>% slice(1:10) %>% knitr::kable()
```

#### Model: 1, Profiles: 7 (alternate)

When investigating an alternate solution (associated with the second lowest log-likelihood) for the model 1, seven profile solution, we can see that even for the solutions associated with other log-likelihoods, the profiles that can be identified are very similar. One minor distinction concerns the **competent but not engaged or challenged** profile, which in the alternate solution is associated with neutral levels of affective engagement, compared to moderately low levels of affective engagement in the solution with the lowest log-likelihood. Because five of the seven profiles associated with both of these model 1, seven profile solutions seem to be distinct from those identified from simpler model 1 solutions, investigation of this alternate solution provides additional evidence that these profiles are not associated with an under-identified model and that simpler models may be preferred over these seven profile solutions.

```{r, spec-solutions-m1_7-other-LL, cache = FALSE, eval = FALSE}
m1_7_alt <- estimate_profiles_mplus(df,  
                                    dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                                    starts = c(600, 120),
                                    model = 1,
                                    n_profiles = 7,
                                    include_BLRT=TRUE,
                                    n_processors = 6, remove_tmp_files = FALSE, optseed = 597614)
write_rds(m1_7_alt, "data/models/m1_7_alt.rds")
```

```{r, m1_7-other-LL-p, eval = TRUE, cache = FALSE}
m1_7_alt <- read_rds("data/models/m1_7_alt.rds")
plot_profiles_mplus(m1_7_alt, to_scale = TRUE)
```

```{r, m1_7-other-LL-ll, cache = FALSE, eval = FALSE}
extract_LL_mplus() %>% slice(1:10) %>% knitr::kable()
```

### Model 2 candidate solutions

#### Model: 2, Profiles: 3

This solution is characterized by: 

- a **universally low** profile, profile 1, associated with moderate (low) and low levels of all of the variables; this profile is similar to the universally low profile identified as part of other solutions, although with more moderate values for some of the variables (especially cognitive engagement)
- a **competent but not challenged** profile, profile 2, characterized by high competence and low challenge
- a **challenged** profile, profile 3, characterized by very high challenge and moderate (high) levels of the other variables, similar to the challenged profile found as part of the model 1, four profile solution, but with higher levels of competence, which are moderately high in this solution but moderately low for the other solution.

The number of observations associated with each solution is fairly balanced, with the most in the challenged profile (*n* = 1,241), followed by the universally low (*n* = 954 observations) and competent but not challenged (*n* = 763) profiles. This solution is very different than the three profile solution that was interpreted for model 1. Model 2 differs from model 1 in that covariances between the variables are estimated (they are constrained to be the same are across the profiles). The log-likelihood was replicated (at least) ten times. Thus, this and other solutions associated with model 2 include information about how the variables relate. Including this information seems to be associated with profiles that differentiate the groups on the basis of the levels of each of the variables in more distinct ways: the model 1, three profile solution was characterized by high, moderate, or low levels of all variables for each of the three profiles.

```{r, spec-solutions-for-model2, cache = FALSE, eval = FALSE}
m2_3 <- estimate_profiles_mplus(df,  
                                dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                                starts = c(600, 120),
                                model = 2,
                                n_profiles = 3,
                                include_BLRT=TRUE,
                                n_processors = 6, remove_tmp_files = FALSE)
write_rds(m2_3, "data/models/m2_3.rds")
```

```{r, m2_3p, eval = TRUE, cache = FALSE}
m2_3 <- read_rds("data/models/m2_3.rds")
plot_profiles_mplus(m2_3, to_scale = TRUE)
```

```{r, m2_3p-ll, cache = FALSE, eval = FALSE}
extract_LL_mplus() %>% slice(1:10) %>% knitr::kable()
```

#### Model: 2, Profiles: 4

This solution is characterized by: 

- a **universally low** profile, profile 1
- a **challenged** profile, profile 2
- a **highly challenged** profile, profile 4
- an **engaged and competent but not challenged** profile, profile 3

The number of observations in each of the profiles is not very balanced, with more than 1,000 observations in both the universally low (*n* = 1,029) and challenged (*n* = 1,106) profiles, a moderate number if the engaged and competent but not challenged profile (*n* = 688), and very few in the highly challenged (*n* = 135) profile. The log-likelihood was replicated three times. While each of these profiles has been identified in another solution, the small number of observations in the highly challenged profile suggests that this solution be interpreted with some skepticism because of the potentially limited utility (and statistical power associated with the use) of the profiles in subsequent analyses.

```{r, spec-solutions-model2-4, cache = FALSE, eval = FALSE}
m2_4 <- estimate_profiles_mplus(df,  
                                dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                                starts = c(600, 120),
                                model = 2,
                                n_profiles = 4,
                                include_BLRT=TRUE,
                                n_processors = 6, remove_tmp_files = FALSE)
write_rds(m2_4, "data/models/m2_4.rds")
```

```{r, m2_4p, eval = TRUE, cache = FALSE}
m2_4 <- read_rds("data/models/m2_4.rds")
plot_profiles_mplus(m2_4, to_scale = TRUE)
```

```{r, m2_4p-ll, cache = FALSE, eval = FALSE}
extract_LL_mplus() %>% slice(1:10) %>% knitr::kable()
```

#### Model: 2, Profiles: 5

This solution is characterized by: 

- a **universally low** profile, profile 1
- a **full** profile, profile 4, although with very high levels of challenged (in addition to high levels of all of the other variables), making this profile similar to that (challenged) profile
- a **highly challenged** profile, profile 5
- an **all moderate** profile, profile 3, although with moderately lower levels of competence than is found in profiles associated with other solutions
- a **competent but not challenged** profile, profile 2, similar to the competent but not challenged or engaged profile, but with neutral, rather than low, levels of the engagement variables

The number of observations associated with each of the profiles is not very balanced, with a very large number of observations in the all moderate profile (*n* = 1,113) and a large number in the competent but not challenged profile (*n* = 871), a moderate number in the full profile (*n* = 573), and very few in the universally low (*n* = 271) and challenged but not competent (*n* = 130) profiles. The log-likelihood was replicated four times. Like for the model 2, four profile solution, the small number of observations associated with two of the profiles suggests that this solution should be interpreted with some caution. 

```{r, spec-solutions-model2-5, cache = FALSE, eval = FALSE}
m2_5 <- estimate_profiles_mplus(df,  
                                dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                                starts = c(600, 120),
                                model = 2,
                                n_profiles = 5,
                                include_BLRT=TRUE,
                                n_processors = 6, remove_tmp_files = FALSE)
write_rds(m2_5, "data/models/m2_5.rds")
```

```{r, m2_5p, eval = TRUE, cache = FALSE}
m2_5 <- read_rds("data/models/m2_5.rds")
plot_profiles_mplus(m2_5, to_scale = TRUE)
```

```{r, m2_5p-ll, cache = FALSE, eval = FALSE}
extract_LL_mplus() %>% slice(1:10) %>% knitr::kable()
```

## Appendix D: Research Question 2 additional materials

```{r, rq2-0-tab, eval = FALSE}
l <- list(m1, m2, m3, m4, m5, m6)
o <- map_df(l, tidy_model)
write_rds(o, "data/rq2-0-tab.rds")
```

```{r, rq2-0-tab-pres}
o <- read_rds("data/rq2-0-tab.rds")
o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models for null models", linesep = "")
```

## Appendix E: Research question #3 additional materials

```{r, rq3-supp, eval = FALSE}
l <- list(m1d, m2d, m3d, m4d, m5d, m6d)
o <- map_df(l, tidy_model_inq)
write_rds(o, "data/rq3-supp.rds")
```

```{r}
o <- read_rds("data/rq3-supp.rds")
o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         overall_pre_interest,
         dm_composite,
         inquiry_based,
                  gender_female, urm,
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
    mutate(model = c("Only behavioral",
                                  "Universally low",
                                  "Engaged and competent but not challenged",
                                  "Only affective",
                                  "All moderate",
                                  "Full")) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models with interest, composite, and activity", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down") %>% 
  kableExtra::landscape()
```
