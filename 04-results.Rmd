# Results

```{r, setup-results, include =FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      collapse = TRUE,
                      error = TRUE,
                      fig.width = 6,
                      fig.asp = .618,
                      out.width = "80%",
                      fig.align = "center",
                      results = "hold",
                      knitr.kable.na = '')

source("04-results.R")
```

## Descriptive statistics for the engagement measures

First, descriptive statistics for the five engagement variables that were used to estimate the profiles are presented in Table 4.1. These descriptive statistics show high overall levels of cognitive (*M* = 2.768, *SD* = 1.063), behavioral (*M* = 2.863, *SD* = 1.044) and affective (*M* = 2.831, *SD* = 1.051) engagement. 

These statistics also show high perceptions of competence (*M* = 3.000 (*SD* = 0.952)) and more moderate perceptions of challenge (*M* = 2.270 (*SD* = 1.117)). There was a similar degree of (moderate) variability (see the *SD*s), indicating that, across all of the responses, there was variation in the five engagement variables. This variability may be due to the youth, instructional episode, program, and even for unexplained reasons.

```{r}
oo <- d_red %>% 
  select(dm_cog_eng,
         dm_beh_eng,
         dm_aff_eng,
         dm_challenge,
         dm_competence) %>% 
  psych::describe(.) %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column("var") %>% 
  select(var, n, mean, sd) %>% 
  mutate(var = c("Cog. eng.",
                 "Beh. eng.",
                 "Aff. eng.",
                 "Challenge", 
                 "Competence"))

names(oo) <- c("", "n", "Mean", "SD")

oo %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Descriptive statistics for study variables", linesep = "", digits = 3)
```

## Correlations among the study variables

Correlations between the variables that are used to create the profiles of engagement and the one other variable which was continuous (rather than a code for a group such as youths' URM status), pre-program interest in STEM (Table 4.2). These correlations, which range from *r* = .08 through *r* = .60 (all statistically significant), represent low to moderate relations among these variables. 

```{r}
p <- d_red %>%
  select(overall_pre_interest, dm_cog_eng:dm_competence) %>%
  corrr::correlate() %>%
  corrr::shave() %>%
  corrr::fashion() %>% 
  mutate(rowname = c("Pre-interest",
                     "Cog. eng.",
                     "Beh. eng.",
                     "Aff. eng.",
                     "Challenge", 
                     "Competence"))

names(p) <- c("",
              "Pre-interest",
              "Cog. eng.",
              "Beh. eng.",
              "Aff. eng.",
              "Challenge", 
              "Competence")

p %>% 
  knitr::kable(booktabs = TRUE, format = "latex", linesep = "", caption = "Correlations among study variables")
```

## Results for Research Question #1

### Frequency of the aspects of work with data

Of the 236 instructional episodes used in the analysis, 170 (72%) were coded as involving one or more of the five aspects of work with data. The reader is reminded that an instructional episode refers to the ten-minute block of time immediately preceding an ESM signal. As presented in Table 4.3, the five aspects of work with data occurred regularly. Making observations was found to be the least frequent of the five aspects, occurring in 24% of instructional episodes. Data modeling was the next most frequent aspect, occurring in 29% of the episodes, followed by asking questions (38%), generating data (43%), and communicating findings (again 43%). 

```{r}
# from here: https://docs.google.com/spreadsheets/d/1wx2J81vERpVZjIcQwiZb6vcz1U1eDFYEJDTYTLm6zqM/edit#gid=0
the_ns <- c(90, 57, 102, 68, 103)

data_frame(`Aspect of Work with Data` = c("Asking Questions", "Making Observations", "Generating Data", "Data Modeling", "Communicating Findings"),
           `Proportion of Instructional Episodes` = round(the_ns / 236, 3),
           N = the_ns) %>%
  knitr::kable(booktabs = TRUE, linesep = "", caption = "Proportion of signals for which each of the aspects of work with data was present")
```

As suggested by the proportions reported in Table 5, the different aspects of work with data often co-occurred within a single instructional episode. On average, there were 1.86 (*SD* = 1.61) aspects of work with data present during each instructional episode. This indicates that, on average, youth were engaged in around two of aspects of the work with data during each instructional episode. There was a considerable amount of variation in the extent to which these types of work with data were supported in each program: In Appendix C, the frequencies by program are presented. 

### The nature of work with data

```{r, include = FALSE}
# data is from here:
# https://docs.google.com/spreadsheets/d/1wx2J81vERpVZjIcQwiZb6vcz1U1eDFYEJDTYTLm6zqM/edit#gid=0
```

The open-ended, qualitative approach used to understand the specific nature of youths' work with data showed the variety of ways each of the five aspects was enacted. Note that for each aspect of work with data, sometimes I there to be ways of working with data that were not very common and systematic and so did not fit into the categories I define here.

#### Asking questions or identifying problems

Among the instructional episodes that involved asking questions, qualitative descriptions revealed that around one-third (36/92, or 39%) explicitly demonstrated youth working to understand the phenomenon or problem they were investigating. When doing so, they were focused on actively constructing predictions and hypotheses about phenomena related to the program. For example, in an instructional episode during the *Ecosphere* program in which youth constructed inclined tables to study how water moved throughout the ecosystem, the youth activity leader prompted youth to generate hypotheses of what would happen when water was poured onto the table, before pouring the water. 

Other instructional episodes involved questions that were not focused on predicting or hypothesizing, but rather on asking a more general type of question (21/92; 23%), or involved the *instructor* (but not youth) posing questions or identifying problems (14/96; 16%). In the former case, youth were found to be asking more general questions about understanding the assignment, task, or even the phenomena. For example, in the *Marine Investigators* program, youth visited a water treatment site, and were provided opportunities to ask questions about what they observed: However, youths' questions were not questions that could then be answered with empirical data, but were rather to clarify their understanding. In the latter, instructors were asking youth questions (i.e., questions to elicit youths' conceptual understanding). 

#### Making observations

In the instructional episodes when the STEM-PQA revealed that youth were making observations, the vast majority (49/57, 86%) of these were focused on observing phenomena in the field, or, in the case of engineering-focused programs, noticing what was going on with a particular design. For example, in the *Building Mania* program, youth constructed Rube Goldberg machinesyouth constructed Rube Goldberg machines and were prompted by activity leaders to notice how changes in their design led to differences in how far objects were launched or rolled.

In other instances, youth were involved in observing phenomena, but were not ever asked to use those data in subsequent activities or through engaging in other aspects of work with data. For example, the science-focused programs (*Island Explorers*, *The Ecosphere*, and *Marine Investigators*) all emphasized making observations, but these observations were not frequently written down or entered into a spreadsheet as data. For example, in *Marine Investigators*, youth observed how the Atlantic Ocean brings salt water into the (freshwater) bay. Youth observe "buffers" between the salt and freshwater, but do not collect or otherwise generate data related to their observations. 

In a small number of cases making observations were focused on making observations not of phenomena, but of something more general (10/57; 18%). For example, in the *Adventures in Mathematics* program, youth observed other youth or the activity leader working through a mathematics problem, but not one that at any stage of the activity was focused on a phenomena that youth identified or discussed. 

#### Generating data

In about half (48/102; 47%) of the episodes that involved generating data, youth were writing down their own observations of a phenomenon, recording information from experiments, or recording the results of a trial (in engineering contexts). For example, in the *Marine Investigators* program, youth collected pieces of recyclable plastic, bringing them back to the classroom and counting them for each location they were collected. 

During some of these cases, youth generated data, but they did not use the data they generated in subsequent activities. In the engineering-focused programs (*Uptown Architecture*, *Crazy Machines*, and *Dorchester House* particularly, youth often generated data that resulted from their engineering designs (and communicated and interpreted their findings,) but did not model this data as a regular part of their activities. In one particular example, in the *Ecosphere* program, youth collected water samples in the field. They then brought these samples to the classroom and tested the water, involving youth in both collecting and, to a degree, generating data (by noting the pH levels of the water). However, later in the day, youth created a small-scale model (with inclined trays of dirt, rocks, and plants) of an ecosystem, in which they added food coloring to determine the impacts of chemicals and acid rain. Youth then interpreted and discussed these findings, but did not connect the discussion to the water samples youth collected and tested earlier.

In a very small number of cases (2/102; 2%), youth collected, but did not write down data. For example, again in the *Marine Investigators* program, youth used nets to collect saltwater organisms, which they then transported in buckets back to the classroom setting for subsequent analysis. While these specimens were collected to serve as data for a future activity, there was no recording observed during the episode. Very often, in the (approximately) other half of episodes related to this aspect of work with data, the ways in which youth generated data were not very systematic or clearly identifiable, a point discussed in detail in the next chapter. 

#### Data modeling

A large majority (49/68, 72%) of the instructional episodes identified as data modeling were focused on youths' uses of statistical and mathematical models. For example, in the *Comunidad de Aprendizaje* program, youth accessed nationally-representative data and were tasked to solve problems, like finding out what percentage of people engage in particular activities, like donating to charity. In another example, in the *Marine Investigators*, youth participated in activities designed to help them understand water quality in their ecosystem. Youth collected trash from sites around their community (in different "districts") and then brought the trash and recyclable plastic back to the classroom. Then, the youth activity leaders involved youth in an ambitious data modeling activity. The aim was to figure out how much plastic enters local waterways. As a part of this activity, youth activity leaders asked youth not only to determine the quantity of trash that entered the waterways, but asked youth about *why* youth thought about and used math in particular ways (i.e., by adding the quantity of trash collected and then extrapolating from this quantity to the amount from across the entire city over the course of the year). This appeared to be an ambitious and powerful data modeling activity. 

Very often, data modeling was focused on solving equations, even when related to real-life (as in buying groceries, how money is spent, and how to budget, in *Comunidad de Apendizaje*). In these episodes during which youth were modeling data (4/68; 6%), they were using equations provided by the youth activity leader to solve problems. When data modeling, a model was not always one of data. In a small number of the cases (5/68; 7%), the model was a physical model, such as during the *Crazy Machines* program, in which youth saw how changes to their Rube Goldberg machine worked or did not work. 

While data modeling activities appeared to be ambitious in their design and enactment, youth activity leaders sometimes faced the challenge of linking data modeling activities to other aspects of work with data. For example, the mathematics-focused programs, such as the *Adventures in Mathematics* program, the youth activity leaders recognizing that youth had difficulty solving equations, used duct tape and building on an earlier activity in which youth considered what constituted a rate, on how many "hops" it would take someone to move from one end of the line of duct tape to the other. The youth activity leader than asked youth to consider how far they could move in one hop and to consider how they could find out many hops it would take, using a mathematical equation. In this activity, youth were supported in their attempts to approach mathematics problem-solving in creative ways.

In a small number of instructional episodes, data modeling involved a model that could generate data (6/68; 9%). For example, in the *Marine Investigators* program, a youth activity leader used a plush toy seal designed to teach youth about anatomy and the dangers of aquatic mammals consuming trash and recyclables. In this specific instructional episode, a model was clearly used (by the youth activity leader rather than the youth, in this case), but the model was not a data model but rather a physical one that was used to help youth understand a phenomenon.

#### Interpreting and communicating findings

In around half (49/103, 48%) of the instructional episodes in which youth were interpreting and communicating findings, youth were sharing what they found from an investigation or the results of using the product they designed. For example, in the *Comunidad de Aprendizaje* program, youth participated in an activity designed to support their thinking about creating a product to bring to market; the youth activity leaders described this as being akin to the television show the *Shark Tank*. In one instructional episode, the youth activity leader asks youth to think of an idea that would make an investor willing to invest in; youth shared their ideas, describing what their ideas was, why it was a good idea, how much they could sell it for, and what their profit would be, while fielding questions from youth activity leaders and their peers. Interpreting and communicating findings was also commonly present in instructional episodes in which youth were debating the findings of an investigation, such as the results of calculations for the amount of recyclables entering waterways (in *Marine Investigators*). 

In the other instructional episodes that were not focused on youth sharing what they found from an investigation, youth were most commonly communicating about topics other than the results of an investigation or design process (3/103, 3%), such as trying to find out the answer to a discrete question posed by the youth activity leader, or the youth activity leader was who was doing the interpreting and communicating (4/103, 4%). For example, in the former case, during the *Adventures in Mathematics* program, the youth activity leader helped youth to solve problems on a worksheet, asking guiding questions to help them to begin to solve problems on their own. In the latter type of interpreting and communicating findings (the youth activity leader doing the interpreting and communicating), youth commonly engaged in other aspects of work with data (i.e., generating data), but the youth activity leader compiled, modeled, and then interpreted the data that the youth generated, rather than youth doing such activities themselves. 

## Results for Research Question #2: What profiles of youth engagement emerge from experiential data collected in the programs?

On the basis of fit statistics, statistical tests, and concerns of interpretability and parsimony, a solution with six profiles of engagement was selected. This solution represents the profiles of engagement identified to answer this research question and for use in subsequent analyses. This solution was associated with a model with varying means, equal variances, and covariances fixed to 0 (the first model type among those described in the methods). Because of the exploratory nature of the approach used to identify the profiles, LPA, it is important to consider alternate solutions. In particular, a seven profile solution with the same model specification was similar (but not superior) in terms of the fit statistics and statistical tests. This solution, presented in Appendix F, was determined to not be superior to the six profile solution, ultimately chosen on the basis of parsimony and interpretability. 

The result of this model selection process was the estimation of *six distinct profiles* identified from the data, as presented in Figures 4.1 and 4.2. Figure 4.1 shows the profiles with variables that were centered to have a mean equal to 0 and a standard deviation of 1. Thus, the *y*-axis for this plot is labeled "Z-score"). Figure 4.2 shows the profiles with the raw data (not transformed). Thus, the *y*-axis for this plot is labeled "Value." The two plots are presented because they provide different insight into the composition of the profiles: Those with the centered variables highlights positive and negative departures from the mean value for each variable, making differences between the profiles distinct. The plot with the raw data instead highlights the reported values of the variables, emphasizing the values of the variables in the profiles in the same units youth considered when they responded (and potentially highlighting similarities that may seem very different in the plot with the centered data).

```{r, fig.width = 7, fig.asp = .618, out.width = "100%", fig.cap = "The six profiles of engagement (with variable values standardized)"}

m1_6 <- read_rds("data/models/m1_6.rds")

p1 <- m1_6 %>%
  plot_profiles_mplus(to_center = TRUE, to_scale = TRUE) +
  scale_x_discrete("", 
                   limits = c("Profile 2 (n = 667)",
                              "Profile 1 (n = 370)",
                              "Profile 4 (n = 345)",
                              "Profile 5 (n = 638)",
                              "Profile 3 (n = 450)",
                              "Profile 6 (n = 488)"),
                   labels = c("Universally low (n = 667)",
                              "Only behavioral (n = 370)",
                              "Only affective (n = 345)",
                              "All moderate (n = 638)",
                              "Engaged and competent but not challenged (n = 450)",
                              "Full (n = 488)")) +
  xlab(NULL) +
  ylab("Z-score") +
  viridis::scale_fill_viridis("",
                              limits = c("DM_AFF_E", "DM_BEH_E", "DM_COG_E", "DM_CHALL", "DM_COMPE"),
                              labels = c("Affective", "Behavioral", "Cognitive", "Challenge", "Competence"), discrete = TRUE) +
  theme(plot.margin = margin(1, 0, 0, 1, "cm"))

p1
```

```{r, fig.cap = "The six profiles of engagement (with raw variable values)"}
m1_6 <- read_rds("data/models/m1_6.rds")

p2 <- m1_6 %>%
  plot_profiles_mplus(to_center = FALSE, to_scale = FALSE) +
  scale_x_discrete("", 
                   limits = c("Profile 2 (n = 667)",
                              "Profile 1 (n = 370)",
                              "Profile 4 (n = 345)",
                              "Profile 5 (n = 638)",
                              "Profile 3 (n = 450)",
                              "Profile 6 (n = 488)"),
                   labels = c("Universally low (n = 667)",
                              "Only behavioral (n = 370)",
                              "Only affective (n = 345)",
                              "All moderate (n = 638)",
                              "Engaged and competent but not challenged (n = 450)",
                              "Full (n = 488)")) +
  xlab(NULL) +
  ylab("Value") +
  viridis::scale_fill_viridis("",
                              limits = c("DM_AFF_E", "DM_BEH_E", "DM_COG_E", "DM_CHALL", "DM_COMPE"),
                              labels = c("Affective", "Behavioral", "Cognitive", "Challenge", "Competence"), discrete = TRUE) +
  theme(plot.margin = margin(1, 0, 0, 1, "cm")) +
  coord_cartesian(ylim = c(1, 4))

p2
```

This solution is characterized by:

- A *universally low* profile, characterized by low levels of working hard, learning something new, and enjoying the activity, and perceptions challenge and competence
- An *only behaviorally engaged* profile, with moderate levels of working hard, very low enjoyment of the activity, and moderately (low) levels of learning something new and challenge and competence
- An *only affectively engaged* profile, with moderate levels of enjoyment, low levels of hard work, and moderately (low) levels of cognitive learning something new, challenge, and competence
- A *all moderate* profile, with moderate levels of the three indicators of working hard, learning something new, enjoying the activity, challenge, and competence
- An *engaged and competent but not challenged* profile, characterized by high levels of working hard, learning something new, enjoying the activity, and competence, but with low levels of challenge
- A *full* profile, with high levels of working hard, learning something new, enjoying the activity, challenge, and competence

The six profiles are characterized by both varying levels on both the indicators of engagement (cognitive, behavioral, and affective) and perceptions of challenge and competence. In addition, the number of observations across the profiles is relatively balanced (with no profiles associated with a very large or small number of observations). The universally low profile was associated the largest number of observations (*n* = 667), followed by the all moderate profile (*n* = 638); each of the other four profiles were associated with 300 to 400 observations. The results for research questions 3-5 use this solution and the six profiles in subsequent analyses.

## Results for Research Question #3: What sources of variability are there for the profiles of engagement?

For all six profiles, the ICCs represent the systematic variability (the proportion of variance explained) associated with each of the three levels (youth, instructional episode, and program) for each profile. Thus, the different levels can have different proportions of variance explained for different profiles. The systematic variability at the youth level, for example, could be .10 for the *Full* profile and .025 for the *Universally Low* profile.

At the program level, the ICCs were found to be small, with values ranging from 0.00 to 0.023, suggesting that little variability can be explained by the program youth were in. For the instructional episode level, the ICCs were also small, ranging from 0.004 to 0.01. Finally, at the youth-level, the ICCs ranged from .093 to .432. 

<!-- Looking across these values, most of the explained variability in the responses is associated with youth; the program and instructional episode levels were associated with very small values, suggesting that variables at the instructional episode may have minimal effects, although adding variables at *other* levels (i.e., youth characteristics that are at the youth level) can change the value of (other levels') ICCs (Gelman & Hill, 2007). -->

```{r}
i <- readr::read_rds("data/m1-6.rds") 

ii <- i %>% 
  select(beep_ID_ICC:program_ID_ICC) %>% 
  mutate(order = c(2, 1, 4, 5, 3, 6)) %>% 
  arrange(order) %>% 
  mutate(profile = c("Universally low (n = 667)",
                     "Only behavioral (n = 370)",
                     "Only affective (n = 345)",
                     "All moderate (n = 638)",
                     "Engaged and competent but not challenged (n = 450)",
                     "Full (n = 488)"))

names(ii) <- c("Instructional Episode", "Youth", "Program", "order", "Profile")

ii %>% 
  select(Profile, `Instructional Episode`:Program) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Intra-class correlation (ICC) values for each of the three levels", linesep = "")
```

In terms of ICCS at youth level across the six profiles, the value for the youth-level ICC was highest for the *Full* profile (*ICC* = .432), suggesting that some youth have a strong tendency to be fully engaged (possibly due to their initial interest or other individual characteristics and differences). The other profile characterized by a consistent pattern across all of the variables--the *Universally low* profile--had a modest value for the ICC at the youth level (*ICC* = .267). Finally, a large amount of variability is associated with the residual (variance that is not associated with the program, instructional episode, or youth levels). This suggests that there is wide variation in youths' responses that may not be readily explained or predicted by variables *at one level alone*. Remaining unexplained variability is captured by the residual term. Some youth from particular programs may engage during some episode instructional episodes in very high or low ways that are not captured by modeling the variability at each of these levels alone.

The ICCs lend insight into the sources of variability for a specific profile. In addition to this analysis, examining how often youth reported the same profile across instructional episodes lends further insight into sources of variability for the profiles. This analysis can be particularly useful for understanding variability at the youth level, which the ICCs show to be associated with the most systematic variability. As presented in Figure 4.3, the mean proportion of responses for each youth in the profile they reported most varied widely across youth. There was a small number of youth who reported the same profile in all of their responses, but for most youth, the profile they reported most made up only a portion of all of their responses. For most youth, the most frequent profile was observed just over 50% of the time. Specifically, on average, youth reported their most-reported profile in .540 (*SD* = .194, *min* = .182, *max* = 1.00) of their responses. 

In sum, these findings show that there was substantial variability in the profiles present at the youth level. Less variability was explained by either the program youth were in or the nature of the particular instructional episode present when youth were signaled. These results set the stage for those for the next two research questions, on the relations between the aspects of work with data (for research question #4) and the youth characteristics (for research question #5) and the profiles of engagement.

```{r, fig.cap = "Histogram of the proportion of responses for each youth in the profile they reported most"}
p <- d %>%
  count(participant_ID, profile) %>%
  spread(profile, n, 0) %>%
  gather(profile, n, -participant_ID) %>%
  group_by(participant_ID) %>%
  mutate(n_p = n / sum(n)) %>%
  select(-n) %>%
  summarize(m_n_p = max(n_p))

ggplot(p, aes(x = m_n_p)) +
  geom_histogram(bins = 50) +
  theme_bw() +
  xlab("Proportion of responses for each youth in the profile they reported most") +
  ylab("Number of Youth") +
  theme(text = element_text(family = "Times"))
```

## Results for Research Question #4: Aspects of work with data and engagement

To understand how aspects of work with data are related to engagement, six analytic models were specified – one for each engagement profile. In each model, the dependent variable is the  probability of a response being classified in a particular profile (for example “fully engaged”), as determined by the Latent Profile Analysis. The five aspects of work with data were the predictor (or independent) variables. Because various aspects of work with data tended to co-occur, entering indicators for all 5 aspects simultaneously serves to isolate the association for any single aspect while controlling on the presence of the others. All models also include a number of youth characteristics which will be used to answer research question 5 below. 

Associations between the five aspects of work with data and the six engagement profiles are presented in Table 4.5. In this table, each column represents the output from one of the six different models. As an example, the first column reports the coefficients for the associations between the predictor variables and the *Only behavioral* profile. Because the outcome is in the form of a probability (ranging from 0.00 to 1.00), it can be interpreted as the change in the probability of a response being associated with each profile. Note that the *p*-values are calculated using the most conservative and recommended by recent research Kenward-Rogers approximation (Halekoh & Hojsgaard, 2014).

The only engagement profile that was significantly associated with any aspects of work with data was the Full profile (see the column with the column name Full for these results). When program activities involved modeling data, youth were around 3% more likely to be fully engaged ($\beta$ = 0.034 (0.017), p = .020; partial R^2 = .002). In other words, when program activities included modeling data, youth are more likely to report working harder, learning more, enjoying themselves more, and feeling more competent and challenged.

Youth were also more likely to be in the Full engagement profile when program activities included generating data ($\beta$ = 0.027 (0.015), p = .033; partial R^2 = .002).  These particular program activities increased the probability of full engagement by around 3%. To sum up these two findings, modeling data and generating data are associated with a (very) positive form of engagement, that exhibited by the Full profile. However, the effect sizes indicate quite small effects in substantive terms.

To determine just how robust these effects were, sensitivity analysis was carried out for these two effects (for the relation of data modeling with *Full* engagement and the relation of generating data with *Full* engagement). This follow-up analysis revealed that the effect of modeling data on *Full* engagement much more robust than that for generating data: 9.835% of this effect (of data modeling) would have to be due to bias to invalidate the inference about its effect. For generating data, only 1.884% of the effect of generating data would need to be due to bias to invalidate the inference about its effect. These values are not minuscule but are also not very large (Frank, 2003). So, while statistically significant, the effect of data modeling seems to be a more robust effect than the effect of generating data, which does not seem to be a very robust (and should therefore be interpreted with some skepticism).

<!-- There was another effect which was not statistically significant, but which nearly was so. Activities that involved asking questions were associated with an increased probability of youth engagement in the All moderate profile, and this effect was marginally significant (β = 0.023 (0.017), p = .090; partial R^2 = .001). -->

```{r, eval = T}
o <- read_rds("data/m1d-6d.rds")
o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

oo <- o %>%
  select(model,
         intercept = `(Intercept)`,
         overall_pre_interest,
         gender_female,
         urm,
         dm_ask, dm_obs, dm_gen, dm_mod, dm_com
  ) %>% 
  mutate(the_order = c(2, 1, 4, 5, 3, 6)) %>% 
  arrange(the_order) %>%
  select(-the_order) %>% 
  mutate(model = c("Universally low",
                   "Only behavioral",
                   "Only affective",
                   "Eng. and comp. but not chall.",
                   "All moderate",
                   "Full"))

names(oo) <- c("Profile", "Intercept", "Pre-interest", "Gender-Female", "URM status", "Asking", "Observing", "Generating", "Modeling", "Communicating")

re_p <- function(x) {
  o <- str_sub(x, start = -6, end = -2)
  
  p_vals <- str_extract_all(x, "\\([^)]*\\)") %>% 
    map(~.[2]) %>% 
    str_extract_all("\\(?[0-9,.]+") %>% 
    as.numeric()
  
  str_c(str_remove(x, " \\(p.*"), ifelse(p_vals < .05, "*",
                                         ifelse(p_vals > .05 & p_vals < .10, "+", "")))
}

oo <- mutate_at(oo, vars(Intercept:Communicating), re_p)

oo %>% 
  select(-Intercept) %>% 
  t() 
knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models with the interactions between interest and other characactistics and the composite for work with data", linesep = "") %>%
  kableExtra::kable_styling(latex_options = "scale_down") %>%
  kableExtra::landscape() %>% 
  group_rows("Youth characteristics", 1, 3) %>% 
  group_rows("Aspects of Work With Data", 4, 8)
```

## Results for Research Question #5: Youth characteristics and engagement

Associations between youth characteristics and the six profiles are reported in the top half of Table 4.5. Youth who enter the program with higher levels of interest (in STEM) are more likely to report being in the engaged and competent but not challenged profile (β = 0.039, p = .009; partial R^2 = .001). In other words, youth who are more interested at the outset of the program report working harder, learning more, enjoying themselves more, and feeling more competent when they are involved in program activities, though they also report lower levels of challenge. For this effect, 17.879% would be needed to invalidate the inference, suggesting a moderately robust effect.

In terms of youths' pre-program interest, these analyses show that youth who enter the program with higher levels of interest (in STEM) are more likely to report being in the *Engaged and competent but not challenged* profile ($\beta$ = 0.039, *p* = .009; *partial R^2* = .001). For each one-unit increase in pre-program interest in STEM, youth are around 4% more likely to report this profile. In other words, youth who are more interested at the outset of the program report working harder, learning more, enjoying themselves more, and feeling more competent when they are actually involved in a program activities, though they also report lower levels of challenge. For this effect, 17.879% would be needed to invalidate the inference, a slightly larger value for the follow-up sensitivity analysis than those found for the (statistically significant) relations involving the aspects of work with data, suggesting a moderately robust effect. 

<!-- Female youth reported more often than males that they were in the *Universally low* profile, though this difference did not quite reach statistical significance ($\beta$ = 0.037, *p* = .051; *partial R^2* = .006). The effect size again suggest very small effects in substantive terms. For this effect, 17.843% of the bias would need to be removed (or the effect would need to be larger by this percentage) to sustain the inference. The moderately large amount of bias that would need to be removed for the effect of being female (on the *Universally low* profile) to be significant suggests that this effect should not be very seriously interpreted.  -->

There were not any statistically significant effects of youths' URM status. This may be a function of the large proportion of youth from under-represented (in STEM) racial and ethnic groups: hispanic (48%), African American or Black (36%), and youth who identify as being from multiple racial and ethnic groups (3%) made up 87% of the youth in the programs, so there were not many youth who were *not* from under-represented groups in the sample, suggesting that the absence of findings may be due to this small sample (and low statistical power). Nevertheless, no relations between URM status and youths' engagement were found, indicating that there is at least not evidence that youth from such backgrounds do engage in different ways.

These (somewhat minimal) findings for the youth characteristics were more surprising than those observed for the aspects of work with data. The results of research question #3, on the sources of variability for the profiles of engagement, suggested that there was a lot of systematic variability at the level of the youth (there were large ICCs at the youth level, with smaller ICCs at the instructional episode level). Because pre-interest, gender, and URM status are variables at this level, it could be expected that they would have important relations with the profiles of engagement. However it appears that the particular youth characteristics considered were not effective at explaining much of this variability; possible reasons why are discussed further in the next section.
