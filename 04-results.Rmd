# Results

```{r, setup-results, include =FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      collapse = TRUE,
                      error = TRUE,
                      fig.width = 6,
                      fig.asp = .618,
                      out.width = "80%",
                      fig.align = "center",
                      results = "hold",
                      knitr.kable.na = '')

source("04-results.R")
```

In this section, I present the results associated with the preliminary analysis and the four research questions. 

## Results from the preliminary analysis

### Descriptive statistics for study variables

First, descriptive statistics for all of the study variables--overall pre-interest, the five variables that are used to estimate the profiles, are presented. Overall pre-interest and the variables used to estimate the profiles are presented first.


```{r}
oo <- d_red %>% 
  select(overall_pre_interest, 
         dm_cog_eng,
         dm_beh_eng,
         dm_aff_eng,
         dm_challenge,
         dm_competence) %>% 
  psych::describe() %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column("var") %>% 
  select(var, n, mean, sd) %>% 
  mutate(var = c("Pre-interest",
                 "Cog. eng.",
                 "Beh. eng.",
                 "Aff. eng.",
                 "Challenge", 
                 "Competence"))

names(oo) <- c("", "n", "mean", "sd")

oo %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Descriptive statistics for study variables", linesep = "", digits = 3)
```

### Correlations among study variables

Next, correlations between individual aspects of work with data (and the composite) and the variables that are used to create the profiles are presented. These correlations suggest that the aspects of work with data are not related to the aspects of work with data to a large degree, which is not surprising given the small ICC values for the momentary level, as the aspects of work with data are associated with this level.

```{r}
p <- d_red %>%
  select(dm_ask:dm_com, dm_cog_eng:dm_competence) %>%
  corrr::correlate() %>%
  corrr::shave() %>%
  corrr::fashion() %>% 
  mutate(rowname = c("Asking",
                     "Observing",
                     "Generating",
                     "Modeling",
                     "Communicating",
                     "Cog. eng.",
                     "Beh. eng.",
                     "Aff. eng.",
                     "Challenge", 
                     "Competence")) 

names(p) <- c("", "Asking",
              "Observing",
              "Generating",
              "Modeling",
              "Communicating",
              "Cog. eng.",
              "Beh. eng.",
              "Aff. eng.",
              "Challenge", 
              "Competence")

p %>% 
  knitr::kable(booktabs = TRUE, format = "latex", linesep = "", caption = "Correlations among study variables") %>%
  kableExtra::kable_styling(latex_options = "scale_down") %>%
  kableExtra::landscape()
```

Most noteworthy is the very small correlations between the aspects of work with data and the profiles; these correlations range (in absolute values) from .00 to .05. Only the relations between communicating and profile six are statistically significant. The composite variable was correlated with the profiles from (in absolute values) 0.002 to 0.035, none statistically significant. The aspects of work with data are modestly correlated with one another, with correlations ranging from .16 to .46; all were significant. 

## Results for Research Question #1

### Frequency of work with data

From the coding with the STEM-PQA, work with data appears common. Out of the 248 segments, 12 were codeable for work with data; for these, issues with the video-recordings were the primary source of the missing data; in these cases, youth may have still replied to signals, but it was not possible to code for work with data associated with these responses. 

<!-- 1.	Of all the coded video segments, what proportion were coded as having evidence of working with data of any kind. -->
<!-- 2.	How often was each type of work with data observed? -->
<!-- 3.	Then remind us that the different types of work with data can co-occur. How often did this happen? What you present here suggests that itâ€™s typical to see 2 types happening at the same time. Are there certain pairs (or trios) of work with data that occur together  more frequently than others? -->
<!-- 4.	As you are presenting these results you need to remind us that the time frame for what you are reporting is 10 minute spans of time in the program where they were supposed to be focused on STEM content. -->

<!-- The composite measure, created on the basis of summing the codes for the five aspects of work with data, has a minimum value of 0 and a maximum of 5. Its mean is 1.86 (*SD* = 1.61). This indicates that, on average, youth were engaged in 1.86 aspects of the work with data during the program. -->

We can also examine the breakdown by program, which shows that, descriptively, there exists substantial variability.

```{r}
data_frame(`Aspect of Work With Data` = c("Asking Questions", "Making Observations", "Generating Data", "Data Modeling", "Communicating Findings"),
           Proportion = c(.389, .258, .453, .288, .470),
           N = c(92, 61, 107, 68, 111)) %>%
  knitr::kable(booktabs = TRUE, linesep = "", caption = "Proportion of signals for which each of the aspects of work with data was present")

pn <- data_frame(program_name = c("Island Explorers", "The Ecosphere", "Zoology Partners", "Marine Investigators", "Comunidad de Aprendizaje", "Jefferson House", "Uptown Architecture", "Building Mania", "Adventures in Mathematics"),
                 asking = c(5, 15, 6, 11, 18, 4, 9, 8, 14),
                 observing = c(6, 10, 4, 8, 10, 2, 5, 5, 7),
                 generating = c(7, 12, 3, 6, 22, 13, 17, 9, 13),
                 modeling = c(4, 7, 4, 9, 15, 11, 4, 8, 11),
                 communicating = c(6, 12, 5, 13, 18, 18, 7, 12, 18),
                 total_segments = c(16, 24, 24, 24, 55, 24, 24, 24, 24))


pnn <- pn %>% 
  mutate(asking = asking / total_segments,
         observing=observing / total_segments,
         generating = generating/total_segments,
         modeling = modeling/total_segments,
         communicating=communicating/total_segments)

names(pnn) <- c("Variable", "Asking", "Observing", "Generating", "Modeling", "Communicating", "Total Segments")

pnn <- mutate_if(pnn, is.numeric, round, 3)

pnn %>% 
  knitr::kable(booktabs = TRUE, linesep = "", caption = "Proportion of signals for which each of the aspects of work with data was present by program") %>% 
  kableExtra::landscape()
```

### Nature of work with data

Each of the segments of video was coded. This coding resulted in approximately three to four sentence notes from each of two raters for every segment. I then reviewed these notes with the aim to identify themes based on enriching and better understanding the aspects of work with data.

#### Asking questions or identifying problems

Asking questions occurred in 92 of the segments (as coded by the PQA). In the 92 segments that were coded with asking questions, the open-ended, in-depth analysis identified 36 segments that were focused on asking questions in ways that clearly aligned with the conceptual framework for work with data. Qualitative coding showed that this aspect of work with data was highly variable. When the qualitative coding revealed this code to be present, it was often when youth were trying to better understand the phenomenon or problem they were investigating. For example, in a segment during the *Ecosphere* program in which youth constructed inclined tables to study how water moved throughout the ecosystem, the youth activity leader prompted youth to generate hypotheses of what would happen when water was poured onto the table, before pouring the water. Other segments showed that there were also many segments for which the PQA codes suggested asking questions would be present, but the in-depth analysis revealed were not always always focused on predicting, conjecturing, or hypothesizing. In these cases, the code  was applied to instances in which the youth were asking generic questions (i.e., about how they do an assignment) or when the instructor was asking youth questions (i.e., math-related questions). For example, in the *Marine Investigators* program, youth visited a water treatment site, and were provided opportunities to ask questions about what they saw. 

#### Making observations

Making observations occurred in 57 of the segments (as coded by the PQA), 49 which the open-ended coding revealed were clearly aligned with the coding frame, indicating that this code was used in ways that were close to how this aspect of work with data was conceptualized. Many of the times, this code was applied in conjunction with observing phenomenon in the field, or, in the case of engineering-focused programs, noticing what was going on with a particular design. For example, in the *Building Mania* program, youth constructed Rube Goldberg machines; youth were prompted by the activity leaders to notice how changes in their design led to differences in how far objects were launched or rolled. When qualitative coders determined this was not present, it was usually due to the observations being not of phenomena, but of the instructor. For example, in the *Adventures in Mathematics* program, instances in which youth observed other youth or the youth activity leader solving a mathematics problem was often coded as involving making observations. 

#### Generating data

Generating data occurred in 102 segments (as coded by the PQA), 48 of which the in-depth analysis showed were aligned with the coding frame. When present based on qualitative codes, youth were writing down observations, recording information from experiments, or recording the results of a trial (in engineering contexts). For example, in the *Marine Investigators* program, youth collected pieces of recyclable plastic, bringing them back to the classroom and counting them for each location they were collected. When the PQA code indicated that work with data was present, but the subsequent analysis indicated that this practice was not evident, this was often youth were writing down what the youth activity leader was saying, or was focused on collecting specimens, but not writing them down, entering them into a spreadsheet, or otherwise recording them as data. For example, again in the *Marine Investigators* program, youth used nets to collect saltwater organisms, which they then transported in buckets back to the classroom setting for subsequent analysis. While these specimens could be considered as data, at least in the segment described, youth did not inscribe notes or any other observations on the specimens they were collecting, and so data was not generated (at this stage).

#### Data modeling

Data modeling occurred in 68 segments (as coded by the PQA), 49 which were aligned with the coding frame. Like making observations, for data modeling, there was a high degree of alignment between the PQA codes and what the open-ended coding. When this aspect of work with data was found to be present on the basis of the qualitative coding, youth used mathematical models. For example, in the *Comunidad de Aprendizaje* program, youth accessed nationally-representative data and were tasked to solve problems, like finding out what percentage of people engage in particular activities, like donating to charity. When the PQA code was present but data modeling was not done in a way aligned with the conceptual framework for work with data, the youth activity leader, rather than students, was doing the modeling, or the model was not one that could generate data. For example, in the *Marine Investigators* program, a youth activity leader used a plush toy seal designed to teach youth about anatomy and the dangers of aquatic mammals consuming trash and recyclables.

#### Interpreting and communicating findings

Codes for interpreting and communicating were present in 103 segments (as coded by the PQA), in-depth, open-ended coding revealed 49 were aligned with the coding frame. When the qualitative coding revealed this aspect of work with data to be present, youth were often sharing what they found from an investigation or the results of using the product they designed. For example, in the *Comunidad de Aprendizaje* program, youth participated in an activity designed to support their thinking about creating a product to bring to market; the youth activity leaders described this as being akin to the television show the *Shark Tank*. In one segment, the youth activity leader asks youth to think of an idea that would make an investor willing to invest in; students shared their ideas, describing what their ideas was, why it was a good idea, how much they could sell it for, and what their profit would be, while fielding questions from youth activity leaders and their peers. Interpreting and communicating findings was also commonly present in segments in which youth were debating the findings of an investigation, such as the results of calculations for the amount of recyclables entering waterways (in *Marine Investigators*). When not present, which was common, youth were communicating about topics other than the results of an investigation or design process, such as trying to find out the answer to a question posed by the youth activity leader, or the youth activity leader was who was doing the interpreting and communicating. For example, in the *Adventures in Mathematics* program, the youth activity leader helped youth to solve problems on a worksheet, asking guiding questions to help youth start to solve problems on their own. 

### Summary of Findings for Research Question #1

This suggests that differences in how work with data was conceptualized and operationalized may lead, in some cases, to codes that do not reflect work with data accurately, and can lead to some findings that seem unexpected given what we know about the potential for work with data to be engaging to youth.

## Results for Research Question #2: What profiles of youth engagement and its conditions emerge from experiential data collected in the programs?

on the basis of the selection criteria  you used (you can name them again if you wish), the six profile solution with varying means, equal variances and covariances fixed to 0 emerged as the best fit of the data. This was on the basis of fit statistics, statistical tests, and concerns of interpretability and parsimony. The model demonstrated superior fit on the basis of the information criteria (AIC and BIC) and on the basis of the measure of classification accuracy (entropy). A seven profile solution with the same specifications regarding means, variances and covariances was also a similarly good fit (and is presented in the Appendix), but the 6 profile solution was ultimately chosen on the basis of parsimony and interpretability. For the selected model, presented below, the raw data and the data that are centered to have a mean equal to 0 and a standard deviation of 1 (thus, the y-axis on each of the plots is labeled "Z-score").

```{r}
m1_6 <- read_rds("data/models/m1_6.rds")

p <- m1_6 %>%
  plot_profiles_mplus(to_center = TRUE, to_scale = TRUE) +
  scale_x_discrete("", 
                   limits = c("Profile 2 (n = 667)",
                              "Profile 1 (n = 370)",
                              "Profile 4 (n = 345)",
                              "Profile 5 (n = 638)",
                              "Profile 3 (n = 450)",
                              "Profile 6 (n = 488)"),
                   labels = c("Universally low (n = 667)",
                              "Only behavioral (n = 370)",
                              "Only affective (n = 345)",
                              "All moderate (n = 638)",
                              "Engaged and competent but not challenged (n = 450)",
                              "Full (n = 488)")) +
  xlab(NULL) +
  ylab("Z-score") +
  viridis::scale_fill_viridis("",
                              limits = c("DM_AFF_E", "DM_BEH_E", "DM_COG_E", "DM_CHALL", "DM_COMPE"),
                              labels = c("Affective", "Behavioral", "Cognitive", "Challenge", "Competence"), discrete = TRUE) +
  theme(plot.margin = margin(1, 0, 0, 1, "cm"))

p

m1_6 <- read_rds("data/models/m1_6.rds")

p <- m1_6 %>%
  plot_profiles_mplus(to_center = FALSE, to_scale = FALSE) +
  scale_x_discrete("", 
                   limits = c("Profile 2 (n = 667)",
                              "Profile 1 (n = 370)",
                              "Profile 4 (n = 345)",
                              "Profile 5 (n = 638)",
                              "Profile 3 (n = 450)",
                              "Profile 6 (n = 488)"),
                   labels = c("Universally low (n = 667)",
                              "Only behavioral (n = 370)",
                              "Only affective (n = 345)",
                              "All moderate (n = 638)",
                              "Engaged and competent but not challenged (n = 450)",
                              "Full (n = 488)")) +
  xlab(NULL) +
  ylab("Value") +
  viridis::scale_fill_viridis("",
                              limits = c("DM_AFF_E", "DM_BEH_E", "DM_COG_E", "DM_CHALL", "DM_COMPE"),
                              labels = c("Affective", "Behavioral", "Cognitive", "Challenge", "Competence"), discrete = TRUE) +
  theme(plot.margin = margin(1, 0, 0, 1, "cm"))

p

```

This solution is characterized by:

- A *full* profile, profile 6
- A *universally low* profile, profile 2
- A *all moderate* profile, profile 5--and, like, the model 1, six profile solution--with moderate levels of affective engagement
- An *only behaviorally engaged* profile, profile 1, with moderate levels of behavioral engagement, very low affective engagement, and moderately (low) levels of cognitive engagement and challenge and competence
- An *only affectively engaged* profile, profile 4, with moderate levels of affective engagement, low levels of behavioral engagement, and moderately (low) levels of cognitive engagement and challenge and competence
- An *engaged and competent but not challenged* profile, profile 3, characterized by high levels of each of the three dimensions of engagement and of competence, but with low levels of challenge

The number of observations associated with each of the profiles is somewhat balanced, with the universally low profile with the largest number of observations (*n* = 667), followed by the all moderate profile (*n* = 638). Each of the other four profiles were associated with 300 to 400 observations.

### Sources of variability in momentary profiles

#### Null models

The null models presented in the table provide insight into the levels at which predictors may be able to explain the outcome. For all six profiles, the ICCs at the program level were very small, from 0.00 to 0.023. This suggests that very little variability can be explained simply by the program. For the momentary level, the ICCs were also very small, ranging from 0.004 to 0.011. Finally, the youth-level ICCs ranged from .099 to .427. 

Looking across these values, considering variability at the program, momentary, and youth levels, most of the explained variability in the responses is associated with youth; the program and momentary levels were associated with very small values, suggesting that variables at these levels have minimal variability to explain. In turn, this suggests that these variables, including those for work with data, may not have strong effects in terms of their relations with the profiles.

In terms of specific ICCs at the youth level, the value for the youth-level ICC was highest for the *full* profile, suggesting that some youth have a strong tendency to be fully engaged (possibly due to their initial interest or other individual characteristics and differences). The other profile characterized by a consistent pattern across all of the variables--the *universally low* profile--had a modest ICC, .265. Finally, a large amount of variability is associated with the residual (variance that is not associated with the program, momentary, or youth levels). This suggests that there is wide variation in students' responses that may not be readily explained or predicted.

#### Variability in momentary profiles across youth

Variability in terms of the profiles youth report can also be considered. These show that a 

```{r}
x <- d %>% 
  group_by(participant_ID) %>% 
  select(participant_ID, profile_1_p:profile_6_p) %>% 
  summarise_all(sum) %>% 
  select(profile_1_p:profile_6_p)

the_row_sum <- rowSums(as.data.frame(x))

divide_by_the_row_sum <- function(x) {
  x / the_row_sum
}

x <- mutate_all(x, divide_by_the_row_sum)

t <- as.vector(x$which_max %>% table())

x$which_max <- apply(x, 1, which.max)

x %>% 
  group_by(which_max) %>% 
  summarize_all(mean) %>% 
  gather(key, val, -which_max) %>% 
  ggplot(aes(x = which_max, y = val, group = key, fill = key)) +
  geom_col(position = "dodge") +
  theme_bw() +
  ylab("Probability") +
  xlab("Profile") +
  scale_fill_brewer("Profile", type = "qual", palette = 2, labels = 1:6) +
  scale_x_continuous(breaks = 1:6, labels = 
                       str_c(1:6, " (n = ", t, ")")
  )
```

<!-- This then leads very nicely into your next step where you say â€“ students show some within-person variability in their profiles, now Iâ€™m going to check the degree to which this variability might be due to work with data.  -->

### Summary of research question #2 findings

After reviewing a wide range of models, a relatively simple model (model 1) with six profiles was selected for use in subsequent analyses. This model has momentary profiles of engagement and its conditions characterized by both varying levels on the dimensions of engagement and perceptions of challenge and competence. In addition, the number of observations across the profiles is relatively balanced. 

## Results for Research Question #3: How do data practices relate to youth engagement in the programs?

For this question, models with the aspects of work with data both separate from and together with the youth characteristics were fit. 

The models only with the aspects of work with data yielded very similar results; see the appendix.

The models with both together were also used as part of research question #4, though they are presented here (and interpreted in the sections for both results).

```{r, eval = T}
o <- read_rds("data/m1d-6d.rds")
o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

oo <- o %>%
  select(model,
         intercept = `(Intercept)`,
         overall_pre_interest,
         gender_female,
         urm,
         dm_ask, dm_obs, dm_gen, dm_mod, dm_com
  ) %>%
  mutate(model = c("Only behavioral",
                   "Universally low",
                   "Engaged and competent but not challenged",
                   "Only affective",
                   "All moderate",
                   "Full"),
         the_order = c(2, 1, 3, 5, 3, 6)) %>% 
  arrange(the_order) %>%
  select(-the_order)

# names(oo) <- c("Profile", "Intercept", "Comp.", "Pre-interest", "Female", "URM status", "Pre-interest X Comp.", "Gender X Comp.", "URM status X Comp.")

oo %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models with the interactions between interest and other characactistics and the composite for work with data", linesep = "") %>%
  kableExtra::kable_styling(latex_options = "scale_down") %>%
  kableExtra::landscape()
```

<!-- ### Models with variables for aspects of work with data added separately -->

<!-- <!-- Start by saying that you ran one multilevel models predicting the probability of membership in each of the 6 profiles, using the work with data codes as predictors: Thus each of the rows in the table represents a different  --> -->

<!-- When the predictor variables for work with data are added, some overall patterns and specific findings can be identified. The only relations with *p*-values that were below the criterion for statistical significance (.05) were for the relations between modeling data and the *full* profile ($\beta$ = 0.036 (0.016), *p* = .016) and between generating data and the full profile ($\beta$ = 0.029 (0.015), *p* = .024). Interpreting and communicating findings was positively related to the *Only behavioral* profile ($\beta$ = 0.025 (0.014), *p* = .043). -->

<!-- ```{r, eval = F} -->
<!-- o <- read_rds("data/m1a-6a.rds") -->

<!-- o <- mutate(o, model = c( -->
<!--   str_c("profile_", 1:6))) -->

<!-- oo <- o %>% -->
<!--   select(model, -->
<!--          intercept = `(Intercept)`, -->
<!--          dm_ask, dm_obs, dm_gen, dm_mod, dm_com) %>% -->
<!--   mutate(model = c("Only behavioral", -->
<!--                    "Universally low", -->
<!--                    "Engaged and competent but not challenged", -->
<!--                    "Only affective", -->
<!--                    "All moderate", -->
<!--                    "Full")) -->

<!-- names(oo) <- c("Profile", "Intercept", "Asking", "Observing", "Generating", "Modeling", "Communicating") -->

<!-- oo %>%  -->
<!--   knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models for work with data as separate variables", linesep = "") %>% -->
<!--   kableExtra::kable_styling(latex_options = "scale_down") %>% -->
<!--   kableExtra::landscape() -->
<!-- ``` -->

<!-- Adding these variables changed the (conditional upon the random effects) R^2^ values from, .002 to .018, very small changes suggesting that the aspects of work with data do not strongly predict the profiles. The sensitivity analysis for the effect of generating data suggested that 1.884% of the inference would have to be due to bias to invalidate the inference, suggesting that this effect is not very robust to potential sources of bias, such as an omitted (in this analysis) confounding (or control) variable. For the effect of modeling, 9.835% would need to be due to bias to invalidate the inference and for the effect of interpreting and communicating findings, 9.41% would need to be due to bias. -->

### Summary of findings for research question #3

When looking across findings, we find few relations between work with data and the profiles, though there were notable effects of modeling and generating data, though they were small effects (i.e., when students are doing this, they are around 3% more likely to be responding in a way associated with the *full* profile). 

```{r, eval = FALSE}
names(ds3) <- c("Profile", "Asking", "Observing", "Generating", "Modeling", "Communicating", "Composite")

ds3 %>%
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Summary of results for research question 3 (how work with data relates to engagement)", linesep = "") %>%
  kableExtra::kable_styling(latex_options = "scale_down") %>%
  kableExtra::landscape()
```

Broadly, further explanations and investigations of these effects --focusing on the characteristics of work with data in the context of summer STEM programs and how this support is measured in terms of codes from the video--are the focus on research question #4 and are discussed in the next chapter. Moreover, these findings are deepened in subsequent analyses for research questions #4.

## Results for Research Question #4: How do youth characteristics relate to their engagement in summer STEM programs?

For this question, models with the youth characteristics separate from and together with the aspects of work with data were fit. 

Like for the results for the previous question, the models only with the youth characteristics yielded very similar results; see the appendix.

Thus, the model presented in the previous section with both youth characteristics and the aspects of work with data are interpreted here. 

<!-- ### Models with pre interest, gender, and under-represented minority (URM) status -->

<!-- These results show that overall pre-interest is associated with the *engaged and competent but not challenged* profile ($\beta$ = 0.039 (0.021), p = .009). The effect of being a female has a relation of 0.059 (0.036, p = .054) upon the probability of a response being associated with the *universally low* profile; though this effect did not meet the criteria for statistical significance, sensitivity analysis to determine how much more robust the effect would need to be to make an inference. For the effect of overall pre-interest upon the *engaged and competent but not challenged* profile, 17.879% would be needed to invalidate the inference, suggesting a moderately robust effect. For the effect of gender upon the *universally low* profile, 16.996% of the bias would need to be removed (or the effect would need to be larger by this percentage) to sustain the inference. The change in R^2^ values ranged from .004 to .007, suggesting that pre-interest and other individual characteristics - in addition to the aspects of work with data - have minimal relations with the profiles. This is more surprising than the similarly minimal relations observed for work with data: as the null models indicate, there were large ICCs (a large proportion of the variability in the outcome variables) at the youth-level (as pre-interest, gender, and URM status are variables associated with this level). This is discussed further in the next chapter.  -->

<!-- ```{r, eval = F} -->
<!-- o <-read_rds("data/m1b-6b.rds") -->

<!-- o <- mutate(o, model = c( -->
<!--   str_c("profile_", 1:6))) -->

<!-- oo <- o %>% -->
<!--   select(model, -->
<!--          intercept = `(Intercept)`, -->
<!--          overall_pre_interest, -->
<!--          gender_female, -->
<!--          urm) %>% -->
<!--   mutate(model = c("Only behavioral", -->
<!--                    "Universally low", -->
<!--                    "Engaged and competent but not challenged", -->
<!--                    "Only affective", -->
<!--                    "All moderate", -->
<!--                    "Full")) -->

<!-- names(oo) <- c("Profile", "Intercept", "Pre-interest", "Female", "URM status") -->

<!-- oo %>%  -->
<!--   knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models with interest and other characteristics", linesep = "") %>% -->
<!--   kableExtra::kable_styling(latex_options = "scale_down") %>% -->
<!--   kableExtra::landscape() -->
<!-- ```  -->

### Pre-interest, gender, and URM status and the aspects work with data seperately

These results show similar patterns to the earlier models.Like in the models with only pre-interest and the other individual characteristics alone (and like in the model with the individual aspects), pre-interest is related to the *only behavioral* profile ($\beta$ = 0.033 (0.018), p = .033). Being female is again related but not to a level that it meets the criteria for statistical significance ($\beta$ = 0.064 (0.041), p = .059). With the interactions added, the composite was no significantly related to the *only behavioral* profile ($\beta$ = 0.016 (0.016), p = .156) to a similar extent and with similar robustness as found in the separate model. One interaction, between pre-interest and being female, had a significant effect upon the profile for *full* engagement ($\beta$ = 0.012 (0.006), p = .026). However, only 1.953% of the effect would need to be due to bias to invalidate the inference. The R^2^ values, relative to the models with only random effects (the null models), increased from .003 to .028, again suggesting small effects of the predictors upon the profiles. Note that "Comp." refers to the data modeling composite.

### Pre-interest, gender, and URM status interactions work with the codes for work with data

Here, interactions for the aspects of work with data that were statistically significant are considered. 

```{r, eval = F}
o <- read_rds("data/m1e-m6ei-m6eii.rds")
o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

# oo <- o %>%
#   select(model,
#          intercept = `(Intercept)`,
#          dm_composite,
#          overall_pre_interest,
#          gender_female,
#          urm,
#          `overall_pre_interest:dm_composite`,
#          `dm_composite:gender_female`,
#          `dm_composite:urm`) %>%
#   mutate(model = c("Only behavioral",
#                    "Universally low",
#                    "Engaged and competent but not challenged",
#                    "Only affective",
#                    "All moderate",
#                    "Full"))
# 
# names(oo) <- c("Profile", "Intercept", "Comp.", "Pre-interest", "Female", "URM status", "Pre-interest X Comp.", "Gender X Comp.", "URM status X Comp.")
# 
# oo %>% 
#   knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models with the interactions between interest and other characactistics and the composite for work with data", linesep = "") %>%
#   kableExtra::kable_styling(latex_options = "scale_down") %>%
#   kableExtra::landscape()
```

### Summary of findings for research question #4

When looking across findings, we find minimal relations between pre-interest and other individual characteristics.

```{r}

mtcars %>% 
  select(hp) %>% 
  
  names(ds4) <-names(oo) <- c("Profile", "Pre-interest", "Female", "URM status", "Pre-interest X comp.", "Gender X comp.", "URM status X comp.")

ds4 %>%
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Summary of results for Research Question 4 (how youth characteristics relate to engagement)", linesep = "") %>%
  kableExtra::kable_styling(latex_options = "scale_down") %>%
  kableExtra::landscape()
```

In particular, we found that pre-interest was related to the *engaged and competent but not challenged* profile to a modest extent. Being female did not demonstrate statistically significant relations with the *univerally low* profile, though some moderately-sized effects that were nearly statistically significant were observed and interpreted in terms of how much bias would need to be reduced (or how much the larger the effect would need to be) in order for this relation to be statistically significant. Note that the positive pre-interest coefficient is the estimate from the model with the interaction (without the interaction, the coefficient was also statistically significant and was 0.039). These results, like those for research question #2, are similar to those obtained when the model 1 type, seven profile solution is used for the outcome variables. There were few interactive effects observed; the magnitude of the effect of the composite and gender interaction was small (as were the changes in the R^2^ value as a consequence of adding this interaction), and the effect appears to not be highly robust to potential sources of bias. Like for research question #2, reasons for why this may be are explored in the next chapter. 
