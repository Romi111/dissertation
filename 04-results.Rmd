In this section, results in terms of the research questions are presented.

```{r, setup-results-fix, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE, 
                      collapse = TRUE,
                      error = TRUE,
                      fig.width = 6,
                      fig.asp = .618,
                      out.width = "80%", 
                      fig.align = "center", 
                      results = "hold") 

options(knitr.kable.NA = '')
```

```{r, loading-packages}
library(tidyverse)
library(lme4)
library(corrr)
library(jmRtools)
library(tidyLPA)
library(kableExtra)
library(sjPlot)
library(broom)
library(broom.mixed)
```

```{r, loading-data, eval = F}
esm <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-esm.csv")
pre_survey_data_processed <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-pre-survey.csv")
post_survey_data_partially_processed <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-post-survey.csv")
video <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-video.csv")
pqa <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-pqa.csv")
attendance <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-attendance.csv")
class_data <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-class-video.csv")
demographics <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-demographics.csv")
pm <- read_csv("/Volumes/SCHMIDTLAB/PSE/Data/STEM-IE/STEM-IE-program-match.csv")
```

```{r, loading-rdata}
# save.image("~/desktop/sandbox-01.Rdata")
load("~/desktop/sandbox-01.Rdata")
```

```{r, processing-attendance-demo-esm-data}
attendance <- rename(attendance, participant_ID = ParticipantID)
attendance <- mutate(attendance, prop_attend = DaysAttended / DaysScheduled, 
                     participant_ID = as.integer(participant_ID))
attendance <- select(attendance, participant_ID, prop_attend)

demographics <- filter(demographics, participant_ID!= 7187)
demographics <- left_join(demographics, attendance)

esm$overall_engagement <- jmRtools::composite_mean_maker(esm, hard_working, concentrating, enjoy, interest)
```

```{r, joining-to-df}
df <- left_join(esm, pre_survey_data_processed, by = "participant_ID") # df & post-survey
df <- left_join(df, video, by = c("program_ID", "response_date", "sociedad_class", "signal_number")) # df & video
df <- left_join(df, demographics, by = c("participant_ID", "program_ID")) # df and demographics
```

```{r, proc-beep-actvariables, echo = F}
df$participant_ID <- as.factor(df$participant_ID)
df$program_ID <- as.factor(df$program_ID)
df$beep_ID <- as.factor(df$beep_ID)
df$beep_ID_new <- as.factor(df$beep_ID_new)

df$youth_activity_rc <- ifelse(df$youth_activity == "Off Task", "Not Focused", df$youth_activity)

df$youth_activity_rc <- ifelse(df$youth_activity_rc == "Student Presentation" | df$youth_activity_rc == "Problem Solving", "Creating Product", df$youth_activity_rc)

df$youth_activity_rc <- ifelse(df$youth_activity_rc == "Showing Video", "Program Staff Led", df$youth_activity_rc)

df$youth_activity_rc <- as.factor(df$youth_activity_rc)

df$youth_activity_rc <- forcats::fct_relevel(df$youth_activity_rc, "Not Focused")

df$relevance <- jmRtools::composite_mean_maker(df, use_outside, future_goals, important)
```

```{r proc-demographics}
df$urm <- ifelse(df$race %in% c("White", "Asian"), 0, 1)
df$race <- as.factor(df$race)
df$race <- fct_lump(df$race, n = 2)
df$race_other <- fct_relevel(df$race, "Other")
df$gender_female <- as.factor(df$gender) # female is comparison_group
df$gender_female <- ifelse(df$gender_female == "F", 1, 
                           ifelse(df$gender_female == "M", 0, NA))
```

```{r, proc-pqa-data}
pqa <- mutate(pqa, 
              active = active_part_1 + active_part_2,
              ho_thinking = ho_thinking_1 + ho_thinking_2 + ho_thinking_3,
              belonging = belonging_1 + belonging_2,
              agency = agency_1 + agency_2 + agency_3 + agency_4,
              youth_development_overall = active_part_1 + active_part_2 + ho_thinking_1 + ho_thinking_2 + ho_thinking_3 + belonging_1 + belonging_2 + agency_1 + agency_2 + agency_3 + agency_4,
              making_observations = stem_sb_8,
              data_modeling = stem_sb_2 + stem_sb_3 + stem_sb_9,
              interpreting_communicating = stem_sb_6,
              generating_data = stem_sb_4,
              asking_questions = stem_sb_1,
              stem_sb = stem_sb_1 + stem_sb_2 + stem_sb_3 + stem_sb_4 + stem_sb_5 + stem_sb_6 + stem_sb_7 + stem_sb_8 + stem_sb_9)

pqa$sociedad_class <- ifelse(pqa$eighth_math == 1, "8th Math",
                             ifelse(pqa$seventh_math == 1, "7th Math",
                                    ifelse(pqa$sixth_math == 1, "6th Math",
                                           ifelse(pqa$robotics == 1, "Robotics",
                                                  ifelse(pqa$dance == 1, "Dance", NA)))))

pqa <- rename(pqa, 
              program_ID = SiteIDNumeric,
              response_date = resp_date,
              signal_number = signal)

pqa$program_ID <- as.character(pqa$program_ID)

df <- left_join(df, pqa, by = c("response_date", "program_ID", "signal_number", "sociedad_class"))
```

```{r, proc-vars-for-modeling}
df <- df %>% 
  mutate(dm_cog_eng = learning,
         dm_beh_eng = hard_working,
         dm_aff_eng = enjoy,
         dm_challenge = challenge,
         dm_competence = good_at) %>% 
  rename(ssb_predict = stem_sb_1,
         ssb_model = stem_sb_2 ,
         ssb_analyze = stem_sb_3,
         ssb_measure = stem_sb_4,
         ssb_tools = stem_sb_5,
         ssb_precision = stem_sb_6,
         ssb_vocabulary = stem_sb_7,
         ssb_classification = stem_sb_8,
         ssb_symbols = stem_sb_9) %>% 
  mutate(dm_ask = ssb_predict,
         dm_obs = ssb_classification,
         dm_gen = ifelse(ssb_measure == 1 | ssb_precision == 1, 1, 0),
         dm_mod = ssb_model,
         dm_com = ifelse(ssb_symbols == 1 | ssb_analyze == 1, 1, 0)) %>% 
  mutate(ov_cog_eng = (important + future_goals) / 2,
         ov_beh_eng = (hard_working + concentrating) / 2,
         ov_aff_eng = (enjoy + interest) / 2) %>% 
  mutate(dm_composite = dm_ask + dm_obs + dm_gen + dm_mod + dm_com)

df$dm_overall_eng <- composite_mean_maker(df, dm_cog_eng, dm_beh_eng, dm_aff_eng)

df <- mutate(df, inquiry_based = ifelse(youth_activity_rc == "Creating Product" | youth_activity_rc == "Lab Activity", 1, 0)) 
```

## Descriptive Statistics

First, descriptive statistics for all of the study variables--overall pre-interest, the five variables that are used to estimate the PECs, and the variables for each of the five aspects of work with data (which are dichotomous variables)--are presented. Overall pre-interest and the variables used to estimate the PECs are presented first in table 4.1.

```{r}
df %>% 
  select(overall_pre_interest, 
         dm_cog_eng,
         dm_beh_eng,
         dm_aff_eng,
         dm_challenge,
         dm_competence) %>% 
  psych::describe() %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Descriptive statistics for continuous study variables", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

```{r, include = FALSE}
df %>% 
  select(dm_ask:dm_com) %>% 
  count(dm_ask) %>% 
  knitr::kable(booktabs = TRUE)

df %>% 
  select(dm_ask:dm_com) %>% 
  count(dm_obs) %>% 
  knitr::kable(booktabs = TRUE)

df %>% 
  select(dm_ask:dm_com) %>% 
  count(dm_gen) %>% 
  knitr::kable(booktabs = TRUE)

df %>% 
  select(dm_ask:dm_com) %>% 
  count(dm_mod) %>% 
  knitr::kable(booktabs = TRUE)

df %>% 
  select(dm_ask:dm_com) %>% 
  count(dm_com) %>% 
  knitr::kable(booktabs = TRUE)

# knitr::kable(format = "latex", booktabs = TRUE, caption = "Descriptive statistics for binary study variables", linesep = "")
```

Also, here are the youth activity codes and their counts and proportions.

```{r}
df %>% 
  count(inquiry_based) %>% 
  mutate(prop = round(n / sum(n), 3)) %>% 
  arrange(desc(prop)) %>% 
  knitr::kable(booktabs = TRUE)
```



## Research Question #1

This question addresses what profiles emerged from the data. This section first provides information about the statistical software that was developed and solutions for all models (whether models converged and the log-likelihood was replicated). Then, fit statistics for models that converged and for which the log-likelihood was replicated are described, followed by a comparison of specific, candidate solutions. At the end of this section, models selected are described in detail.

### Statistical software developed

The MPlus software is used to carry out LPA as part of this study. In order to more flexibly carry out LPA, an open-source tool, tidyLPA, was developed. This tool provides interfaces to the MPlus software as well as to the open-source mclust software. In addition to being used as part of this study, this package is provided free of use to other analysts as the first tool dedicated to carrying out LPA as part of the R software. Since being released, the package has been downloaded more than 100 times (Wickham, 2018). 

```{r, compare-solutions-overall-stats, eval = FALSE}
d <- compare_solutions_mplus(df,  
                             dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                             starts = c(600, 120),
                             n_profiles_min = 2, 
                             n_profiles_max = 10,
                             return_stats_df = TRUE,
                             return_table = TRUE,
                             n_processors = 6, 
                             save_models = TRUE,
                             include_BLRT = TRUE)

write_rds(d, "data/overall-stats-for-all-models.rds")
```

### Overall solutions for all models

```{r, printing-solutions-overall-stats, eval = T}
# d <- read_rds("data/overall-stats-for-all-models.rds")

overall_stats_for_all_models <- readr::read_rds("data/overall-stats-for-all-models.rds")

overall_stats_for_all_models[[1]] %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Overall statistics for all models", linesep = "") %>%
  kableExtra::kable_styling(latex_options = "scale_down") %>% 
  kableExtra::landscape()
```

First, I examined a wide range of models and solutions. I did this in order to select particular, candidate models to scrutinize in greater detail. In order to carry out this analysis, I followed guidelines recommended by the developers of MPlus (Asparouhov & Muthen, 2012; Muthen & Muthen, 2017) as well as those making recommendations about its use (Geiser, 2012). In particular, I set the number of starts to 600 for initial stage starts, and to 120 for the number of starts to be optimized. This means that for each model estimated, 600 random starting values for the parameters were used to initialize the EM algorithm. Of these 600, 120 that demonstrated the lowest log-likelihood were allowed to continue until they reached convergence or the limit for the number of iterations. In order for a model to me considered trustworthy, of these 120 runs, the lowest log-likelihood must be replicated at least one time. 

The results are presented in Figure 5.1. If this is the case, then the log-likelihood would appear in the table below; if not, "LL not replicated" is reported as the value. If none of the 120 runs converge, then "Did not converge" is reported as the value. As can be seen from this table, only models associated with model specifications 1 and 2 (and among these two solutions, only those associated with particular number of profiles) converged. Thus, only solutions associated with models 1 and 2 are explored in subsequent sections.

### In-depth statistics for particular models

After investigating the general information about a range of model solutions, solutions associated with models 1 and 2 are explored in greater detail, following recommendations associated with mixture modeling (Collins and Lanza, 2009; Geiser, 2012) and the authors of the MPlus software (Muthen & Muthen, 2017) as well as recent peer-reviewed articles (Pastor et al., 2007). For these models, the log-likelihood (LL), a range of information criteria (AIC, BIC, sample adjusted BIC [SABIC], consistent AIC [CAIC]), statistics about the quality of the profile assignments (entropy, which represents the mean posterior probability) are presented. 

The information criteria are based on the log-likelihood but take various steps to penalize complex models, and so can be used to directly compare models (i.e., the model with the lowest values for these statistics can be considered to better reflect the underlying properties of the profiles). Simulation studies have suggested that BIC, CAIC, SABIC, and BLRT are most helpful for selecting the correct number of profiles (Nylund, Asparouhov, & Muthen, 2007). For the entropy statistic, higher values are considered better, though scholars have suggested that the entropy statistic not be used for model selection (Lubke & Muthen, 2007).The log-likelihood should not be interpreted directly but is presented in conjunction with the information criteria for context about how each of them differs from the log-likelihood. These are also presented in Figures 5.1 and 5.2 

In addition to these statistics, a number of modified likelihood ratio tests (LRTs) are used, as the test statistics associated with unmodified LRT do not follow the distribution that the test is based on (Muthen & Muthen, 2017). These are the Vu-Lo-Mendell-Rubin LRT, Lo-Mendell-Rubin LRT, and the bootstrapped LRT. Of the three, the bootstrapped is considered to be the best indicator of which of two models, one nested (with certain parameters fixed to 0) within the other, fits better, but it is also the most computationally-intensive to carry out (Asparouhov & Muthen, 2012). For each of the LRTs, the test statistic and its associated p-value are provided; a p-value greater than .05 suggests that the model with fewer profiles should be preferred.

```{r, printing-solutions-spec-stats, eval = TRUE}
overall_stats_for_all_models[[2]] %>% 
  arrange(model, n_profile) %>% 
  select(-model, n_profiles = n_profile) %>% 
  knitr::kable(format = "latex", caption = "Solutions for models that converged with replicated LL", booktabs = TRUE, linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down") %>% 
  kableExtra::landscape() %>% 
  kableExtra::group_rows("Model 1", 1, 7) %>% 
  kableExtra::group_rows("Model 2", 8, 11)
```

```{r, model1, eval = T, cache = F, out.width = "60%", fig.cap = "Fit statistics for model 1"}

overall_stats_for_all_models[[2]] %>% 
  select(n_profile:CAIC, Entropy) %>% 
  filter(model == 1) %>% 
  mutate(AIC = AIC * -1,
         LL = LL * -1) %>% 
  gather(key, val, -n_profile, -model) %>% 
  ggplot(aes(x = n_profile, y = val)) +
  geom_point() +
  geom_line() +
  facet_grid(key ~ model, scales = "free") +
  theme_bw() +
  xlab("Number of Profiles") +
  ylab(NULL)
```

```{r, model2, eval = T, cache = F, out.width = "50%", fig.cap = "Fit statistics for model 2"}

overall_stats_for_all_models[[2]] %>% 
  select(n_profile:CAIC, Entropy) %>% 
  filter(model == 2) %>% 
  mutate(AIC = AIC * -1,
         LL = LL * -1) %>% 
  gather(key, val, -n_profile, -model) %>% 
  ggplot(aes(x = n_profile, y = val)) +
  geom_point() +
  geom_line() +
  facet_grid(key ~ model, scales = "free") +
  theme_bw() +
  xlab("Number of Profiles") +
  ylab(NULL)
```

Looking across the statistics presented in Table 4.3 and Figures 4.1 and 4.2, some general ideas about which models are to be preferred emerge. Solutions are interpreted first for each model individually and then across models with the goal of choosing a smaller number of models to investigate in more detail.

For solutions associated with model 1, the decrease (indicating a preferred model) in information criteria becomes smaller as the number of profiles increases from 5 to 6 and 6 to 7. A solution associated with 8 profiles did not replicate the log-likelihood and the VLMR and LMR suggest that the solution associated with 9 profiles did not fit better than that with 8 profiles, suggesting that models with 7 or fewer profiles be preferred. Considering these models, the entropy statistic increases by a large amount between the solution associated with 4 and 5 profiles (and then decreases slightly between 5 and 6 and 6 and 7 profile solutions), suggesting (but not providing conclusive evidence) that models 5, 6, or 7 may be preferred. The bootstrapped LRT suggests that, until the log-likelihood is not replicated, every more complex model be selected. Taking these pieces of evidence into conclusion, for model 1, solutions associated with 4 through 7 may be considered in more depth, with an emphasis on solutions associated with profiles with 5 and 6 profiles on the basis of the slowing of the decrease in the information criteria associated with the solutions with greater profiles than these, and the increase in the entropy from 4 to 5 (and 6) profile solutions.

For solutions associated with model 2, only those associated with 2-5 profile solutions were associated with log-likelihoods that were replicated. For these four models, the log-likelihood decreased in a mostly consistent way, such that changes in the decrease are not as evident as those associated with model 1. The entropy statistic decreases from 2 to 3 profile solutions, increases from 3 to 4 profile solutions, and then decreases slightly from 4 to 5 profile solutions, providing some information that models associated with 4 profiles be preferred to the others. All of the LRTs suggest that the more complex model be selected, not providing clear information about which solutions are to be preferred. On the basis of these pieces of evidence, models with 3, 4, and 5 solutions may be considered in more depth. However, there is a lack of consistent evidence favoring more or less complex models.

### Comparison of candidate solutions

In this section, specific models are examined so that candidate solutions can be compared. For all of the solutions, the data are centered to have a mean equal to 0, but not scaled to have a standard deviation equal to 1.

#### Model: 1, Profiles: 6

This solution is characterized by: 

- a **full** profile, profile 6
- a **universally low** profile, profile 2
- an **all moderate** profile, profile 5--and, like, the model 1, six profile solution--with moderate levels of affective engagement
- an **only behaviorally engaged** profile, profile 1, with moderate levels of behavioral engagement, very low affective engagement, and moderately (low) levels of cognitive engagement and challenge and competence
- an **only affectively engaged** profile, profile 4, with moderate levels of affective engagement, low levels of behavioral engagement, and moderately (low) levels of cognitive engagement and challenge and competence
- an **engaged and competent but not challenged** profile, profile 3, characterized by high levels of each of the three dimensions of engagement and of competence, but with low levels of challenge

The number of observations associated with each of the profiles is somewhat balanced, with the universally low profile with the largest number of observations (*n* = 667; the same number for this profile as in the model 1, five profile solution), followed by the all moderate profile (*n* = 638). Each of the other four profiles were associated with 300 to 400 observations. Unlike the model 1, four and five profile solutions, which distinguished observations on *either* a condition of engagement (i.e., competence) or one of its dimensions (i.e., cognitive, behavioral, and affective), this solution was associated with profiles that distinguished observations on the basis of both: There were profiles for only behaviorally and affectively engaged and for engaged and competent but not challenged. While the engaged and competent but not challenged was distinguished by low levels of challenge--different from the profile associated with the model 1, four profile solution characterized by high levels of competence--this solution is compelling because it appears to group students on the basis of multiple of the indicators, and demonstrate viability on the basis of the fit statistics (i.e., Tables 5.1 and 5.2 and Figure 5.1). The log-likelihood was replicated two times, with the next lowest log-likelihood not being replicated, followed by a log-likelihood that was replicated (at least) seven times. This solution (associated with the log-likelihood that was replicated [at least] seven times) could be investigated in further detail, to see whether--and if so, how--it differs from the solution interpreted here. Pending further exploration, this solution seems like a potential candidate for use in subsequent analyses. 

```{r, spec-solutions-m1_6, cache = FALSE, eval = FALSE}
m1_6 <- estimate_profiles_mplus(df,  
                                dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                                starts = c(600, 120),
                                model = 1,
                                n_profiles = 6,
                                include_BLRT=TRUE,
                                n_processors = 6, remove_tmp_files = FALSE)
write_rds(m1_6, "data/models/m1_6.rds")
```

```{r, m1_6p, cache = FALSE, eval = TRUE}
m1_6 <- read_rds("data/models/m1_6.rds")
plot_profiles_mplus(m1_6, to_scale = TRUE)
```

```{r, m1_6p-ll, eval = TRUE, cache = FALSE, eval = FALSE}
extract_LL_mplus() %>% slice(1:10) %>% knitr::kable()
```

#### Model: 1, Profiles: 7

This solution is characterized by: 

- a **full** profile, profile 7
- a **universally low** profile, profile 1
- a **competent but not engaged or challenged** profile, profile 2, characterized by high competence and moderate (low) or low levels of engagement and challenge
- a **moderately low** profile, profile 3, characterized by moderately low levels of all of the variables
- a **challenged** profile, profile 4, characterized by high challenge, moderate (high) levels of engagement, and moderate (low) levels of competence
- a **highly challenged** profile, profile 5, characterized by patterns similar to those of the challenged profile, but with higher challenge and with low levels of both engagement and challenge
- a **challenged but not engaged or competent** profile, profile 6, characterized by low levels of challenge, and high levels of engagement and competence

The number of observations associated with each of the profiles is not very balanced, with few (*n* = 181) observations associated with the universally low profile and few (*n* = 222) observations associated with the highly challenged profile. The number of observations associated with the other profiles ranged from 317 to 651. Where the universally low profile exhibited the same number of observations in the model 1, five and six profile solutions, for this solution, there were far fewer observations. Also distinct from other solutions, none of the other five profiles were found in the other model 1 solutions. Two pairs of the profiles--challenged and highly challenged and universally low and moderately low--exhibited similar patterns among the variables that were distinguished by different mean levels. The log-likelihood was replicated twice, with the next lowest log-likelihood being replicate four times, possibly warranting further investigation. Taken together, this solution raises questions about whether it may be too complex, possibly suggesting preference for model 1 five and six profile solutions. 

```{r, spec-solutions-m1_7, cache = FALSE, eval = FALSE}
m1_7 <- estimate_profiles_mplus(df,  
                                dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                                starts = c(600, 120),
                                model = 1,
                                n_profiles = 7,
                                include_BLRT=TRUE,
                                n_processors = 6, remove_tmp_files = FALSE)
write_rds(m1_7, "data/models/m1_7.rds")
```

```{r, m1_7p, cache = FALSE, eval = TRUE}
m1_7 <- read_rds("data/models/m1_7.rds")
plot_profiles_mplus(m1_7, to_scale = TRUE)
```

```{r, m1_7-ll, cache = FALSE, eval = FALSE}
extract_LL_mplus() %>% slice(1:10) %>% knitr::kable()
```

#### Looking across model 1 and model 2 solutions

When looking across solutions, some overall patterns in terms of what profiles emerge and some directions for which models are to be selected for use in subsequent analysis can be identified. First, overall patterns are discussed. In table 4.3, which profiles emerge from which solution is presented.

There is a wide range of profiles. Some appear very commonly, particularly those (full and universally low) characterized by high or low levels across all of the variables. Moderate profiles, both all moderate (characterized by moderately high levels across all of the variables) and moderately low (characterized by low levels across all of the variables), also appeared commonly, particularly for the solutions for model 1.

```{r, compare-profiles-by-solution}
d <- readxl::read_xlsx("tables/prof-assignments.xlsx")

d[-1, ] %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Profile assignments by LPA solution", linesep = "", align=rep('c', 13)) %>% 
  kableExtra::kable_styling(latex_options = "scale_down") %>% 
  kableExtra::landscape() %>%
  kableExtra::row_spec(0, angle = -60) %>% 
  kableExtra::group_rows("Model 1", 1, 6) %>% 
  kableExtra::group_rows("Model 2", 7, 9)
```

The model 1, six and seven profile solutions are compelling because both show profiles that are distinguished by dimensions of engagement and its conditions (challenge and competence). For each solution, alternate solutions associated with higher log-likelihoods were explored. One advantage of the six profile solution is that most of its profiles can also be identified in solutions with fewer profiles. For the six profile solutions, this alternate solution was very different, whereas for the seven profile solutions, this alternate solution was highly similar. The model solutions exhibit a less clear pattern in terms of which profiles appear when. All else being equal, on the basis of parsimony, the model 1, six profile solution may be preferred. As a type of sensitivity analysis, the model 1, seven profile solution is also explored, but results for it are included in an appendix.

## Research Question #2

Research question #2 is focused on the relations between each of the profiles and the aspects of work with data. Here is the order of this section:

- Model 1, six profile solution
- Null models
- Correlations between individual aspects of work with data and the composite and the profiles and individual interest
- Correlations between individual aspects of work with data and the composite and the variables that make up the profiles and individual interest
- Models with the work with data variables added separate
- Models with the composite added

### Model 1, six profile solution

Here is the model 1, six profile solution.  [need to change profile names in this plot and subsequent models]

```{r, rq2-3-proc, cache = FALSE}
m <- read_rds("data/models/m1_6.rds")
plot_profiles_mplus(m1_6, to_scale = TRUE) +
  scale_x_discrete(labels = c("Only behavioral (n = 370)",
                              "Universally low (n = 667)",
                              "Engaged and competent but not challenged (n = 450)",
                              "All moderate (n = 638)",
                              "Only affective (n = 638)",
                              "Full (n = 488)"))
```

```{r}
cc <- df %>% select(dm_cog_eng:dm_competence) %>% complete.cases()
C <- m %>% pull(C)

C_p <- select(m, CPROB1:CPROB6) %>% 
  apply(MARGIN = 1, FUN = max)

df_ss <- df[cc, ]
df_ss$profile <- C
df_ss$profile_p <- C_p

d <- df_ss %>% select(contains("dm"), participant_ID, program_ID, beep_ID = beep_ID_new, profile, profile_p, overall_pre_interest, youth_activity_rc, inquiry_based)

d <- d %>% 
  mutate(
    profile_1 = ifelse(profile == 1, 1, 0),
    profile_2 = ifelse(profile == 2, 1, 0),
    profile_3 = ifelse(profile == 3, 1, 0),
    profile_4 = ifelse(profile == 4, 1, 0),
    profile_5 = ifelse(profile == 5, 1, 0),
    profile_6 = ifelse(profile == 6, 1, 0),
    profile_1_p = ifelse(profile == 1, profile_p, 0),
    profile_2_p = ifelse(profile == 2, profile_p, 0),
    profile_3_p = ifelse(profile == 3, profile_p, 0),
    profile_4_p = ifelse(profile == 4, profile_p, 0),
    profile_5_p = ifelse(profile == 5, profile_p, 0),
    profile_6_p = ifelse(profile == 6, profile_p, 0)
  )
```

```{r, rq2-0-null, cache = TRUE}
m1 <- lmer(profile_1_p ~ 1 +
             (1 | participant_ID) +
             (1 | beep_ID) +
             (1 | program_ID),
           data = d)

m2 <- lmer(profile_2_p ~ 1 +
             (1 | participant_ID) +
             (1 | beep_ID) +
             (1 | program_ID),
           data = d)

m3 <- lmer(profile_3_p ~ 1 +
             (1 | participant_ID) +
             (1 | beep_ID) +
             (1 | program_ID),
           data = d)

m4 <- lmer(profile_4_p ~ 1 +
             (1 | participant_ID) +
             (1 | beep_ID) +
             (1 | program_ID),
           data = d)

m5 <- lmer(profile_5_p ~ 1 +
             (1 | participant_ID) +
             (1 | beep_ID) +
             (1 | program_ID),
           data = d)

m6 <- lmer(profile_6_p ~ 1 +
             (1 | participant_ID) +
             (1 | beep_ID) +
             (1 | program_ID),
           data = d)
```

```{r, rq2-1-all-vars-com, cache = TRUE}
m1a <- lmer(profile_1_p ~ 1 +
              dm_ask + dm_obs + dm_gen + dm_mod + dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m2a <- lmer(profile_2_p ~ 1 +
              dm_ask + dm_obs + dm_gen + dm_mod + dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m3a <- lmer(profile_3_p ~ 1 +
              dm_ask + dm_obs + dm_gen + dm_mod + dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m4a <- lmer(profile_4_p ~ 1 +
              dm_ask + dm_obs + dm_gen + dm_mod + dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m5a <- lmer(profile_5_p ~ 1 +
              dm_ask + dm_obs + dm_gen + dm_mod + dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m6a <- lmer(profile_6_p ~ 1 +
              dm_ask + dm_obs + dm_gen + dm_mod + dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)
```

```{r, rq2-2-composite, cache = TRUE}
m1c <- lmer(profile_1_p ~ 1 +
              dm_composite +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m2c <- lmer(profile_2_p ~ 1 +
              dm_composite +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m3c <- lmer(profile_3_p ~ 1 +
              dm_composite +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m4c <- lmer(profile_4_p ~ 1 +
              dm_composite +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m5c <- lmer(profile_5_p ~ 1 +
              dm_composite +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m6c <- lmer(profile_6_p ~ 1 +
              dm_composite +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)
```

```{r, tidy-model-sep-func, cache = FALSE}

# get_kr_df <- function(model_object) {
#   L <- diag(rep(1, length(lme4::fixef(model_object))))
#   L <- as.data.frame(L)
#   out <- purrr::map_dbl(L, pbkrtest::get_Lb_ddf, object = model_object)
#   names(out) <- names(lme4::fixef(model_object))
#   out
# }

wald_p_sig <- function(x) {
  (1 - pnorm(x))
}

tidy_model <- function(model) {
  
  fixef_names <- c("(Intercept)", "dm_ask", "dm_ask:overall_pre_interest", "dm_com",
                   "dm_gen", "dm_mod", "dm_obs", "overall_pre_interest", "overall_pre_interest:dm_com",
                   "overall_pre_interest:dm_gen", "overall_pre_interest:dm_mod",
                   "overall_pre_interest:dm_obs")
  
  d <- as.data.frame(matrix(rep(NA, 12), ncol = 12))
  names(d) <- fixef_names
  
  # fixefs
  fixef_vals <- tidy(model) %>%
    filter(effect == "fixed") %>%
    mutate(est = round(estimate, 3),
           se = round(std.error, 3),
           p_val = wald_p_sig(statistic)) %>% 
    mutate(est_se = ifelse(p_val < .001, 
                           str_c(est, " (", se, ")", " (p < .001)"),
                           str_c(est, " (", se, ")", " (p = ", round(p_val, 3), ")")
    )) %>%
    select(term, est_se) %>%
    spread(term, est_se)
  
  dd <- bind_rows(d, fixef_vals)[-1, ]
  
  # ICCs
  icc_vals <- sjstats::icc(model) %>%
    as.numeric() %>%
    round(3)
  
  # To return
  names(icc_vals) <- str_c(names(sjstats::icc(model)), "_ICC")
  ddd <- cbind(dd, as.data.frame(t(icc_vals)))
  ddd
}

```

### Null models

The null models presented in table 4.5 provide insight into the levels at which predictors may be able to explain the outcome. For all six profiles, the ICCs were very small, from 0.00 to 0.023. This suggests that very little variability can be explained simply by the program. For the momentary level, the ICCs were also very small, ranging from 0.004 to 0.011. Finally, the youth-level ICCs ranged from .099 to .427. Noteworthy, the ICC was highest for the full profile. The other profile characterized by a consistent pattern across all of the variables--the universally low profile--had a modest ICC, .265.

```{r, rq2-0-tab}
l <- list(m1, m2, m3, m4, m5, m6)

o <- map_df(l, tidy_model)

o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models for null models", linesep = "")
```

### Correlations between individual aspects of work with data and the composite and the profiles and individual interest

First, a correlation matrix of each of the profiles and each of the aspects of work with data (as well as overall pre interest and an overall measure of work with data) is presented. Most noteworth is the very small correlations between the aspects of work with data and the profiles; these correlations range (in absolute values) from .00 to .05. Only the relations etween communicating and profile six are statistically significant. The composite variable was correlated with the profiles from (in absolute values) 0.002 to 0.035, none statistically significant. The aspects of work with data are modestly correlated with one another, with correlations ranging from .16 to .46; all were significant. 

```{r, rq2-1-corr}
d %>% 
  select(dm_ask:dm_com, dm_composite,
         profile_1_p:profile_6_p,
         overall_pre_interest) %>% 
  corrr::correlate() %>% 
  corrr::shave() %>%
  corrr::fashion() %>% 
  knitr::kable(booktabs = TRUE, linesep = "", format = "latex") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

In order to determine whether there were greater correlations with the variables that make up the profiles, the correlations between the five variables that comprise the PECs and the five aspects of work with data were examined. These correlations were about the same as those between the profiles and teh aspects of work with data, ranging from (in absolute value terms) .00 to .06.

```{r, rq2-1-corr-components, eval = F}
d %>% 
  select(dm_ask:dm_com, dm_cog_eng:dm_competence) %>%
  corrr::correlate() %>% 
  corrr::shave() %>%
  corrr::fashion() %>% 
  knitr::kable(booktabs = TRUE, format = "latex", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down") %>% 
  kableExtra::landscape()
```

```{r, rq2-1-corr-p, eval = F}
p_vals <- d %>% 
  select(dm_ask:dm_com, dm_composite,
         profile_1_p:profile_6_p,
         overall_pre_interest) %>%
  psych::corr.test() %>% 
  pluck(4) %>% 
  round(3)
```

```{r, rq2-1-corr-spearman, eval = F}

# In order to determine whether these very small correlations are in part due to the dichotomous codes for work with data, a Spearman's correlation between the profile classifications (as a dichotomous variable) and the aspects of work with data was also carried out. These values were also very small, ranging from .00 to .04. 

d %>% 
  select(dm_ask:dm_com,
         profile_1:profile_6) %>% 
  corrr::correlate(method = "spearman") %>% 
  corrr::shave() %>%
  corrr::fashion() %>% 
  knitr::kable(booktabs = TRUE, linesep = "", caption = "Correlations between individual aspects of work with data nad the composite and the profiles") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

```{r, rq2-1-corr-p-spearman, eval = F}
p_vals <- d %>% 
  select(dm_ask:dm_com,
         profile_1:profile_6) %>% 
  psych::corr.test(method = "spearman") %>% 
  pluck(4) %>% 
  round(3)
```

### Correlations between individual aspects of work with data and the composite and the variables that make up the profiles and individual interest

Next, Pearson correlations between individual aspects of work with data (and the composite) and the variables that make up the profiles are presented. These correlations suggest that the aspects of work with data are not only not related to the profiles, but also not related to the aspects of work with data (with values ranging from .00 to .06). 

```{r, rq2-1-corr-ind-aspects}
d %>% 
  select(dm_ask:dm_com, dm_composite,
         dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
         overall_pre_interest) %>% 
  corrr::correlate() %>% 
  corrr::shave() %>%
  corrr::fashion() %>% 
  knitr::kable(booktabs = TRUE, linesep = "", caption = "Correlations between individual aspects of work with data nad the composite and the variables that make up the profiles") %>% 
  kableExtra::kable_styling(latex_options = "scale_down") %>% 
  kableExtra::landscape()
```

### Models with the work with data variables added separate

When the predictor variables for work with data are added, some overall patterns and specific findings can be identified. The only relations with *p*-values that were below the criterion for statistical significance (.05) were for the relations between modeling data and full engagement (B = 0.027 (0.016), p = .04) and between generating data and full engagement (B = 0.027 (0.014), p = .03). For this profile, the participant-level ICC decreased slightly.

```{r, rq2-1-tab}
l <- list(m1a, m2a, m3a, m4a, m5a, m6a)

o <- map_df(l, tidy_model)

o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         dm_ask, dm_obs, dm_gen, dm_mod, dm_com,
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models for all variables separate", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down") %>% 
  kableExtra::landscape()
```

### Models with the composite added

For the composite of work with data, the composite predicted profile 1, only behavioral (B = 0.008 (0.004), p = .019), but not any of the other profiles. However, this coefficient is very small. 

```{r, tidy-model-com-func, cache = FALSE}

# get_kr_df <- function(model_object) {
#   L <- diag(rep(1, length(lme4::fixef(model_object))))
#   L <- as.data.frame(L)
#   out <- purrr::map_dbl(L, pbkrtest::get_Lb_ddf, object = model_object)
#   names(out) <- names(lme4::fixef(model_object))
#   out
# }

wald_p_sig <- function(x) {
  (1 - pnorm(x))
}

tidy_model_com <- function(model) {
  
  fixef_names <- c("(Intercept)", "dm_composite", "overall_pre_interest", "overall_pre_interest:dm_composite")
  
  d <- as.data.frame(matrix(rep(NA, 4), ncol = 4))
  names(d) <- fixef_names
  
  # fixefs
  fixef_vals <- tidy(model) %>%
    filter(effect == "fixed") %>%
    mutate(est = round(estimate, 3),
           se = round(std.error, 3),
           p_val = wald_p_sig(statistic)) %>% 
    mutate(est_se = ifelse(p_val < .001, 
                           str_c(est, " (", se, ")", " (p < .001)"),
                           str_c(est, " (", se, ")", " (p = ", round(p_val, 3), ")")
    )) %>%
    select(term, est_se) %>%
    spread(term, est_se)
  
  dd <- bind_rows(d, fixef_vals)[-1, ]
  
  # ICCs
  icc_vals <- sjstats::icc(model) %>%
    as.numeric() %>%
    round(3)
  
  # To return
  names(icc_vals) <- str_c(names(sjstats::icc(model)), "_ICC")
  ddd <- cbind(dd, as.data.frame(t(icc_vals)))
  ddd
}

```

```{r}
l <- list(m1c, m2c, m3c, m4c, m5c, m6c)

o <- map_df(l, tidy_model_com)

o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         dm_composite,
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models for the composite", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

### Looking across findings for research question #2

When looking across findings, we find very few relations between work with data and the profiles. When looking across findings, we find very few relations between work with data and the profiles. This seemed to be the case for whether profiles or the variables that make up profiles were considered. Reasons for why this may be are discussed in the next chapter. 

## Research Question #3

This question focuses on whether the relations differ on the basis on the activity students are doing. Here is the order of this section:

1. Differences across profiles aby youth activity
1. Differences across the variables that make up the profiles by youth activity
1. Models with activity
1. Models with activity and the composite
1. Models with activity interacted with the composite

### Differences across profiles by activity

Mean differences across profiles by youth activity are examined using *t*-tests. Of these six mean differences, there were statistically significant differences between inquiry-based and non-inquiry-based activities between profiles 2, which was less common during inquiry-based activities (*p* = .003, *d* = 0.13), and 6, which was more common during inquiry-based activities (*p* < .001, *d* = 0.16).

```{r, rq3-1-diff-by-profiles}
rounded_mean <- function(x) {
  round(mean(x), 3)
}

d %>% 
  select(inquiry_based, profile_1_p:profile_6_p) %>% 
  group_by(inquiry_based) %>% 
  summarize_all(rounded_mean) %>% 
  knitr::kable(booktabs = TRUE, caption = "Differences across profiles by youth activity")
```

```{r, rq3-1-t-tests, eval = F}
tidyttest::t_test(d, profile_1_p, inquiry_based)
tidyttest::t_test(d, profile_2_p, inquiry_based) # p = .003, d = .13
tidyttest::t_test(d, profile_3_p, inquiry_based)
tidyttest::t_test(d, profile_4_p, inquiry_based)
tidyttest::t_test(d, profile_5_p, inquiry_based)
tidyttest::t_test(d, profile_6_p, inquiry_based) # p < .001, d = .16
```

### Differences across the variables that make up the profiles by activity

Mean differences across the variables that make up the profiles and youth activity are examined using *t*-tests. Of these five mean differences, there were statistically significant differences between inquiry-based and non-inquiry-based activities between all of the variables except for competence; studnets were more cognitively (*p* = .036, *d* = 0.09), behaviorally (*p* = .002, *d* = 0.13), and affectively (*p* < .001, *d* = .17), and were also more challenged (*p* < .00, *d* = .27)

```{r, rq3-1-diff-by-ind-vars}
d %>% 
  select(inquiry_based, dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence) %>% 
  group_by(inquiry_based) %>% 
  summarize_all(rounded_mean) %>% 
  knitr::kable(booktabs = TRUE, caption = "Differences across variables that make up profiles by activity")
```

```{r, rq3-1-t-tests-ind-vars, eval = F}
tidyttest::t_test(d, dm_cog_eng, inquiry_based) # p = .036, d = .09
tidyttest::t_test(d, dm_beh_eng, inquiry_based) # p = .002, d = .13
tidyttest::t_test(d, dm_aff_eng, inquiry_based) # p < .001, d = .17
tidyttest::t_test(d, dm_competence, inquiry_based) # p = .223
tidyttest::t_test(d, dm_challenge, inquiry_based) # p < .001, d = .27
```

### Models with activity

```{r, rq3-2-inq, cache = TRUE}
m1oi <- lmer(profile_1_p ~ 1 +
              inquiry_based +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m2oi <- lmer(profile_2_p ~ 1 +
              inquiry_based +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m3oi <- lmer(profile_3_p ~ 1 +
              inquiry_based +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m4oi <- lmer(profile_4_p ~ 1 +
              inquiry_based +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m5oi <- lmer(profile_5_p ~ 1 +
              inquiry_based +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m6oi <- lmer(profile_6_p ~ 1 +
              inquiry_based +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)
```


```{r, tidy-model-inquiry-separate, cache = FALSE}

# get_kr_df <- function(model_object) {
#   L <- diag(rep(1, length(lme4::fixef(model_object))))
#   L <- as.data.frame(L)
#   out <- purrr::map_dbl(L, pbkrtest::get_Lb_ddf, object = model_object)
#   names(out) <- names(lme4::fixef(model_object))
#   out
# }

wald_p_sig <- function(x) {
  (1 - pnorm(x))
}

tidy_model_inq <- function(model) {
  
  fixef_names <- c("(Intercept)", "inquiry_based", "dm_ask", "dm_obs", "dm_gen", "dm_mod", "dm_com", "inquiry_based:dm_ask", "inquiry_based:dm_obs", "inquiry_based:dm_gen", "inquiry_based:dm_mod", "inquiry_based:dm_com", "dm_composite", "overall_pre_interest")
  
  d <- as.data.frame(matrix(rep(NA, 14), ncol = 14))
  names(d) <- fixef_names
  
  # fixefs
  fixef_vals <- tidy(model) %>%
    filter(effect == "fixed") %>%
    mutate(est = round(estimate, 3),
           se = round(std.error, 3),
           p_val = wald_p_sig(statistic)) %>% 
    mutate(est_se = ifelse(p_val < .001, 
                           str_c(est, " (", se, ")", " (p < .001)"),
                           str_c(est, " (", se, ")", " (p = ", round(p_val, 3), ")")
    )) %>%
    select(term, est_se) %>%
    spread(term, est_se)
  
  dd <- bind_rows(d, fixef_vals)[-1, ]
  
  # ICCs
  icc_vals <- sjstats::icc(model) %>%
    as.numeric() %>%
    round(3)
  
  # To return
  names(icc_vals) <- str_c(names(sjstats::icc(model)), "_ICC")
  ddd <- cbind(dd, as.data.frame(t(icc_vals)))
  ddd
}

```

These models show that the activity predicts full engagement (*p* = .006 (0.016), *p* < .001). None of the other profiles were statistically significantly related.

```{r, inquiry-separate}
l <- list(m1oi, m2oi, m3oi, m4oi, m5oi, m6oi)

o <- map_df(l, tidy_model_inq)

o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         inquiry_based, 
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models for activity", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

```{r, rq3-2-interactions-with-work-with-data, cache = TRUE, eval = FALSE}
m1i <- lmer(profile_1_p ~ 1 +
              inquiry_based*dm_ask +
              inquiry_based*dm_obs +
              inquiry_based*dm_gen +
              inquiry_based*dm_mod +
              inquiry_based*dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m2i <- lmer(profile_2_p ~ 1 +
              inquiry_based*dm_ask +
              inquiry_based*dm_obs +
              inquiry_based*dm_gen +
              inquiry_based*dm_mod +
              inquiry_based*dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m3i <- lmer(profile_3_p ~ 1 +
              inquiry_based*dm_ask +
              inquiry_based*dm_obs +
              inquiry_based*dm_gen +
              inquiry_based*dm_mod +
              inquiry_based*dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m4i <- lmer(profile_4_p ~ 1 +
              inquiry_based*dm_ask +
              inquiry_based*dm_obs +
              inquiry_based*dm_gen +
              inquiry_based*dm_mod +
              inquiry_based*dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m5i <- lmer(profile_5_p ~ 1 +
              inquiry_based*dm_ask +
              inquiry_based*dm_obs +
              inquiry_based*dm_gen +
              inquiry_based*dm_mod +
              inquiry_based*dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m6i <- lmer(profile_6_p ~ 1 +
              inquiry_based*dm_ask +
              inquiry_based*dm_obs +
              inquiry_based*dm_gen +
              inquiry_based*dm_mod +
              inquiry_based*dm_com +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)
```

```{r, inquiry-separate-comp, eval = FALSE}
l <- list(m1i, m2i, m3i, m4i, m5i, m6i)

o <- map_df(l, tidy_model_inq)

o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         inquiry_based, 
         dm_ask:`inquiry_based:dm_com`,
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models for composites", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

### Models with activity and the composite 

```{r, rq3-2-inq-and-composite, cache = TRUE}
m1iio <- lmer(profile_1_p ~ 1 +
               inquiry_based + dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)

m2iio <- lmer(profile_2_p ~ 1 +
               inquiry_based + dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)

m3iio <- lmer(profile_3_p ~ 1 +
               inquiry_based + dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)

m4iio <- lmer(profile_4_p ~ 1 +
               inquiry_based + dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)

m5iio <- lmer(profile_5_p ~ 1 +
               inquiry_based + dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)

m6iio <- lmer(profile_6_p ~ 1 +
               inquiry_based + dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)
```

These models show that the acitivty is still related to full engagement (B = 0.063 (0.015), p < .001) and that the work with data composite is related to only behavioral (B = 0.008 (0.004), p = .016). These patterns were very similar to those found in earlier models with each of the predictor variables on their own.

```{r, inquiry-composite-and-activity}
l <- list(m1iio, m2iio, m3iio, m4iio, m5iio, m6iio)

o <- map_df(l, tidy_model_inq)

o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         inquiry_based, 
         dm_composite, 
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models for activity and composites", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

### Models with activity interacted with the composite

```{r, rq3-2-interactions-with-composite, cache = TRUE}
m1ii <- lmer(profile_1_p ~ 1 +
               inquiry_based*dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)

m2ii <- lmer(profile_2_p ~ 1 +
               inquiry_based*dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)

m3ii <- lmer(profile_3_p ~ 1 +
               inquiry_based*dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)

m4ii <- lmer(profile_4_p ~ 1 +
               inquiry_based*dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)

m5ii <- lmer(profile_5_p ~ 1 +
               inquiry_based*dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)

m6ii <- lmer(profile_6_p ~ 1 +
               inquiry_based*dm_composite +
               (1 | participant_ID) +
               (1 | beep_ID) +
               (1 | program_ID),
             data = d)
```

These models show a similar pattern as the model without the interaction, with statistically significant relationships between the activity and full engagement (B = 0.078 (0.026), p < .001) and between the composite and only behavioral (B = 0.008 (0.005), p = .034).

```{r, inquiry-composite-interaction}
l <- list(m1ii, m2ii, m3ii, m4ii, m5ii, m6ii)

o <- map_df(l, tidy_model_inq)

o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         inquiry_based, 
         dm_composite, 
         `inquiry_based:dm_composite`,
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models for activity and composites interactions", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

## Research Question #4

Research question #4 is focused on how the relationships observed as part of RQ2 differ on the basis of pre-program interest. Here is the order of this section:

- Models with pre interest, composite, and activity
- Models with pre interest interacted with the composite
- Models with pre interest interacted with youth activity

```{r, rq3-1-all-vars-sep, eval = TRUE}
m1c <- lmer(profile_1_p ~ 1 +
              dm_composite +
              inquiry_based + 
              overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m2c <- lmer(profile_2_p ~ 1 +
              dm_composite +
              inquiry_based + 
              overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m3c <- lmer(profile_3_p ~ 1 +
              dm_composite +
              inquiry_based + 
              overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m4c <- lmer(profile_4_p ~ 1 +
              dm_composite +
              inquiry_based + 
              overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m5c <- lmer(profile_5_p ~ 1 +
              dm_composite +
              inquiry_based + 
              overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m6c <- lmer(profile_6_p ~ 1 +
              dm_composite +
              inquiry_based + 
              overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)
```

```{r, rq3-2-all-vars-sep-interaction, eval = TRUE}
m1d <- lmer(profile_1_p ~ 1 +
              dm_composite*overall_pre_interest +
              inquiry_based + 
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m2d <- lmer(profile_2_p ~ 1 +
              dm_composite*overall_pre_interest +
              inquiry_based + 
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m3d <- lmer(profile_3_p ~ 1 +
              dm_composite*overall_pre_interest +
              inquiry_based + 
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m4d <- lmer(profile_4_p ~ 1 +
              dm_composite*overall_pre_interest +
              inquiry_based + 
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m5d <- lmer(profile_5_p ~ 1 +
              dm_composite*overall_pre_interest +
              inquiry_based + 
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m6d <- lmer(profile_6_p ~ 1 +
              dm_composite*overall_pre_interest +
              inquiry_based + 
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)
```

```{r, rq3-2-all-vars-sep-interaction-inq, eval = TRUE}
m1e <- lmer(profile_1_p ~ 1 +
              dm_composite + 
              inquiry_based*overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m2e <- lmer(profile_2_p ~ 1 +
              dm_composite + 
              inquiry_based*overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m3e <- lmer(profile_3_p ~ 1 +
              dm_composite + 
              inquiry_based*overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m4e <- lmer(profile_4_p ~ 1 +
              dm_composite + 
              inquiry_based*overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m5e <- lmer(profile_5_p ~ 1 +
              dm_composite + 
              inquiry_based*overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)

m6e <- lmer(profile_6_p ~ 1 +
              dm_composite + 
              inquiry_based*overall_pre_interest +
              (1 | participant_ID) +
              (1 | beep_ID) +
              (1 | program_ID),
            data = d)
```

### Models with pre interest, composite, and activity

These results were also very similar to when interest was added as a control: The activity and full engagement were statistically signifincantly related (B = 0.056 (0.016), p < .001) and between the composite and only behavioral (B = 0.008 (0.004), p = .027). Interest predicted the engaged and competent but not challenged profile (B = 0.037 (0.016), p = .008).

```{r, eval = TRUE}
l <- list(m1c, m2c, m3c, m4c, m5c, m6c)

o <- map_df(l, tidy_model_inq)

o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         overall_pre_interest,
         dm_composite,
         inquiry_based,
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models with interest, composite, and activity", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

### Models with pre interest interacted with the composite

These models show...

```{r, eval = TRUE}
l <- list(m1d, m2d, m3d, m4d, m5d, m6d)

o <- map_df(l, tidy_model_inq)

o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         overall_pre_interest,
         dm_composite,
         inquiry_based,
         `dm_composite:overall_pre_interest`,
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models with interest and composite interaction", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

### Models with pre interest interacted with youth activity

These models show...

```{r, eval = TRUE}
l <- list(m1e, m2e, m3e, m4e, m5e, m6e)

o <- map_df(l, tidy_model_inq)

o <- mutate(o, model = c(
  str_c("profile_", 1:6)))

o %>% 
  select(model, 
         intercept = `(Intercept)`,
         overall_pre_interest,
         dm_composite,
         inquiry_based,
         `inquiry_based:overall_pre_interest`,
         beep_ID_ICC = beep_ID_ICC,
         participant_ID_ICC,
         program_ID_ICC) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, caption = "Results of mixed effects models with interest and activity interaction", linesep = "") %>% 
  kableExtra::kable_styling(latex_options = "scale_down")
```

### Looking across findings for research question #4

When looking across findings, we find very few relations between work with data and the profiles. When looking across findings, like for research question #2, we find very few relations between work with data and the profiles. Like for research question #2, reasons for why this may be are explored in the next chapter.

## Research Question #5

```{r, loading-spreadsheets, eval = FALSE}
library(googlesheets)

g1 <- gs_title("USE THIS! New Coding Frame - KMS")
g2 <- gs_title("USE THIS! New Coding Frame - HM")
g3 <- gs_title("USE THIS! New Coding Frame - KS")

d1 <- rs_read(g1, ws = 1)
d2 <- rs_read(g1, ws = 2)
d3 <- rs_read(g1, ws = 3)
```

Research question #5 is focused on investigating specific findings of interest. 

### Why is support for work with data not related to the PECs?

### How does support for work with data lead to specific student activities related to work with data?

### What affordances and constraints do summer STEM programs have for work with data?

### What are characteristics of especially engaging moments?
