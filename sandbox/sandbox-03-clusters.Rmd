---
title: "sandbox-01"
author: "Joshua Rosenberg"
date: "12/27/2017"
output: html_document
---

# Sandbox - 03

### Background

This is a sandbox for exploring the data, in preparation for adding to the results section.

This document is organized around two sets of model specifications:

1. Fit using the R package `mclust`
2. Fit using the commerical software `MPlus`

Both are interfaced to through the `tidyLPA` package. 

### Models that are specified

**mclust**

For models fit using `mclust`, eight model specifications are tested, where all five refers to the variables for cognitive (learning), behavioral (hard working), and affective (enjoy), and challenge and competence, where three refers to just the three engagement measures. Note that the prior is to regularize the parameter estimates to be more less likely to be extreme (and therefore to be less likely to lead to convergence problems, but possibly less meaningful / interpretable).

* All five variables w/ no prior
* All five w/ prior
* All five w/ no prior and standardized (M = 0, SD = 1) variables
* All five w/ prior and standardized (M = 0, SD = 1) variables
* Three variables w/ no prior
* Three w/ prior
* Three w/ no prior and standardized (M = 0, SD = 1) variables
* Three w/ prior and standardized (M = 0, SD = 1) variables

*MPlus*

* All five variables w/ no prior
* All five w/ no prior and standardized (M = 0, SD = 1) variables
* Three variables w/ no prior
* Three w/ no prior and standardized (M = 0, SD = 1) variables

# 1. Processing data

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning =T, echo = F, cache = F)
```

```{r, loading-packages}
library(tidyverse)
library(lmerTest)
library(lme4)
library(corrr)
library(jmRtools)
library(tidyLPA)
```

```{r, loading-data, eval = F}
esm <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-esm.csv")
pre_survey_data_processed <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-pre-survey.csv")
post_survey_data_partially_processed <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-post-survey.csv")
video <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-video.csv")
pqa <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-pqa.csv")
attendance <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-attendance.csv")
class_data <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-class-video.csv")
demographics <- read_csv("/Volumes/SCHMIDTLAB/PSE/data/STEM-IE/STEM-IE-demographics.csv")
pm <- read_csv("/Volumes/SCHMIDTLAB/PSE/Data/STEM-IE/STEM-IE-program-match.csv")
```

```{r}
# save.image("~/desktop/sandbox-01.Rdata")
load("~/desktop/sandbox-01.Rdata")
```

```{r, processing-some-data}
attendance <- rename(attendance, participant_ID = ParticipantID)
attendance <- mutate(attendance, prop_attend = DaysAttended / DaysScheduled, 
                     participant_ID = as.integer(participant_ID))
attendance <- select(attendance, participant_ID, prop_attend)

demographics <- filter(demographics, participant_ID!= 7187)
demographics <- left_join(demographics, attendance)

esm$overall_engagement <- jmRtools::composite_mean_maker(esm, hard_working, concentrating, enjoy, interest)
```

```{r, joining-df}
df <- left_join(esm, pre_survey_data_processed, by = "participant_ID") # df & post-survey
df <- left_join(df, video, by = c("program_ID", "response_date", "sociedad_class", "signal_number")) # df & video
df <- left_join(df, demographics, by = c("participant_ID", "program_ID")) # df and demographics
```

```{r, proc-variables, echo = F}
df$participant_ID <- as.factor(df$participant_ID)
df$program_ID <- as.factor(df$program_ID)
df$beep_ID <- as.factor(df$beep_ID)
df$beep_ID_new <- as.factor(df$beep_ID_new)

df$youth_activity_rc <- ifelse(df$youth_activity == "Off Task", "Not Focused", df$youth_activity)

df$youth_activity_rc <- ifelse(df$youth_activity_rc == "Student Presentation" | df$youth_activity_rc == "Problem Solving", "Creating Product", df$youth_activity_rc)

df$youth_activity_rc <- ifelse(df$youth_activity_rc == "Showing Video", "Program Staff Led", df$youth_activity_rc)

df$youth_activity_rc <- as.factor(df$youth_activity_rc)

df$youth_activity_rc <- forcats::fct_relevel(df$youth_activity_rc, "Not Focused")

df$relevance <- jmRtools::composite_mean_maker(df, use_outside, future_goals, important)
```

```{r processing-demographics, echo = F, eval = F}
df$urm <- ifelse(df$race %in% c("White", "Asian"), 0, 1)
df$race <- as.factor(df$race)
df$race <- fct_lump(df$race, n = 2)
df$race_other <- fct_relevel(df$race, "Other")
df$gender_female <- as.factor(df$gender) # female is comparison_group
df$gender_female <- ifelse(df$gender_female == "F", 1, 
                           ifelse(df$gender_female == "M", 0, NA))
```

```{r}
pqa <- mutate(pqa, 
              active = active_part_1 + active_part_2,
              ho_thinking = ho_thinking_1 + ho_thinking_2 + ho_thinking_3,
              belonging = belonging_1 + belonging_2,
              agency = agency_1 + agency_2 + agency_3 + agency_4,
              youth_development_overall = active_part_1 + active_part_2 + ho_thinking_1 + ho_thinking_2 + ho_thinking_3 + belonging_1 + belonging_2 + agency_1 + agency_2 + agency_3 + agency_4,
              making_observations = stem_sb_8,
              data_modeling = stem_sb_2 + stem_sb_3 + stem_sb_9,
              interpreting_communicating = stem_sb_6,
              generating_data = stem_sb_4,
              asking_questions = stem_sb_1,
              stem_sb = stem_sb_1 + stem_sb_2 + stem_sb_3 + stem_sb_4 + stem_sb_5 + stem_sb_6 + stem_sb_7 + stem_sb_8 + stem_sb_9)

# pqa <- rename(pqa, sixth_math_sociedad = sixth_math)
# pqa <- rename(pqa, seventh_math_sociedad = seventh_math)
# pqa <- rename(pqa, eighth_math_sociedad = eighth_math)
# pqa <- rename(pqa, dance_sociedad = dance)
# pqa <- rename(pqa, robotics_sociedad = robotics)

pqa$sociedad_class <- ifelse(pqa$eighth_math == 1, "8th Math",
                             ifelse(pqa$seventh_math == 1, "7th Math",
                                    ifelse(pqa$sixth_math == 1, "6th Math",
                                           ifelse(pqa$robotics == 1, "Robotics",
                                                  ifelse(pqa$dance == 1, "Dance", NA)))))

pqa <- rename(pqa, 
              program_ID = SiteIDNumeric,
              response_date = resp_date,
              signal_number = signal)

pqa$program_ID <- as.character(pqa$program_ID)

df <- left_join(df, pqa, by = c("response_date", "program_ID", "signal_number", "sociedad_class"))
```

```{r}
df <- df %>% 
    mutate(youth_activity_three = case_when(
        youth_activity_rc == "Creating Product" ~ "Creating Product",
        youth_activity_rc == "Basic Skills Activity" ~ "Basic Skills Activity",
        TRUE ~ "Other"
    ))

df$youth_activity_three <- fct_relevel(df$youth_activity_three, 
                                       "Other")
```

```{r}

# <!-- Cognitive engagement	As you were signaled, were you learning anything or getting better at something? -->
# <!-- Behavioral engagement	As you were signaled, how hard were you working? -->
# <!-- Affective engagement	As you were signaled, did you enjoy what you are doing? -->
# <!-- Perceived challenge	As you were signaled, how challenging was the main activity? -->
# <!-- Perceived competence	As you were signaled, were you good at the main activity? -->

library(jmRtools)

df <- df %>% 
    mutate(dm_cog_eng = learning,
           dm_beh_eng = hard_working,
           dm_aff_eng = enjoy,
           dm_challenge = challenge,
           dm_competence = good_at) %>% 
    rename(ssb_predict = stem_sb_1,
           ssb_model = stem_sb_2 ,
           ssb_analyze = stem_sb_3,
           ssb_measure = stem_sb_4,
           ssb_tools = stem_sb_5,
           ssb_precision = stem_sb_6,
           ssb_vocabulary = stem_sb_7,
           ssb_classification = stem_sb_8,
           ssb_symbols = stem_sb_9) %>% 
    mutate(dm_ask = ssb_predict,
           dm_obs = ssb_classification,
           dm_gen = ifelse(ssb_measure == 1 | ssb_precision == 1, 1, 0),
           dm_mod = ifelse(ssb_model == 1 | ssb_analyze == 1, 1, 0),
           dm_com = ssb_symbols) %>% 
    mutate(ov_cog_eng = (important + future_goals) / 2,
           ov_beh_eng = (hard_working + concentrating) / 2,
           ov_aff_eng = (enjoy + interest) / 2)
```

```{r}
out <- df %>% 
    group_by(program_ID) %>% 
    select(contains("ssb")) %>% 
    summarize_all(sum, na.rm = T)

out1 <- pqa %>% 
    select(contains("stem"), -sum_stem_sb, -stem_sb) %>% 
    summarize_all(sum, na.rm = T) / 236

names(out1) <- df %>% select(contains("ssb")) %>% names()

pqa_out <- pqa %>% 
    group_by(program_ID) %>% 
    select(contains("stem"), -sum_stem_sb, -stem_sb) %>% 
    summarize_all(sum, na.rm = T)

names(pqa_out) <- names(out)
```

# 1. mclust profiles

### 1A. All five - no prior

```{r, eval = T}
df %>%
    select(dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence) %>% 
    compare_models_lpa(contains("dm"))
```

### 1B. All five - prior

```{r, eval = T}
df %>%
    select(dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence) %>% 
    compare_models_lpa(contains("dm"), prior_control = T)
```

### 1C. All five - no prior - standardized

```{r, eval = T}
df %>%
    select(dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence) %>% 
    mutate_all(center_and_scale_vector) %>% 
    compare_models_lpa(contains("dm"))
```

### 1D. All five - prior - standardized

```{r, eval = T}
df %>%
    select(dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence) %>% 
    mutate_all(center_and_scale_vector) %>% 
    compare_models_lpa(contains("dm"), prior_control = T)
```

### 1E. Three - no prior

```{r, eval = T}
df %>%
    select(dm_cog_eng, dm_beh_eng, dm_aff_eng) %>% 
    compare_models_lpa(contains("dm"))
```

### 1F. Three - prior

```{r, eval = T}
df %>%
    select(dm_cog_eng, dm_beh_eng, dm_aff_eng) %>% 
    compare_models_lpa(contains("dm"), prior_control = T)
```

### 1G. Three - no prior - standardized

```{r, eval = T}
df %>%
    select(dm_cog_eng, dm_beh_eng, dm_aff_eng) %>% 
    mutate_all(center_and_scale_vector) %>% 
    compare_models_lpa(contains("dm"))
```

### 1H. Three - prior - standardized

```{r, eval = T}
df %>%
    select(dm_cog_eng, dm_beh_eng, dm_aff_eng) %>% 
    mutate_all(center_and_scale_vector) %>% 
    compare_models_lpa(contains("dm"), prior_control = T)
```

# Mplus

### 2A: All five variables w/ no prior

```{r}
out_df <- compare_models_mplus(df, dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_chalenge, dm_competence)

out_df %>% 
    gather(key, val, -n_profiles) %>% 
    filter(val != "LL not replicated",
           val != "Convergence problem") %>% 
    ggplot(aes(x = n_profiles, y = val, color = key, group = key)) +
    geom_point() +
    geom_line()
```

### 2B: All five w/ no prior and standardized (M = 0, SD = 1) variables

```{r}
dfs <- df %>% select(dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_chalenge, dm_competence) %>% mutate_all(center_and_scale_vector)

out_df2 <- compare_models_mplus(dfs, dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_chalenge, dm_competence)
```

### 2C: Three variables w/ no prior

```{r}
out_df3 <- compare_models_mplus(df, dm_cog_eng, dm_beh_eng, dm_aff_eng)
```

### 2D: Three w/ no prior and standardized (M = 0, SD = 1) variables

```{r}
out_df4 <- compare_models_mplus(dfs, dm_cog_eng, dm_beh_eng, dm_aff_eng)
```












```{r, eval = F}
try_mplus1 <- function(i, j) {
    out <- tryCatch(
        {
            m <- create_profiles_mplus(df, 
                                       dm_cog_eng, dm_beh_eng, dm_aff_eng,
                                       n_profiles = (i + 1), model = j,
                                       start_iterations=c(100, 20),
                                       m_iterations = 1000)
            
            extract_mplus_summary(m)$BIC
            
        },
        error=function(cond) {
            return("did not converge")
        },
        warning=function(cond) {
            return(NULL)
        },
        finally={
        }
    )    
    return(out)
}

out_df1 <- data.frame(matrix(ncol = 5, nrow = 16))
names(out_df1) <- paste0("model_", 1:5)
out_df1 <- out_df1 %>% 
    mutate(n_profiles = 2:17) %>% 
    select(n_profiles, everything())

for (i in 1:16) {
    for (j in 1:5) {
        cat("i=", i, "\n")
        cat("j=", j, "\n")
        out_df1[i, j + 1] <- try_mplus1(i + 1, j)
    }
}

scale_vector <- function(x) {
    x / stats::sd(x, na.rm = TRUE)
}

center_vector <- function(x) {
    x - mean(x, na.rm = TRUE)
}

center_and_scale_vector <- function(x) {
    if (stats::sd(x, na.rm = TRUE) == 0) {
        x - mean(x, na.rm = TRUE)
    } else {
        (x - mean(x, na.rm = TRUE)) / stats::sd(x, na.rm = TRUE)
    }
}

```

# Comparing models - all five

```{r}
library(tidyLPA)
library(jmRtools)

d <- read_csv("all-five-vars-BIC.csv")

d %>% 
    gather(key, val, -n_profiles) %>% 
    filter(val != "did not converge") %>% 
    ggplot(aes(x = n_profiles, y = val, color = key, group = key)) +
    geom_point() +
    geom_line()

dd <- df %>%
    select(dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence) %>%
    mutate_all(center_and_scale_vector)

compare_models_lpa(df,
                   dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence, prior_control=T)
```

# Comparing models - all five, no standardizing

```{r}
create_profiles_lpa(df,
                    dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence, n_profiles = 2, model = 2, prior_control=T) %>% plot_profiles_lpa(to_center = T)

# m2, p5 - 9149.502, 9149.5*, but same substantive - eng doesn't matter much
# m1, p6 - 9711.2* - low and high challenge associated with sim levels of other vars, competent but bummed, no all high, all low
# m5, p6 - 9670.242 - competence seems less imp, but still low and high challenge
# m5, p7 - not super interesting
# m1, p7 - not stable, 7151.38 seems more stable
```

# # Comparing models - just three, no standardizing

```{r}

d1 <- read_csv("three-vars-BIC.csv")

d1 %>% 
    gather(key, val, -n_profiles) %>% 
    filter(val != "did not converge") %>% 
    ggplot(aes(x = n_profiles, y = val, color = key, group = key)) +
    geom_point() +
    geom_line()

compare_models_lpa(df,
                   dm_cog_eng, dm_beh_eng, dm_aff_eng, prior_control=T)
```

# for three, without centering and scaling

```{r}
compare_models_lpa(df,
                   dm_cog_eng, dm_beh_eng, dm_aff_eng, prior_control=T)

create_profiles_lpa(df,
                    dm_cog_eng, dm_beh_eng, dm_aff_eng, n_profiles = 4, model = 5, prior_control=T) %>% 
    plot_profiles_lpa(to_center = T)

# prof 5, m3 - 72.173, not a lotta
# prof 5, m5 - 712.964, not a lotta
# prof 4, m1 - 1274.95, high beh, mod beg
# 1212.899, high cog, high cog low others, low cog
# prof 4, m5 - 626.427

psych::fac()

```

# for three, with centering and scaling

```{r}
compare_models_lpa(d,
                   dm_cog_eng, dm_beh_eng, dm_aff_eng, prior_control = T)

create_profiles_lpa(d,
                    dm_cog_eng, dm_beh_eng, dm_aff_eng, n_profiles = 6, model = 1, prior_control=T) %>% 
    plot_profiles_lpa(to_center = T)

# prof 4, m1 - 781.9 and 767.833
# prof 4, m5 - 626.427
# prof 5, m3 - 385.322
```

# For three, new vars

```{r}
library(tidyLPA)
compare_models_lpa(df,
                   ov_aff_eng, ov_beh_eng, ov_cog_eng, prior_control = T)
# dm_challenge, dm_competence,
# m5, p5 stable, boring
# m1, p7 not stable
# m1, p8 not stable
# m1, p6 not stable, very related to our analyses
```

# For five, new vars

```{r}
compare_models_lpa(df,
                   ov_aff_eng, ov_beh_eng, ov_cog_eng, dm_challenge, dm_competence, prior_control = T)
# m2, p4: small cluster
# m2, p5: ok
# m5, p8 - not stable
# m1, p9 - not stable
```

# Factanal

```{r}
library(nFactors)

ddd <- dplyr::select(df, dm_cog_eng, dm_beh_eng, dm_aff_eng)
ddd <- ddd[complete.cases(ddd), ]
ev <- eigen(cor(ddd)) # get eigenvalues
ap <- parallel(subject=nrow(ddd),var=ncol(ddd),
               rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)

library(psych)
fit <- fa(as.matrix(ddd), nfactors=3, rotate = "oblimin")
fit # print results

library(lavaan)

m <- ' visual  =~ x1 + x2 + x3 
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '
```

```{r}
# d <- df %>% 
#     select(dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence) %>% 
#     mutate_all(center_and_scale_vector)
# 

# 
# create_profiles_lpa(d,
#                     dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
#                     n_profiles=5, model = 1) %>% plot_profiles_lpa()

d %>% 
    create_profiles_mplus(dm_cog_eng, dm_beh_eng, dm_aff_eng, dm_challenge, dm_competence,
                          n_profiles = 8, model = 2)

# MplusAutomation::runModels("t.inp")
m <- MplusAutomation::readModels("t.out")
# extract_warnings(m)
# extract_errors(m)

m$parameters %>% 
    pluck(1) %>% 
    filter(paramHeader == "Means",
           !(stringr::str_detect(param, "C#"))) %>% 
    ggplot(aes(x = LatentClass, y = est, fill = param)) +
    geom_col(position = "dodge")
```

### Rmixmod

```{r, eval = F}
library(Rmixmod)
iris

m <- mixmodCluster(iris[, -5], nbCluster = 2:3, models = mixmodGaussianModel())
summary(m)

d <- select(df, contains("dm"))
d <- d[complete.cases(d), ]
d <- mutate_all(d, scale)

my_models <- c("Gaussian_pk_L_B",
               "Gaussian_pk_L_C",
               "Gaussian_pk_Lk_Bk",
               "Gaussian_pk_Lk_Ck"
)

list.models <- mixmodGaussianModel(listModels = my_models)

m <- mixmodCluster(d, nbCluster = 3:6, 
                   models = list.models)

extract_criterion_value <- function(x) {
    criterion <- m["results"][x][[1]]@criterion
    criterion_value <- m["results"][x][[1]]@criterionValue
    model <- m["results"][x][[1]]@model
    n_profiles <- m["results"][x][[1]]@nbCluster
    data.frame(model, n_profiles, criterion, criterion_value)
}

extract_criterion_value(1)

1:length(m["results"]) %>% 
    purrr::map_df(extract_criterion_value) %>% 
    arrange(desc(criterion_value)) %>% 
    ggplot(aes(x = n_profiles, y = criterion_value, color = model, group = model)) +
    geom_line() +
    geom_point()
```